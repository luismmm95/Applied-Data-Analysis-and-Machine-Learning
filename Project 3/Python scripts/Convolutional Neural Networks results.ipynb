{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network analizes results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sympy as sp\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisializes the Neural Network model \n",
    "from keras.models import Sequential\n",
    "\n",
    "# This is to perform the convolution operation on a image, hence the 2D\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# Used for Flattening. Flattening is the process of converting all the resultant 2 dimensional arrays into a single long \n",
    "# continuous linear vector.\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# Used to perform the full connection of the neural network\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Stochastic gradient descent\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Regularizer that utilizes Ridge regression\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preprocessing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IO\n",
    "import Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  5408\n",
      "Number of validation images:  601\n",
      "Number of test images:  4006\n"
     ]
    }
   ],
   "source": [
    "raw_data = IO.loader(\"hmnist_8_8_RGB.csv\")\n",
    "\n",
    "data, raw_labels = Preprocess.create_label_data_split(raw_data, \"label\")\n",
    "labels, legend = Preprocess.make_categorical(raw_labels, 7)\n",
    "data = data.astype(np.float64)\n",
    "\n",
    "# one-hot representation of labels\n",
    "labels = np.argmax(labels, axis = 1)\n",
    "labels = to_categorical(labels, num_classes = 7)\n",
    "\n",
    "# Resizing data to (images,rows,col,RGB) = (10015,28,28,3)\n",
    "resized_data = []\n",
    "for i in range(10015):\n",
    "    resized_data.append(data[i].reshape(8,8,3))\n",
    "\n",
    "resized_data = np.array(resized_data)\n",
    "\n",
    "# Splitting test, training and validation for both data and labels \n",
    "train_size = 0.6\n",
    "test_size = 1 - train_size\n",
    "train, test, train_labels, test_labels = train_test_split(resized_data, labels, train_size=train_size, test_size=test_size,\n",
    "                                                         random_state = 7)\n",
    "\n",
    "valid_size = 0.1\n",
    "train_size = 1 - valid_size\n",
    "train, valid, train_labels, valid_labels = train_test_split(train, train_labels, train_size=train_size, test_size=valid_size,\n",
    "                                                           random_state = 15)\n",
    "\n",
    "print(\"Number of training images: \" , str(len(train)))\n",
    "print(\"Number of validation images: \" , str(len(valid)))\n",
    "print(\"Number of test images: \" , str(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Convolutional Neural Network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_NN(data_shape, n_neurons_layers, n_categories, eta=0.1, lmbd=0.1, n_filters=32, filter_sizes=3, \n",
    "                            pool_size = (2, 2), conv_strides=1, act_func='relu', cost_function='categorical_crossentropy'):\n",
    "    '''\n",
    "    This function creates a Convolutional Neural Networks give the following parameters. \n",
    "    \n",
    "    data_shape:       3D tensor with shape: (batch, steps, channels). Essentialy the input shape.\n",
    "    n_neurons_layers: Number of neurons/nodes of in the hidden layers. If a vector, it will generate \n",
    "                      n hidden layers = len(n_neurons_layers), where each value in the vector denotes the number of neurons\n",
    "                      in each hidden layer.\n",
    "    n_categories:     Nunber of classification (output nodes). \n",
    "    eta:              Learning rate of the Stochastic gradient descent.\n",
    "    lmbd:             L2 regularization parameter, also known as regularization strength.\n",
    "    n_filters:        Number of filters.\n",
    "    filter_sizes:     An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "                      Can be a single integer to specify the same value for all spatial dimensions. If a vector, \n",
    "                      it will generate n convolutional layers = size(filter_sizes), \n",
    "                      where each value in the vector denotes the filter size in each convolutional layer.\n",
    "    pool_size:        integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will \n",
    "                      halve the input in both spatial dimension. If only one integer is specified, the same window length \n",
    "                      will be used for both dimensions.\n",
    "    conv_strides:     An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height \n",
    "                      and width. Can be a single integer to specify the same value for all spatial dimensions. For the \n",
    "                      convolutional layer.\n",
    "    act_func:         Activation function to use. If you don't specify anything, no activation is applied \n",
    "                      (ie. \"linear\" activation: a(x) = x).\n",
    "    cost_function:    String (name of objective function) or objective function. See losses. If the model has multiple \n",
    "                      outputs, you can use a different loss on each output by passing a dictionary or a list of losses. \n",
    "                      The loss value that will be minimized by the model will then be the sum of all individual losses.\n",
    "    '''\n",
    "    model = Sequential() # Inisializing Neural Network model\n",
    "    \n",
    "    ## Convolution and pooling layers\n",
    "    # Adding a convolution layers\n",
    "    if np.size(filter_sizes)>1:\n",
    "        for conv_layer, filter_size in enumerate(filter_sizes):\n",
    "            model.add(Conv2D(n_filters, filter_size, strides = conv_strides, input_shape = data_shape,\n",
    "                             activation = act_func, kernel_regularizer=l2(lmbd)))\n",
    "    else:\n",
    "        conv_layer = 0\n",
    "        model.add(Conv2D(n_filters, filter_sizes, strides = conv_strides, input_shape = data_shape, activation = act_func,\n",
    "                         kernel_regularizer=l2(lmbd)))\n",
    "    \n",
    "    # adding the pooling layer\n",
    "    model.add(MaxPooling2D(pool_size = pool_size))\n",
    "    # Converting pooled image pixels (2D-array) to a one dimensional single vector.\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    ## Constructing hidden layers\n",
    "    # Adding a fully-connected layer\n",
    "    if np.size(n_neurons_layers)>1:\n",
    "        for layer, n_neuron in enumerate(n_neurons_layers):\n",
    "            model.add(Dense(units = n_neuron, activation='sigmoid', kernel_regularizer=l2(lmbd)))\n",
    "    else:\n",
    "        layer = 0\n",
    "        model.add(Dense(units = n_neurons_layers, activation='sigmoid', kernel_regularizer=l2(lmbd)))\n",
    "    \n",
    "    ## Output layer\n",
    "    model.add(Dense(units = n_categories, activation='softmax', kernel_regularizer=l2(lmbd)))\n",
    "    \n",
    "    ## Compiling model \n",
    "    sgd = SGD(lr=eta)\n",
    "    model.compile(loss = cost_function, optimizer = sgd, metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Convolutional Neural Network model with the following parameters:\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Learning rate eta = \", eta)\n",
    "    print(\"regularization strength lambda = \", lmbd)\n",
    "    print(\"\")\n",
    "    print(\"Number of convolutional layers: \", (conv_layer+1))\n",
    "    print(\"Number of filters in each convolutional layer: \", n_filters)\n",
    "    print(\"Filter size in each convolutional layer: \", filter_sizes)\n",
    "    print(\"\")\n",
    "    print(\"Number of hidden layers: \", (layer+1))\n",
    "    print(\"Nunber of neurons in each hidden layer: \", n_neurons_layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing create_convolutional_NN function with singel or vector input of  filter_sizes (receptive_field) and n_neurons_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.1\n",
      "regularization strength lambda =  0.1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  6\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 23, 13, 15)        1635      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 6, 15)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 990)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 4955      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 42        \n",
      "=================================================================\n",
      "Total params: 6,632\n",
      "Trainable params: 6,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,18,3)\n",
    "n_filters = 15\n",
    "n_categories = 7\n",
    "\n",
    "receptive_field = [1, 2, 3, 4, 5, 6]\n",
    "n_neurons_layers = [5, 10, 20, 40, 80, 100]\n",
    "\n",
    "# singel value input for both filter_sizes (receptive_field) and n_neurons_layers\n",
    "CNN_model_test = create_convolutional_NN(input_shape, n_neurons_layers[0], n_categories, n_filters = n_filters, \n",
    "                                    filter_sizes = receptive_field[5])\n",
    "CNN_model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.1\n",
      "regularization strength lambda =  0.1\n",
      "\n",
      "Number of convolutional layers:  6\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "Number of hidden layers:  6\n",
      "Nunber of neurons in each hidden layer:  [5, 10, 20, 40, 80, 100]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 18, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 17, 15)        915       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 15, 15)        2040      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 22, 12, 15)        3615      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 8, 15)         5640      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 3, 15)         8115      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 1, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 455       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 80)                3280      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               8100      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 34,047\n",
      "Trainable params: 34,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vector input for both filter_sizes (receptive_field) and n_neurons_layers\n",
    "CNN_model_test = create_convolutional_NN(input_shape, n_neurons_layers, n_categories, n_filters = n_filters, \n",
    "                                    filter_sizes = receptive_field)\n",
    "CNN_model_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is merely a test showing that one can change how many convolutional and hidden layes are set into the model, by sending more than one arguments at once (filter_sizes and n_neurons_layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model preformance with different values of eta vs. lambda and n_neurons vs. n_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_etaVSlambda(train_accuracy,test_accuracy):\n",
    "    sns.set()\n",
    "    sns.set(font_scale=2)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    sns.heatmap(train_accuracy, vmin=0, vmax=1, annot=True, ax=ax, cmap=\"YlGnBu\")\n",
    "    ax.set_title(\"Training Accuracy\")\n",
    "    ax.set_ylabel(\"Learning rate $\\eta$\")\n",
    "    ax.set_xlabel(\"Regularization parameter $\\lambda$\")\n",
    "    ax.set_xticklabels(['0.00001', '0.0001', '0.001', '0.01', '1'])\n",
    "    ax.set_yticklabels(['0.00001', '0.0001', '0.001', '0.01', '1', '2'])\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    sns.heatmap(test_accuracy, vmin=0, vmax=1, annot=True, ax=ax, cmap=\"YlGnBu\")\n",
    "    ax.set_title(\"Test Accuracy\")\n",
    "    ax.set_ylabel(\"Learning rate $\\eta$\")\n",
    "    ax.set_xlabel(\"Regularization parameter $\\lambda$\")\n",
    "    ax.set_xticklabels(['0.00001', '0.0001', '0.001', '0.01', '1'])\n",
    "    ax.set_yticklabels(['0.00001', '0.0001', '0.001', '0.01', '1', '2'])\n",
    "    plt.show()\n",
    "\n",
    "def plot_neuronsVSfilters(n_neurons,n_filters,train_accuracy,test_accuracy):\n",
    "    sns.set()\n",
    "    sns.set(font_scale=2)\n",
    "\n",
    "    # convert axis values to to string labels\n",
    "    x=[str(i) for i in n_filters]\n",
    "    y=[str(i) for i in n_neurons]\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    sns.heatmap(train_accuracy, vmin=0, vmax=1, annot=True, ax=ax, cmap=\"YlGnBu\")\n",
    "    #ax.set_title(\"Training Accuracy\")\n",
    "    ax.set_ylabel(\"Number of neurons\")\n",
    "    ax.set_xlabel(\"Number of filters\")\n",
    "    ax.set_xticklabels(x)\n",
    "    ax.set_yticklabels(y)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    sns.heatmap(test_accuracy, vmin=0, vmax=1, annot=True, ax=ax, cmap=\"YlGnBu\")\n",
    "    #ax.set_title(\"Test Accuracy\")\n",
    "    ax.set_ylabel(\"Number of neurons\")\n",
    "    ax.set_xlabel(\"Number of filters\")\n",
    "    ax.set_xticklabels(x)\n",
    "    ax.set_yticklabels(y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: eta (learning rate) vs. lambda (regularization parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 100\n",
    "input_shape = np.shape(np.array(train)[1])\n",
    "n_categories = labels.shape[1]\n",
    "receptive_field = 3 \n",
    "\n",
    "eta_values = [0.00001, 0.0001, 0.001, 0.01, 1, 2]\n",
    "lambda_values = [0.00001, 0.0001, 0.001, 0.01, 1]\n",
    "n_neuron_values = [5, 10, 20, 30, 40]\n",
    "n_filter_values = [5, 10, 15, 20, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1e-05\n",
      "regularization strength lambda =  1e-05\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 1ms/step - loss: 2.3814 - acc: 0.0418 - val_loss: 2.3639 - val_acc: 0.0449\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.3602 - acc: 0.0414 - val_loss: 2.3453 - val_acc: 0.0449\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.3451 - acc: 0.0414 - val_loss: 2.3316 - val_acc: 0.0449\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.3340 - acc: 0.0422 - val_loss: 2.3211 - val_acc: 0.0449\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.3246 - acc: 0.0420 - val_loss: 2.3125 - val_acc: 0.0449\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.3166 - acc: 0.0423 - val_loss: 2.3046 - val_acc: 0.0449\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.3084 - acc: 0.0423 - val_loss: 2.2974 - val_acc: 0.0449\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 2.3005 - acc: 0.0425 - val_loss: 2.2907 - val_acc: 0.0449\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.2929 - acc: 0.0427 - val_loss: 2.2844 - val_acc: 0.0466\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 2.2860 - acc: 0.0431 - val_loss: 2.2782 - val_acc: 0.0466\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.2800 - acc: 0.0435 - val_loss: 2.2724 - val_acc: 0.0466\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 2.2747 - acc: 0.0435 - val_loss: 2.2669 - val_acc: 0.0449\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.2694 - acc: 0.0433 - val_loss: 2.2618 - val_acc: 0.0449\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.2646 - acc: 0.0436 - val_loss: 2.2564 - val_acc: 0.0433\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 2.2596 - acc: 0.0436 - val_loss: 2.2511 - val_acc: 0.0433\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 2.2550 - acc: 0.0436 - val_loss: 2.2464 - val_acc: 0.0433\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.2506 - acc: 0.0436 - val_loss: 2.2420 - val_acc: 0.0449\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 2.2461 - acc: 0.0438 - val_loss: 2.2375 - val_acc: 0.0449\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 2.2414 - acc: 0.0435 - val_loss: 2.2328 - val_acc: 0.0466\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.2367 - acc: 0.0431 - val_loss: 2.2285 - val_acc: 0.0466\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 2.2325 - acc: 0.0431 - val_loss: 2.2244 - val_acc: 0.0466\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 2.2282 - acc: 0.0433 - val_loss: 2.2205 - val_acc: 0.0466\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 2.2242 - acc: 0.0435 - val_loss: 2.2163 - val_acc: 0.0466\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 2.2199 - acc: 0.0431 - val_loss: 2.2118 - val_acc: 0.0466\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 2.2156 - acc: 0.0431 - val_loss: 2.2073 - val_acc: 0.0449\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.2116 - acc: 0.0433 - val_loss: 2.2032 - val_acc: 0.0449\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.2077 - acc: 0.0435 - val_loss: 2.1993 - val_acc: 0.0449\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 2.2038 - acc: 0.0433 - val_loss: 2.1958 - val_acc: 0.0449\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.2000 - acc: 0.0429 - val_loss: 2.1926 - val_acc: 0.0433\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 2.1964 - acc: 0.0427 - val_loss: 2.1897 - val_acc: 0.0433\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 2.1928 - acc: 0.0429 - val_loss: 2.1868 - val_acc: 0.0433\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 2.1892 - acc: 0.0433 - val_loss: 2.1837 - val_acc: 0.0416\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 2.1854 - acc: 0.0431 - val_loss: 2.1800 - val_acc: 0.0416\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 2.1812 - acc: 0.0435 - val_loss: 2.1763 - val_acc: 0.0416\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.1769 - acc: 0.0427 - val_loss: 2.1727 - val_acc: 0.0416\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.1726 - acc: 0.0425 - val_loss: 2.1690 - val_acc: 0.0416\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 2.1683 - acc: 0.0425 - val_loss: 2.1653 - val_acc: 0.0416\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 2.1642 - acc: 0.0425 - val_loss: 2.1611 - val_acc: 0.0416\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.1600 - acc: 0.0427 - val_loss: 2.1566 - val_acc: 0.0399\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 2.1559 - acc: 0.0423 - val_loss: 2.1519 - val_acc: 0.0416\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 2.1518 - acc: 0.0422 - val_loss: 2.1472 - val_acc: 0.0416\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 2.1477 - acc: 0.0422 - val_loss: 2.1428 - val_acc: 0.0399\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.1439 - acc: 0.0423 - val_loss: 2.1388 - val_acc: 0.0399\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 2.1401 - acc: 0.0423 - val_loss: 2.1352 - val_acc: 0.0399\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 2.1363 - acc: 0.0422 - val_loss: 2.1317 - val_acc: 0.0399\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 2.1326 - acc: 0.0422 - val_loss: 2.1276 - val_acc: 0.0416\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.1287 - acc: 0.0420 - val_loss: 2.1230 - val_acc: 0.0399- loss: 2.1299 - ac\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.1249 - acc: 0.0420 - val_loss: 2.1178 - val_acc: 0.0399\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 2.1208 - acc: 0.0420 - val_loss: 2.1126 - val_acc: 0.0383\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 2.1164 - acc: 0.0425 - val_loss: 2.1076 - val_acc: 0.0383\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 2.1120 - acc: 0.0423 - val_loss: 2.1026 - val_acc: 0.0383\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 2.1074 - acc: 0.0420 - val_loss: 2.0977 - val_acc: 0.0383\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 2.1027 - acc: 0.0420 - val_loss: 2.0928 - val_acc: 0.0383\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 2.0979 - acc: 0.0418 - val_loss: 2.0882 - val_acc: 0.0383\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 2.0935 - acc: 0.0416 - val_loss: 2.0838 - val_acc: 0.0366oss: 2.0970 - acc: 0\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 2.0893 - acc: 0.0412 - val_loss: 2.0794 - val_acc: 0.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 2.0851 - acc: 0.0409 - val_loss: 2.0750 - val_acc: 0.0383\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 2.0809 - acc: 0.0411 - val_loss: 2.0706 - val_acc: 0.0399\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 2.0769 - acc: 0.0411 - val_loss: 2.0665 - val_acc: 0.0399\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 2.0731 - acc: 0.0416 - val_loss: 2.0629 - val_acc: 0.0383\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 2.0697 - acc: 0.0416 - val_loss: 2.0598 - val_acc: 0.0383\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 2.0664 - acc: 0.0412 - val_loss: 2.0568 - val_acc: 0.0383\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 2.0632 - acc: 0.0409 - val_loss: 2.0541 - val_acc: 0.0383\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 2.0602 - acc: 0.0407 - val_loss: 2.0515 - val_acc: 0.0366\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.0573 - acc: 0.0409 - val_loss: 2.0489 - val_acc: 0.0383\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 2.0543 - acc: 0.0407 - val_loss: 2.0462 - val_acc: 0.0366\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 2.0514 - acc: 0.0405 - val_loss: 2.0435 - val_acc: 0.0366\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 2.0484 - acc: 0.0399 - val_loss: 2.0406 - val_acc: 0.0366\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 2.0454 - acc: 0.0399 - val_loss: 2.0378 - val_acc: 0.0366\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 2.0425 - acc: 0.0401 - val_loss: 2.0352 - val_acc: 0.0366\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.0397 - acc: 0.0399 - val_loss: 2.0327 - val_acc: 0.0366\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.0370 - acc: 0.0399 - val_loss: 2.0303 - val_acc: 0.0366\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 2.0344 - acc: 0.0398 - val_loss: 2.0278 - val_acc: 0.0366\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 2.0317 - acc: 0.0396 - val_loss: 2.0252 - val_acc: 0.0366\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 2.0292 - acc: 0.0398 - val_loss: 2.0227 - val_acc: 0.0366\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 2.0267 - acc: 0.0396 - val_loss: 2.0204 - val_acc: 0.0366\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.0244 - acc: 0.0394 - val_loss: 2.0182 - val_acc: 0.0366\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 2.0221 - acc: 0.0394 - val_loss: 2.0161 - val_acc: 0.0366\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 2.0199 - acc: 0.0390 - val_loss: 2.0141 - val_acc: 0.0366\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 2.0178 - acc: 0.0390 - val_loss: 2.0122 - val_acc: 0.0366\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 2.0158 - acc: 0.0392 - val_loss: 2.0103 - val_acc: 0.0349\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 2.0137 - acc: 0.0390 - val_loss: 2.0084 - val_acc: 0.0349\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.0117 - acc: 0.0390 - val_loss: 2.0066 - val_acc: 0.0349\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.0097 - acc: 0.0388 - val_loss: 2.0047 - val_acc: 0.0349\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 2.0077 - acc: 0.0388 - val_loss: 2.0028 - val_acc: 0.0349\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 2.0057 - acc: 0.0386 - val_loss: 2.0010 - val_acc: 0.0333\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.0038 - acc: 0.0390 - val_loss: 1.9991 - val_acc: 0.0333\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 2.0018 - acc: 0.0390 - val_loss: 1.9972 - val_acc: 0.0333\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.9999 - acc: 0.0386 - val_loss: 1.9953 - val_acc: 0.0333\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.9980 - acc: 0.0386 - val_loss: 1.9934 - val_acc: 0.0333\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.9961 - acc: 0.0386 - val_loss: 1.9914 - val_acc: 0.0333\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.9942 - acc: 0.0386 - val_loss: 1.9896 - val_acc: 0.0333\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.9924 - acc: 0.0383 - val_loss: 1.9877 - val_acc: 0.0333\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.9906 - acc: 0.0381 - val_loss: 1.9858 - val_acc: 0.0333\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.9888 - acc: 0.0381 - val_loss: 1.9839 - val_acc: 0.0333\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.9870 - acc: 0.0379 - val_loss: 1.9821 - val_acc: 0.0316\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.9852 - acc: 0.0379 - val_loss: 1.9803 - val_acc: 0.0316\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.9835 - acc: 0.0377 - val_loss: 1.9785 - val_acc: 0.0316\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.9817 - acc: 0.0379 - val_loss: 1.9767 - val_acc: 0.0316\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.9800 - acc: 0.0379 - val_loss: 1.9749 - val_acc: 0.0300\n",
      "5408/5408 [==============================] - 1s 210us/step\n",
      "4006/4006 [==============================] - 1s 225us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1e-05\n",
      "regularization strength lambda =  0.0001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 1ms/step - loss: 2.0551 - acc: 0.1119 - val_loss: 2.0254 - val_acc: 0.1065\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 2.0069 - acc: 0.1119 - val_loss: 1.9900 - val_acc: 0.1065\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.9778 - acc: 0.1119 - val_loss: 1.9663 - val_acc: 0.1065\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.9605 - acc: 0.1119 - val_loss: 1.9532 - val_acc: 0.1065\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.9489 - acc: 0.1119 - val_loss: 1.9449 - val_acc: 0.1065\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.9411 - acc: 0.1119 - val_loss: 1.9381 - val_acc: 0.1065\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.9350 - acc: 0.1119 - val_loss: 1.9327 - val_acc: 0.1065\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.9302 - acc: 0.1119 - val_loss: 1.9280 - val_acc: 0.1065\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.9258 - acc: 0.1119 - val_loss: 1.9237 - val_acc: 0.1065\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.9219 - acc: 0.1119 - val_loss: 1.9198 - val_acc: 0.1065\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.9182 - acc: 0.1119 - val_loss: 1.9161 - val_acc: 0.1065\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.9148 - acc: 0.1119 - val_loss: 1.9126 - val_acc: 0.1065\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.9115 - acc: 0.1119 - val_loss: 1.9093 - val_acc: 0.1065\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.9084 - acc: 0.1119 - val_loss: 1.9062 - val_acc: 0.1065\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.9054 - acc: 0.1119 - val_loss: 1.9033 - val_acc: 0.1065\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.9025 - acc: 0.1119 - val_loss: 1.9004 - val_acc: 0.1065\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.8997 - acc: 0.1119 - val_loss: 1.8977 - val_acc: 0.1065\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.8970 - acc: 0.1119 - val_loss: 1.8949 - val_acc: 0.1065\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.8943 - acc: 0.1119 - val_loss: 1.8922 - val_acc: 0.1065s - loss: 1.8964 - a\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.8915 - acc: 0.1119 - val_loss: 1.8895 - val_acc: 0.1065\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.8889 - acc: 0.1119 - val_loss: 1.8869 - val_acc: 0.1065\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.8862 - acc: 0.1119 - val_loss: 1.8842 - val_acc: 0.1065\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.8835 - acc: 0.1119 - val_loss: 1.8816 - val_acc: 0.1065\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.8808 - acc: 0.1119 - val_loss: 1.8790 - val_acc: 0.1065\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.8782 - acc: 0.1119 - val_loss: 1.8764 - val_acc: 0.1065\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.8755 - acc: 0.1119 - val_loss: 1.8738 - val_acc: 0.1065\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.8729 - acc: 0.1119 - val_loss: 1.8712 - val_acc: 0.1065\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.8703 - acc: 0.1119 - val_loss: 1.8686 - val_acc: 0.1065\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.8677 - acc: 0.1119 - val_loss: 1.8661 - val_acc: 0.1065\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.8652 - acc: 0.1119 - val_loss: 1.8635 - val_acc: 0.1065\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.8626 - acc: 0.1119 - val_loss: 1.8610 - val_acc: 0.1065\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.8600 - acc: 0.1119 - val_loss: 1.8584 - val_acc: 0.1065\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.8575 - acc: 0.1119 - val_loss: 1.8559 - val_acc: 0.1065\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.8550 - acc: 0.1119 - val_loss: 1.8534 - val_acc: 0.1065\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.8525 - acc: 0.1119 - val_loss: 1.8510 - val_acc: 0.1065\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.8501 - acc: 0.1119 - val_loss: 1.8485 - val_acc: 0.1065\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.8476 - acc: 0.1119 - val_loss: 1.8461 - val_acc: 0.1065\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.8452 - acc: 0.1119 - val_loss: 1.8436 - val_acc: 0.1065\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.8428 - acc: 0.1119 - val_loss: 1.8412 - val_acc: 0.1065\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.8403 - acc: 0.1119 - val_loss: 1.8388 - val_acc: 0.1065\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.8379 - acc: 0.1119 - val_loss: 1.8364 - val_acc: 0.1065\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.8355 - acc: 0.1119 - val_loss: 1.8340 - val_acc: 0.1065\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.8331 - acc: 0.1119 - val_loss: 1.8316 - val_acc: 0.1065\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.8307 - acc: 0.1119 - val_loss: 1.8292 - val_acc: 0.1065\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.8283 - acc: 0.1119 - val_loss: 1.8268 - val_acc: 0.1065\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.8259 - acc: 0.1119 - val_loss: 1.8244 - val_acc: 0.1065\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.8236 - acc: 0.1119 - val_loss: 1.8221 - val_acc: 0.1065\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.8212 - acc: 0.1119 - val_loss: 1.8197 - val_acc: 0.1065\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.8189 - acc: 0.1119 - val_loss: 1.8174 - val_acc: 0.1065\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.8165 - acc: 0.1119 - val_loss: 1.8151 - val_acc: 0.1065\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.8142 - acc: 0.1119 - val_loss: 1.8127 - val_acc: 0.1065\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.8119 - acc: 0.1119 - val_loss: 1.8104 - val_acc: 0.1065\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.8096 - acc: 0.1119 - val_loss: 1.8081 - val_acc: 0.1065\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.8073 - acc: 0.1119 - val_loss: 1.8058 - val_acc: 0.1065\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.8050 - acc: 0.1119 - val_loss: 1.8035 - val_acc: 0.1065\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.8027 - acc: 0.1119 - val_loss: 1.8013 - val_acc: 0.1065\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.8004 - acc: 0.1119 - val_loss: 1.7990 - val_acc: 0.1065\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.7981 - acc: 0.1119 - val_loss: 1.7967 - val_acc: 0.1065\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.7959 - acc: 0.1119 - val_loss: 1.7944 - val_acc: 0.1065\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.7936 - acc: 0.1119 - val_loss: 1.7922 - val_acc: 0.1065\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.7914 - acc: 0.1119 - val_loss: 1.7899 - val_acc: 0.1065\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.7892 - acc: 0.1119 - val_loss: 1.7877 - val_acc: 0.1065\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.7869 - acc: 0.1119 - val_loss: 1.7854 - val_acc: 0.1065\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.7847 - acc: 0.1119 - val_loss: 1.7832 - val_acc: 0.1065\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.7825 - acc: 0.1119 - val_loss: 1.7810 - val_acc: 0.1065\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.7803 - acc: 0.1119 - val_loss: 1.7787 - val_acc: 0.1065\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.7781 - acc: 0.1119 - val_loss: 1.7766 - val_acc: 0.1065\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.7759 - acc: 0.1119 - val_loss: 1.7743 - val_acc: 0.1065\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.7738 - acc: 0.1119 - val_loss: 1.7721 - val_acc: 0.1065\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.7716 - acc: 0.1119 - val_loss: 1.7699 - val_acc: 0.1065\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.7694 - acc: 0.1119 - val_loss: 1.7678 - val_acc: 0.1065\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7672 - acc: 0.1119 - val_loss: 1.7656 - val_acc: 0.1065\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.7651 - acc: 0.1119 - val_loss: 1.7634 - val_acc: 0.1065\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.7630 - acc: 0.1119 - val_loss: 1.7613 - val_acc: 0.1065\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.7608 - acc: 0.1119 - val_loss: 1.7591 - val_acc: 0.1065\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.7587 - acc: 0.1119 - val_loss: 1.7570 - val_acc: 0.1065\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.7565 - acc: 0.1119 - val_loss: 1.7548 - val_acc: 0.1065\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.7544 - acc: 0.1119 - val_loss: 1.7527 - val_acc: 0.1065\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.7523 - acc: 0.1119 - val_loss: 1.7506 - val_acc: 0.1065\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7502 - acc: 0.1126 - val_loss: 1.7484 - val_acc: 0.1065\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.7481 - acc: 0.1128 - val_loss: 1.7464 - val_acc: 0.1065\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.7460 - acc: 0.1128 - val_loss: 1.7443 - val_acc: 0.1065\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.7439 - acc: 0.1132 - val_loss: 1.7422 - val_acc: 0.1065\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.7418 - acc: 0.1132 - val_loss: 1.7401 - val_acc: 0.1065\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7398 - acc: 0.1132 - val_loss: 1.7380 - val_acc: 0.1065\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.7377 - acc: 0.1132 - val_loss: 1.7360 - val_acc: 0.1065\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.7357 - acc: 0.1132 - val_loss: 1.7339 - val_acc: 0.1065 0s - loss: 1.7367 - acc: 0.112\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.7336 - acc: 0.1132 - val_loss: 1.7319 - val_acc: 0.1065\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.7316 - acc: 0.1134 - val_loss: 1.7298 - val_acc: 0.1065\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.7295 - acc: 0.1134 - val_loss: 1.7278 - val_acc: 0.1065\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.7275 - acc: 0.1134 - val_loss: 1.7257 - val_acc: 0.1065\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7255 - acc: 0.1134 - val_loss: 1.7237 - val_acc: 0.1065\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7235 - acc: 0.1135 - val_loss: 1.7218 - val_acc: 0.1065\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.7215 - acc: 0.1135 - val_loss: 1.7198 - val_acc: 0.1065\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.7195 - acc: 0.1135 - val_loss: 1.7178 - val_acc: 0.1065\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.7175 - acc: 0.1135 - val_loss: 1.7158 - val_acc: 0.1065\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.7155 - acc: 0.1135 - val_loss: 1.7138 - val_acc: 0.1065\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.7135 - acc: 0.1135 - val_loss: 1.7118 - val_acc: 0.1065\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.7115 - acc: 0.1135 - val_loss: 1.7099 - val_acc: 0.1065\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.7096 - acc: 0.1135 - val_loss: 1.7079 - val_acc: 0.1065\n",
      "5408/5408 [==============================] - 1s 254us/step\n",
      "4006/4006 [==============================] - ETA:  - 1s 227us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1e-05\n",
      "regularization strength lambda =  0.001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 1ms/step - loss: 2.0121 - acc: 0.0889 - val_loss: 2.0208 - val_acc: 0.0965\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.0030 - acc: 0.0960 - val_loss: 2.0110 - val_acc: 0.1032- loss: 2.0011 - acc: 0.0 - ETA: 0s - loss: 2.0038 - acc: 0.09\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.9930 - acc: 0.1072 - val_loss: 2.0005 - val_acc: 0.1131\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.9830 - acc: 0.1207 - val_loss: 1.9887 - val_acc: 0.1314\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.9721 - acc: 0.1350 - val_loss: 1.9757 - val_acc: 0.1464\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.9605 - acc: 0.1494 - val_loss: 1.9613 - val_acc: 0.1764\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.9472 - acc: 0.1644 - val_loss: 1.9463 - val_acc: 0.1947\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.9315 - acc: 0.1860 - val_loss: 1.9291 - val_acc: 0.2146\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.9126 - acc: 0.2147 - val_loss: 1.9092 - val_acc: 0.2413\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.8927 - acc: 0.2443 - val_loss: 1.8890 - val_acc: 0.2729\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.8722 - acc: 0.2731 - val_loss: 1.8677 - val_acc: 0.3111s: 1.8751 - acc: 0.2\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.8499 - acc: 0.3077 - val_loss: 1.8449 - val_acc: 0.3478\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.8267 - acc: 0.3401 - val_loss: 1.8228 - val_acc: 0.3744\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.8047 - acc: 0.378 - 1s 202us/step - loss: 1.8048 - acc: 0.3794 - val_loss: 1.8013 - val_acc: 0.4226\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.7834 - acc: 0.4144 - val_loss: 1.7815 - val_acc: 0.4509\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.7648 - acc: 0.4480 - val_loss: 1.7648 - val_acc: 0.4759\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.7480 - acc: 0.4765 - val_loss: 1.7501 - val_acc: 0.5042\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.7328 - acc: 0.5028 - val_loss: 1.7365 - val_acc: 0.5258loss: 1.7374 - acc: 0.49 - ETA: 0s - loss: 1.7326 - acc: 0.50\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.7196 - acc: 0.5296 - val_loss: 1.7241 - val_acc: 0.5541\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.7083 - acc: 0.5494 - val_loss: 1.7146 - val_acc: 0.5757\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.6993 - acc: 0.5653 - val_loss: 1.7070 - val_acc: 0.5857\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.6913 - acc: 0.5791 - val_loss: 1.7008 - val_acc: 0.5874\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.6844 - acc: 0.5888 - val_loss: 1.6958 - val_acc: 0.5940\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.6783 - acc: 0.5971 - val_loss: 1.6915 - val_acc: 0.6057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.6730 - acc: 0.6037 - val_loss: 1.6876 - val_acc: 0.6123\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6681 - acc: 0.6082 - val_loss: 1.6837 - val_acc: 0.6156\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.6636 - acc: 0.6143 - val_loss: 1.6801 - val_acc: 0.6173\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.6595 - acc: 0.6183 - val_loss: 1.6767 - val_acc: 0.6173\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.6557 - acc: 0.6219 - val_loss: 1.6736 - val_acc: 0.6173\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.6521 - acc: 0.6259 - val_loss: 1.6707 - val_acc: 0.6206\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.6488 - acc: 0.6285 - val_loss: 1.6679 - val_acc: 0.6256\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6455 - acc: 0.6293 - val_loss: 1.6651 - val_acc: 0.6273\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.6424 - acc: 0.6313 - val_loss: 1.6622 - val_acc: 0.6290\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.6394 - acc: 0.6342 - val_loss: 1.6597 - val_acc: 0.6306\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.6364 - acc: 0.6354 - val_loss: 1.6571 - val_acc: 0.6323\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.6335 - acc: 0.6372 - val_loss: 1.6547 - val_acc: 0.6323\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.6307 - acc: 0.6372 - val_loss: 1.6522 - val_acc: 0.6323\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.6281 - acc: 0.6387 - val_loss: 1.6497 - val_acc: 0.6323\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.6254 - acc: 0.6400 - val_loss: 1.6471 - val_acc: 0.6339\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.6227 - acc: 0.6407 - val_loss: 1.6445 - val_acc: 0.6339\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.6201 - acc: 0.6422 - val_loss: 1.6419 - val_acc: 0.6356\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.6176 - acc: 0.6431 - val_loss: 1.6395 - val_acc: 0.6356\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.6151 - acc: 0.6446 - val_loss: 1.6371 - val_acc: 0.6373\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.6128 - acc: 0.6466 - val_loss: 1.6347 - val_acc: 0.6373\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.6104 - acc: 0.6476 - val_loss: 1.6326 - val_acc: 0.6373\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.6081 - acc: 0.6485 - val_loss: 1.6303 - val_acc: 0.6389\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.6058 - acc: 0.6496 - val_loss: 1.6281 - val_acc: 0.6389\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.6037 - acc: 0.6500 - val_loss: 1.6260 - val_acc: 0.6389\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.6016 - acc: 0.6507 - val_loss: 1.6240 - val_acc: 0.6389\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.5996 - acc: 0.6526 - val_loss: 1.6220 - val_acc: 0.6389\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.5976 - acc: 0.6533 - val_loss: 1.6201 - val_acc: 0.6406\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.5957 - acc: 0.6537 - val_loss: 1.6182 - val_acc: 0.6423\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.5939 - acc: 0.6540 - val_loss: 1.6162 - val_acc: 0.6423\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.5921 - acc: 0.6546 - val_loss: 1.6147 - val_acc: 0.6439\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.5903 - acc: 0.6546 - val_loss: 1.6128 - val_acc: 0.6439\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.5885 - acc: 0.6550 - val_loss: 1.6110 - val_acc: 0.6456\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5868 - acc: 0.6555 - val_loss: 1.6093 - val_acc: 0.6456\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.5851 - acc: 0.6557 - val_loss: 1.6076 - val_acc: 0.6456\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.5835 - acc: 0.6564 - val_loss: 1.6057 - val_acc: 0.6456\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.5818 - acc: 0.6572 - val_loss: 1.6043 - val_acc: 0.6456\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.5802 - acc: 0.6575 - val_loss: 1.6028 - val_acc: 0.6456\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.5786 - acc: 0.6579 - val_loss: 1.6014 - val_acc: 0.6456\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.5771 - acc: 0.6581 - val_loss: 1.5999 - val_acc: 0.6456\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.5756 - acc: 0.6581 - val_loss: 1.5984 - val_acc: 0.6456\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.5740 - acc: 0.6587 - val_loss: 1.5970 - val_acc: 0.6456\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.5725 - acc: 0.6588 - val_loss: 1.5955 - val_acc: 0.6473\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5710 - acc: 0.6588 - val_loss: 1.5941 - val_acc: 0.6473\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5696 - acc: 0.6588 - val_loss: 1.5928 - val_acc: 0.6473\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.5681 - acc: 0.6590 - val_loss: 1.5915 - val_acc: 0.6473\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.5668 - acc: 0.6592 - val_loss: 1.5902 - val_acc: 0.6473\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.5654 - acc: 0.6594 - val_loss: 1.5888 - val_acc: 0.6473\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.5641 - acc: 0.6594 - val_loss: 1.5875 - val_acc: 0.6473\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.5627 - acc: 0.6596 - val_loss: 1.5861 - val_acc: 0.6473\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.5621 - acc: 0.659 - 1s 179us/step - loss: 1.5615 - acc: 0.6601 - val_loss: 1.5847 - val_acc: 0.6473\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 174us/step - loss: 1.5602 - acc: 0.6603 - val_loss: 1.5833 - val_acc: 0.6473\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.5589 - acc: 0.6605 - val_loss: 1.5819 - val_acc: 0.6473\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.5577 - acc: 0.6605 - val_loss: 1.5805 - val_acc: 0.6473\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5565 - acc: 0.6603 - val_loss: 1.5793 - val_acc: 0.6473\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 174us/step - loss: 1.5553 - acc: 0.6603 - val_loss: 1.5781 - val_acc: 0.6489\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.5541 - acc: 0.6603 - val_loss: 1.5769 - val_acc: 0.6489\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 1.5529 - acc: 0.6609 - val_loss: 1.5756 - val_acc: 0.6489\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 1.5517 - acc: 0.6609 - val_loss: 1.5743 - val_acc: 0.6489\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 175us/step - loss: 1.5506 - acc: 0.6611 - val_loss: 1.5730 - val_acc: 0.6489\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 177us/step - loss: 1.5495 - acc: 0.6616 - val_loss: 1.5718 - val_acc: 0.6489\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.5484 - acc: 0.6616 - val_loss: 1.5705 - val_acc: 0.6489\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5472 - acc: 0.6620 - val_loss: 1.5691 - val_acc: 0.6489\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 1.5461 - acc: 0.6622 - val_loss: 1.5679 - val_acc: 0.6506\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 175us/step - loss: 1.5451 - acc: 0.6620 - val_loss: 1.5668 - val_acc: 0.6506\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 173us/step - loss: 1.5440 - acc: 0.6622 - val_loss: 1.5656 - val_acc: 0.6506\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.5426 - acc: 0.662 - 1s 175us/step - loss: 1.5429 - acc: 0.6622 - val_loss: 1.5645 - val_acc: 0.6506\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 173us/step - loss: 1.5418 - acc: 0.6627 - val_loss: 1.5633 - val_acc: 0.6506\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5407 - acc: 0.6629 - val_loss: 1.5620 - val_acc: 0.6506\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 1.5396 - acc: 0.6629 - val_loss: 1.5609 - val_acc: 0.6506\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 1.5386 - acc: 0.6631 - val_loss: 1.5598 - val_acc: 0.6506\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.5375 - acc: 0.6636 - val_loss: 1.5588 - val_acc: 0.6506\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 174us/step - loss: 1.5364 - acc: 0.6636 - val_loss: 1.5577 - val_acc: 0.6522\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 172us/step - loss: 1.5354 - acc: 0.6636 - val_loss: 1.5565 - val_acc: 0.6522\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 1.5343 - acc: 0.6640 - val_loss: 1.5557 - val_acc: 0.6522\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.5333 - acc: 0.6642 - val_loss: 1.5546 - val_acc: 0.6522\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5323 - acc: 0.6642 - val_loss: 1.5533 - val_acc: 0.6522\n",
      "5408/5408 [==============================] - 1s 190us/step\n",
      "4006/4006 [==============================] - 1s 188us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1e-05\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 1ms/step - loss: 3.2462 - acc: 0.1285 - val_loss: 3.2233 - val_acc: 0.1248\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 3.2354 - acc: 0.1298 - val_loss: 3.2132 - val_acc: 0.1314\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 3.2240 - acc: 0.1335 - val_loss: 3.2022 - val_acc: 0.1314\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 3.2126 - acc: 0.1350 - val_loss: 3.1912 - val_acc: 0.1298 0s - loss: 3.2149 - a\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 3.2013 - acc: 0.1363 - val_loss: 3.1803 - val_acc: 0.1314\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 3.1896 - acc: 0.1341 - val_loss: 3.1693 - val_acc: 0.1381\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 3.1776 - acc: 0.1359 - val_loss: 3.1583 - val_acc: 0.1314\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 3.1653 - acc: 0.1352 - val_loss: 3.1475 - val_acc: 0.1298\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 175us/step - loss: 3.1535 - acc: 0.1346 - val_loss: 3.1352 - val_acc: 0.1314s - loss: 3.1591 - acc:\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 3.1423 - acc: 0.1339 - val_loss: 3.1216 - val_acc: 0.1364\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 3.1317 - acc: 0.1317 - val_loss: 3.1079 - val_acc: 0.1364\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 3.1220 - acc: 0.1293 - val_loss: 3.0938 - val_acc: 0.1364\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 3.1127 - acc: 0.1289 - val_loss: 3.0804 - val_acc: 0.1364\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 3.1038 - acc: 0.1289 - val_loss: 3.0684 - val_acc: 0.1398\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 3.0951 - acc: 0.1280 - val_loss: 3.0576 - val_acc: 0.1398\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 3.0861 - acc: 0.1278 - val_loss: 3.0487 - val_acc: 0.1364\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 3.0774 - acc: 0.1270 - val_loss: 3.0406 - val_acc: 0.1398\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 3.0691 - acc: 0.1263 - val_loss: 3.0324 - val_acc: 0.1381\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 3.0610 - acc: 0.1256 - val_loss: 3.0241 - val_acc: 0.1364\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 3.0529 - acc: 0.1248 - val_loss: 3.0162 - val_acc: 0.1364\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 3.0453 - acc: 0.1241 - val_loss: 3.0094 - val_acc: 0.1331\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 3.0384 - acc: 0.1233 - val_loss: 3.0034 - val_acc: 0.1331loss: 3.0364 - acc: 0.12\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 3.0319 - acc: 0.1237 - val_loss: 2.9977 - val_acc: 0.1331\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 3.0256 - acc: 0.1233 - val_loss: 2.9920 - val_acc: 0.1314\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 3.0193 - acc: 0.1232 - val_loss: 2.9861 - val_acc: 0.1298\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 3.0129 - acc: 0.1228 - val_loss: 2.9803 - val_acc: 0.1314\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 3.0068 - acc: 0.1226 - val_loss: 2.9747 - val_acc: 0.1281\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 3.0011 - acc: 0.1222 - val_loss: 2.9692 - val_acc: 0.1248\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.9953 - acc: 0.1215 - val_loss: 2.9639 - val_acc: 0.1215\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.9896 - acc: 0.1209 - val_loss: 2.9586 - val_acc: 0.1198\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 2.9838 - acc: 0.1207 - val_loss: 2.9533 - val_acc: 0.1198\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 2.9777 - acc: 0.1195 - val_loss: 2.9482 - val_acc: 0.1181\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 2.9718 - acc: 0.1183 - val_loss: 2.9429 - val_acc: 0.1181\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 2.9658 - acc: 0.1185 - val_loss: 2.9373 - val_acc: 0.1181\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.9597 - acc: 0.1187 - val_loss: 2.9312 - val_acc: 0.1181\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 2.9535 - acc: 0.1189 - val_loss: 2.9250 - val_acc: 0.1181\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 2.9474 - acc: 0.1193 - val_loss: 2.9189 - val_acc: 0.1181\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 201us/step - loss: 2.9415 - acc: 0.1187 - val_loss: 2.9130 - val_acc: 0.1181\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 2.9357 - acc: 0.1183 - val_loss: 2.9072 - val_acc: 0.1181\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.9301 - acc: 0.1182 - val_loss: 2.9014 - val_acc: 0.11810s - loss: 2.9216 - acc\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 2.9245 - acc: 0.1176 - val_loss: 2.8958 - val_acc: 0.1181\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 2.9187 - acc: 0.1176 - val_loss: 2.8901 - val_acc: 0.1181\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 2.9129 - acc: 0.1174 - val_loss: 2.8844 - val_acc: 0.1181\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 2.9070 - acc: 0.1169 - val_loss: 2.8788 - val_acc: 0.1181\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 2.9012 - acc: 0.1167 - val_loss: 2.8733 - val_acc: 0.1181\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.8956 - acc: 0.1167 - val_loss: 2.8681 - val_acc: 0.1181\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.8903 - acc: 0.1165 - val_loss: 2.8629 - val_acc: 0.1181\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.8849 - acc: 0.1161 - val_loss: 2.8578 - val_acc: 0.1181\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 2.8795 - acc: 0.1161 - val_loss: 2.8529 - val_acc: 0.1181\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.8742 - acc: 0.1154 - val_loss: 2.8481 - val_acc: 0.1181\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 2.8689 - acc: 0.1156 - val_loss: 2.8431 - val_acc: 0.1181\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 2.8634 - acc: 0.1158 - val_loss: 2.8381 - val_acc: 0.1181\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 2.8582 - acc: 0.1158 - val_loss: 2.8329 - val_acc: 0.1181\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 2.8531 - acc: 0.1158 - val_loss: 2.8275 - val_acc: 0.1181\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 2.8483 - acc: 0.1158 - val_loss: 2.8221 - val_acc: 0.1181\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 2.8436 - acc: 0.1158 - val_loss: 2.8168 - val_acc: 0.1181\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 2.8391 - acc: 0.1159 - val_loss: 2.8119 - val_acc: 0.1181\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 2.8345 - acc: 0.1159 - val_loss: 2.8072 - val_acc: 0.1181\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 2.8300 - acc: 0.1159 - val_loss: 2.8027 - val_acc: 0.1181\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 2.8255 - acc: 0.1159 - val_loss: 2.7985 - val_acc: 0.1181\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 2.8213 - acc: 0.1161 - val_loss: 2.7944 - val_acc: 0.1181\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 2.8173 - acc: 0.1159 - val_loss: 2.7902 - val_acc: 0.1181\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 2.8134 - acc: 0.1159 - val_loss: 2.7860 - val_acc: 0.1181\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 2.8095 - acc: 0.1159 - val_loss: 2.7818 - val_acc: 0.1181\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 2.8058 - acc: 0.1159 - val_loss: 2.7776 - val_acc: 0.1181\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 174us/step - loss: 2.8021 - acc: 0.1159 - val_loss: 2.7734 - val_acc: 0.1181\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 2.7985 - acc: 0.1163 - val_loss: 2.7694 - val_acc: 0.1181\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 2.7950 - acc: 0.1163 - val_loss: 2.7657 - val_acc: 0.1181\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 2.7915 - acc: 0.1161 - val_loss: 2.7622 - val_acc: 0.1181\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 2.7880 - acc: 0.1161 - val_loss: 2.7588 - val_acc: 0.1181\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 2.7845 - acc: 0.1161 - val_loss: 2.7555 - val_acc: 0.1181\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 2.7810 - acc: 0.1161 - val_loss: 2.7523 - val_acc: 0.1181\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 2.7776 - acc: 0.1161 - val_loss: 2.7490 - val_acc: 0.1181\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 2.7742 - acc: 0.1161 - val_loss: 2.7458 - val_acc: 0.1181\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 2.7709 - acc: 0.1161 - val_loss: 2.7426 - val_acc: 0.1181\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.7677 - acc: 0.1161 - val_loss: 2.7393 - val_acc: 0.1181\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 2.7646 - acc: 0.1161 - val_loss: 2.7360 - val_acc: 0.1181 0s - loss: 2.7671 - acc: 0\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 2.7614 - acc: 0.1159 - val_loss: 2.7328 - val_acc: 0.1181\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 2.7584 - acc: 0.1156 - val_loss: 2.7295 - val_acc: 0.1181\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 2.7553 - acc: 0.1156 - val_loss: 2.7264 - val_acc: 0.1181\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 2.7524 - acc: 0.1154 - val_loss: 2.7233 - val_acc: 0.1181\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 2.7494 - acc: 0.1154 - val_loss: 2.7202 - val_acc: 0.1165\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 2.7464 - acc: 0.1154 - val_loss: 2.7172 - val_acc: 0.1165\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 2.7434 - acc: 0.1154 - val_loss: 2.7142 - val_acc: 0.1165\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 2.7405 - acc: 0.1156 - val_loss: 2.7112 - val_acc: 0.1165\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 2.7376 - acc: 0.1154 - val_loss: 2.7083 - val_acc: 0.1165\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.7348 - acc: 0.1154 - val_loss: 2.7054 - val_acc: 0.1165\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.7319 - acc: 0.1154 - val_loss: 2.7025 - val_acc: 0.1165\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 2.7304 - acc: 0.114 - 1s 191us/step - loss: 2.7291 - acc: 0.1154 - val_loss: 2.6995 - val_acc: 0.1165\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 2.7263 - acc: 0.1154 - val_loss: 2.6967 - val_acc: 0.1165\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 2.7235 - acc: 0.1154 - val_loss: 2.6939 - val_acc: 0.1165\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 2.7208 - acc: 0.1154 - val_loss: 2.6911 - val_acc: 0.1165oss: 2.7190 - acc: 0.115\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 2.7181 - acc: 0.1154 - val_loss: 2.6884 - val_acc: 0.1165\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 2.7154 - acc: 0.1154 - val_loss: 2.6857 - val_acc: 0.1165\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 2.7127 - acc: 0.1154 - val_loss: 2.6830 - val_acc: 0.1165\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 185us/step - loss: 2.7101 - acc: 0.1154 - val_loss: 2.6804 - val_acc: 0.1148\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 2.7075 - acc: 0.1152 - val_loss: 2.6778 - val_acc: 0.1148\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 2.7048 - acc: 0.1152 - val_loss: 2.6752 - val_acc: 0.1131\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 2.7022 - acc: 0.1152 - val_loss: 2.6727 - val_acc: 0.1131\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 2.6997 - acc: 0.1152 - val_loss: 2.6702 - val_acc: 0.1131\n",
      "5408/5408 [==============================] - 1s 184us/step\n",
      "4006/4006 [==============================] - 1s 180us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1e-05\n",
      "regularization strength lambda =  1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 2ms/step - loss: 46.2567 - acc: 0.1050 - val_loss: 46.2175 - val_acc: 0.0998\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 46.1485 - acc: 0.1124 - val_loss: 46.1091 - val_acc: 0.1082\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 46.0420 - acc: 0.1198 - val_loss: 45.9995 - val_acc: 0.1314\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 45.9348 - acc: 0.1317 - val_loss: 45.8907 - val_acc: 0.1481\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 45.8277 - acc: 0.1479 - val_loss: 45.7835 - val_acc: 0.1581\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 45.7204 - acc: 0.1644 - val_loss: 45.6778 - val_acc: 0.1681\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 45.6133 - acc: 0.1884 - val_loss: 45.5719 - val_acc: 0.1880\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 45.5061 - acc: 0.2117 - val_loss: 45.4640 - val_acc: 0.2163\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 45.3983 - acc: 0.2374 - val_loss: 45.3580 - val_acc: 0.2413\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 45.2898 - acc: 0.2739 - val_loss: 45.2527 - val_acc: 0.2712\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 45.1802 - acc: 0.3119 - val_loss: 45.1458 - val_acc: 0.2978\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 45.0720 - acc: 0.3469 - val_loss: 45.0403 - val_acc: 0.3328\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 44.9663 - acc: 0.3763 - val_loss: 44.9331 - val_acc: 0.3594\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 44.8613 - acc: 0.4061 - val_loss: 44.8270 - val_acc: 0.3910\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 44.7566 - acc: 0.4332 - val_loss: 44.7209 - val_acc: 0.4176\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 44.6521 - acc: 0.4580 - val_loss: 44.6169 - val_acc: 0.4476\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 44.5495 - acc: 0.4786 - val_loss: 44.5170 - val_acc: 0.4592\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 44.4488 - acc: 0.4920 - val_loss: 44.4180 - val_acc: 0.4859\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 44.3487 - acc: 0.5083 - val_loss: 44.3191 - val_acc: 0.5008\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 44.2495 - acc: 0.5235 - val_loss: 44.2196 - val_acc: 0.5175\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 44.1505 - acc: 0.5379 - val_loss: 44.1205 - val_acc: 0.5324\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 44.0519 - acc: 0.5492 - val_loss: 44.0211 - val_acc: 0.5424\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 43.9531 - acc: 0.5608 - val_loss: 43.9219 - val_acc: 0.5507\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 43.8550 - acc: 0.5756 - val_loss: 43.8233 - val_acc: 0.5724\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 43.7578 - acc: 0.5836 - val_loss: 43.7253 - val_acc: 0.5890\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 43.6612 - acc: 0.5913 - val_loss: 43.6283 - val_acc: 0.5957\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 43.5653 - acc: 0.6004 - val_loss: 43.5323 - val_acc: 0.5990\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 43.4696 - acc: 0.6067 - val_loss: 43.4374 - val_acc: 0.6007\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 43.3744 - acc: 0.6113 - val_loss: 43.3430 - val_acc: 0.6040\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 43.2797 - acc: 0.6174 - val_loss: 43.2491 - val_acc: 0.6123 loss:\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 43.1854 - acc: 0.6243 - val_loss: 43.1558 - val_acc: 0.6156\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 43.0917 - acc: 0.6270 - val_loss: 43.0629 - val_acc: 0.6173\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 42.9983 - acc: 0.6293 - val_loss: 42.9705 - val_acc: 0.6156\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 42.9053 - acc: 0.6333 - val_loss: 42.8784 - val_acc: 0.6173\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 42.8126 - acc: 0.6350 - val_loss: 42.7866 - val_acc: 0.6190\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 42.7200 - acc: 0.6396 - val_loss: 42.6950 - val_acc: 0.6223\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 42.6278 - acc: 0.6416 - val_loss: 42.6035 - val_acc: 0.6290\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 42.5359 - acc: 0.6424 - val_loss: 42.5120 - val_acc: 0.6290\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 42.4443 - acc: 0.6440 - val_loss: 42.4205 - val_acc: 0.6290\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 42.3529 - acc: 0.6448 - val_loss: 42.3291 - val_acc: 0.6323\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 42.2617 - acc: 0.6463 - val_loss: 42.2376 - val_acc: 0.6373 loss: 42.27\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 42.1707 - acc: 0.6479 - val_loss: 42.1466 - val_acc: 0.6406\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 42.0799 - acc: 0.6490 - val_loss: 42.0557 - val_acc: 0.6439\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 41.9895 - acc: 0.6500 - val_loss: 41.9652 - val_acc: 0.6439\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 41.8992 - acc: 0.6520 - val_loss: 41.8749 - val_acc: 0.6439\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 41.8093 - acc: 0.6531 - val_loss: 41.7849 - val_acc: 0.6489\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 41.7197 - acc: 0.6538 - val_loss: 41.6948 - val_acc: 0.6489\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 41.6301 - acc: 0.6546 - val_loss: 41.6052 - val_acc: 0.6489\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 41.5403 - acc: 0.65 - 1s 186us/step - loss: 41.5409 - acc: 0.6553 - val_loss: 41.5155 - val_acc: 0.6489\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 181us/step - loss: 41.4519 - acc: 0.6557 - val_loss: 41.4263 - val_acc: 0.6489\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 41.3631 - acc: 0.6559 - val_loss: 41.3373 - val_acc: 0.6489\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 41.2746 - acc: 0.6563 - val_loss: 41.2486 - val_acc: 0.6489\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 41.1863 - acc: 0.6563 - val_loss: 41.1600 - val_acc: 0.6489\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 41.0983 - acc: 0.6566 - val_loss: 41.0717 - val_acc: 0.6489\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 41.0104 - acc: 0.6566 - val_loss: 40.9836 - val_acc: 0.6489\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 40.9227 - acc: 0.6566 - val_loss: 40.8955 - val_acc: 0.6489\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 40.8352 - acc: 0.6568 - val_loss: 40.8076 - val_acc: 0.6489\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 40.7479 - acc: 0.6570 - val_loss: 40.7202 - val_acc: 0.6489\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 40.6608 - acc: 0.6572 - val_loss: 40.6329 - val_acc: 0.6489\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 40.5740 - acc: 0.6575 - val_loss: 40.5457 - val_acc: 0.6489\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 40.4872 - acc: 0.6575 - val_loss: 40.4587 - val_acc: 0.6506\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 40.4007 - acc: 0.6577 - val_loss: 40.3719 - val_acc: 0.6506\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 40.3143 - acc: 0.6579 - val_loss: 40.2854 - val_acc: 0.6522\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 40.2281 - acc: 0.6581 - val_loss: 40.1991 - val_acc: 0.6539\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 40.1422 - acc: 0.6587 - val_loss: 40.1130 - val_acc: 0.6539\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 40.0564 - acc: 0.6598 - val_loss: 40.0271 - val_acc: 0.6556\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 39.9708 - acc: 0.6603 - val_loss: 39.9414 - val_acc: 0.6556\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 39.8855 - acc: 0.66 - 1s 183us/step - loss: 39.8855 - acc: 0.6609 - val_loss: 39.8559 - val_acc: 0.6556\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 39.8003 - acc: 0.6611 - val_loss: 39.7706 - val_acc: 0.6556\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 39.7154 - acc: 0.6611 - val_loss: 39.6855 - val_acc: 0.6556\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 39.6306 - acc: 0.6611 - val_loss: 39.6006 - val_acc: 0.6556\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 39.5461 - acc: 0.6614 - val_loss: 39.5160 - val_acc: 0.6556\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 39.4618 - acc: 0.6620 - val_loss: 39.4315 - val_acc: 0.6556\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 39.3776 - acc: 0.6622 - val_loss: 39.3473 - val_acc: 0.6556\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 39.2937 - acc: 0.6624 - val_loss: 39.2633 - val_acc: 0.6556\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 39.2100 - acc: 0.6624 - val_loss: 39.1795 - val_acc: 0.6556\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 39.1264 - acc: 0.6624 - val_loss: 39.0958 - val_acc: 0.6556\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 39.0430 - acc: 0.6625 - val_loss: 39.0124 - val_acc: 0.6556\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 38.9599 - acc: 0.6627 - val_loss: 38.9292 - val_acc: 0.6556\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 38.8769 - acc: 0.6627 - val_loss: 38.8460 - val_acc: 0.6556\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 38.7941 - acc: 0.6631 - val_loss: 38.7631 - val_acc: 0.6556\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 38.7115 - acc: 0.6633 - val_loss: 38.6802 - val_acc: 0.6556\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 38.6291 - acc: 0.6635 - val_loss: 38.5978 - val_acc: 0.6556\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 38.5469 - acc: 0.6635 - val_loss: 38.5155 - val_acc: 0.6556\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 38.4649 - acc: 0.6635 - val_loss: 38.4334 - val_acc: 0.6556\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 38.3831 - acc: 0.6635 - val_loss: 38.3515 - val_acc: 0.6556\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 38.3015 - acc: 0.6635 - val_loss: 38.2698 - val_acc: 0.6556\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 38.2201 - acc: 0.6635 - val_loss: 38.1883 - val_acc: 0.6556\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 38.1388 - acc: 0.6635 - val_loss: 38.1070 - val_acc: 0.6556\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 38.0578 - acc: 0.6636 - val_loss: 38.0259 - val_acc: 0.6556\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 37.9769 - acc: 0.6636 - val_loss: 37.9450 - val_acc: 0.6556\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 37.8962 - acc: 0.6636 - val_loss: 37.8642 - val_acc: 0.6556\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 37.8156 - acc: 0.6640 - val_loss: 37.7837 - val_acc: 0.6556\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 37.7353 - acc: 0.6638 - val_loss: 37.7033 - val_acc: 0.6556\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 37.6551 - acc: 0.6640 - val_loss: 37.6232 - val_acc: 0.6556\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 37.5751 - acc: 0.6640 - val_loss: 37.5432 - val_acc: 0.6556\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 37.4953 - acc: 0.6640 - val_loss: 37.4634 - val_acc: 0.6556\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 37.4157 - acc: 0.6640 - val_loss: 37.3838 - val_acc: 0.6556\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 37.3362 - acc: 0.6640 - val_loss: 37.3044 - val_acc: 0.6556\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 37.2570 - acc: 0.6640 - val_loss: 37.2251 - val_acc: 0.6556\n",
      "5408/5408 [==============================] - 1s 189us/step\n",
      "4006/4006 [==============================] - 1s 192us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.0001\n",
      "regularization strength lambda =  1e-05\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 2ms/step - loss: 2.1124 - acc: 0.0501 - val_loss: 2.0892 - val_acc: 0.0582\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 2.0525 - acc: 0.0503 - val_loss: 2.0473 - val_acc: 0.0582\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 2.0106 - acc: 0.0503 - val_loss: 2.0104 - val_acc: 0.0582\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.9779 - acc: 0.0503 - val_loss: 1.9801 - val_acc: 0.0582\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.9496 - acc: 0.0503 - val_loss: 1.9524 - val_acc: 0.0582\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.9230 - acc: 0.0503 - val_loss: 1.9273 - val_acc: 0.0582\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.8981 - acc: 0.0503 - val_loss: 1.9039 - val_acc: 0.0582\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.8748 - acc: 0.0503 - val_loss: 1.8825 - val_acc: 0.0582\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.8529 - acc: 0.0503 - val_loss: 1.8621 - val_acc: 0.0582\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.8322 - acc: 0.0503 - val_loss: 1.8432 - val_acc: 0.0582\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.8128 - acc: 0.0503 - val_loss: 1.8252 - val_acc: 0.0582\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7942 - acc: 0.0503 - val_loss: 1.8079 - val_acc: 0.0582\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.7765 - acc: 0.0503 - val_loss: 1.7914 - val_acc: 0.0582\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.7595 - acc: 0.0503 - val_loss: 1.7756 - val_acc: 0.0582\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.7433 - acc: 0.0503 - val_loss: 1.7604 - val_acc: 0.0582\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.7277 - acc: 0.2835 - val_loss: 1.7458 - val_acc: 0.5990\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.7129 - acc: 0.6019 - val_loss: 1.7317 - val_acc: 0.6040\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.6986 - acc: 0.6187 - val_loss: 1.7181 - val_acc: 0.6173\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.6849 - acc: 0.6551 - val_loss: 1.7049 - val_acc: 0.6506\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.6717 - acc: 0.6616 - val_loss: 1.6923 - val_acc: 0.6522\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.6591 - acc: 0.6622 - val_loss: 1.6800 - val_acc: 0.6539\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.6469 - acc: 0.6638 - val_loss: 1.6682 - val_acc: 0.6539\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.6352 - acc: 0.6638 - val_loss: 1.6569 - val_acc: 0.6539\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.6239 - acc: 0.6640 - val_loss: 1.6460 - val_acc: 0.6539\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.6130 - acc: 0.6644 - val_loss: 1.6355 - val_acc: 0.6539\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.6026 - acc: 0.6646 - val_loss: 1.6256 - val_acc: 0.6556\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5927 - acc: 0.6646 - val_loss: 1.6160 - val_acc: 0.6556\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.5831 - acc: 0.6648 - val_loss: 1.6068 - val_acc: 0.6556\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.5738 - acc: 0.6649 - val_loss: 1.5979 - val_acc: 0.6556\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5649 - acc: 0.6651 - val_loss: 1.5893 - val_acc: 0.6556\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.5563 - acc: 0.6651 - val_loss: 1.5810 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.5481 - acc: 0.6653 - val_loss: 1.5731 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5402 - acc: 0.6651 - val_loss: 1.5655 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5327 - acc: 0.6655 - val_loss: 1.5582 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.5254 - acc: 0.6661 - val_loss: 1.5512 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.5184 - acc: 0.6662 - val_loss: 1.5443 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 1.5115 - acc: 0.6662 - val_loss: 1.5377 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 1.5049 - acc: 0.6664 - val_loss: 1.5314 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4985 - acc: 0.6670 - val_loss: 1.5252 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.4924 - acc: 0.6675 - val_loss: 1.5193 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.4865 - acc: 0.6677 - val_loss: 1.5136 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.4807 - acc: 0.6679 - val_loss: 1.5081 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.4752 - acc: 0.6679 - val_loss: 1.5028 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.4698 - acc: 0.6681 - val_loss: 1.4976 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.4647 - acc: 0.6681 - val_loss: 1.4927 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.4597 - acc: 0.6683 - val_loss: 1.4879 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.4548 - acc: 0.6683 - val_loss: 1.4832 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.4502 - acc: 0.6683 - val_loss: 1.4787 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4456 - acc: 0.6683 - val_loss: 1.4743 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4412 - acc: 0.6683 - val_loss: 1.4701 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.4369 - acc: 0.668 - 1s 179us/step - loss: 1.4370 - acc: 0.6683 - val_loss: 1.4660 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.4328 - acc: 0.6686 - val_loss: 1.4620 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.4288 - acc: 0.6686 - val_loss: 1.4582 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.4249 - acc: 0.6686 - val_loss: 1.4544 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.4211 - acc: 0.6686 - val_loss: 1.4508 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.4175 - acc: 0.6686 - val_loss: 1.4473 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.4139 - acc: 0.6686 - val_loss: 1.4438 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.4105 - acc: 0.6686 - val_loss: 1.4404 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4071 - acc: 0.6686 - val_loss: 1.4372 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.4038 - acc: 0.6686 - val_loss: 1.4340 - val_acc: 0.6572 loss: 1.4011 - acc: \n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.4006 - acc: 0.6686 - val_loss: 1.4308 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3974 - acc: 0.6686 - val_loss: 1.4278 - val_acc: 0.6572\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.3944 - acc: 0.6686 - val_loss: 1.4248 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.3914 - acc: 0.6686 - val_loss: 1.4219 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.3885 - acc: 0.6686 - val_loss: 1.4191 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.3856 - acc: 0.6686 - val_loss: 1.4163 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3828 - acc: 0.6686 - val_loss: 1.4136 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.3802 - acc: 0.6686 - val_loss: 1.4110 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3775 - acc: 0.6686 - val_loss: 1.4084 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.3749 - acc: 0.6686 - val_loss: 1.4059 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.3724 - acc: 0.6686 - val_loss: 1.4034 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 1.3699 - acc: 0.6686 - val_loss: 1.4009 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.3675 - acc: 0.6686 - val_loss: 1.3985 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.3651 - acc: 0.6686 - val_loss: 1.3962 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.3628 - acc: 0.6686 - val_loss: 1.3939 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3605 - acc: 0.6686 - val_loss: 1.3916 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.3583 - acc: 0.6686 - val_loss: 1.3894 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.3561 - acc: 0.6686 - val_loss: 1.3872 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.3539 - acc: 0.6686 - val_loss: 1.3851 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.3518 - acc: 0.6686 - val_loss: 1.3830 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.3497 - acc: 0.6686 - val_loss: 1.3809 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.3477 - acc: 0.6686 - val_loss: 1.3789 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 177us/step - loss: 1.3457 - acc: 0.6686 - val_loss: 1.3769 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.3438 - acc: 0.6686 - val_loss: 1.3750 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.3419 - acc: 0.6686 - val_loss: 1.3730 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.3400 - acc: 0.6686 - val_loss: 1.3711 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3381 - acc: 0.6686 - val_loss: 1.3692 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.3362 - acc: 0.6686 - val_loss: 1.3674 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.3344 - acc: 0.6686 - val_loss: 1.3655 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3326 - acc: 0.6686 - val_loss: 1.3637 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.3309 - acc: 0.6686 - val_loss: 1.3620 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.3292 - acc: 0.6686 - val_loss: 1.3602 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3275 - acc: 0.6686 - val_loss: 1.3585 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.3258 - acc: 0.6686 - val_loss: 1.3568 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.3242 - acc: 0.6686 - val_loss: 1.3552 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.3225 - acc: 0.6686 - val_loss: 1.3535 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3209 - acc: 0.6686 - val_loss: 1.3519 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3193 - acc: 0.6686 - val_loss: 1.3503 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.3178 - acc: 0.6686 - val_loss: 1.3487 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.3162 - acc: 0.6686 - val_loss: 1.3471 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 220us/step\n",
      "4006/4006 [==============================] - 1s 207us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.0001\n",
      "regularization strength lambda =  0.0001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 2ms/step - loss: 1.9661 - acc: 0.0435 - val_loss: 1.9090 - val_acc: 0.0366\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.8904 - acc: 0.0438 - val_loss: 1.8727 - val_acc: 0.0383\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.8624 - acc: 0.0431 - val_loss: 1.8501 - val_acc: 0.0466\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.8405 - acc: 0.0538 - val_loss: 1.8313 - val_acc: 0.0649\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.8220 - acc: 0.4247 - val_loss: 1.8135 - val_acc: 0.5874\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.8048 - acc: 0.5888 - val_loss: 1.7962 - val_acc: 0.5973\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7884 - acc: 0.5984 - val_loss: 1.7794 - val_acc: 0.6073\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.7723 - acc: 0.6052 - val_loss: 1.7635 - val_acc: 0.6190\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.7567 - acc: 0.6109- ETA: 0s - loss: 1.7597 - acc:  - 1s 181us/step - loss: 1.7567 - acc: 0.6108 - val_loss: 1.7483 - val_acc: 0.6190\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 176us/step - loss: 1.7416 - acc: 0.6191 - val_loss: 1.7337 - val_acc: 0.6256\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.7270 - acc: 0.6265 - val_loss: 1.7195 - val_acc: 0.6373\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.7127 - acc: 0.6331 - val_loss: 1.7057 - val_acc: 0.6456\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.6987 - acc: 0.6500 - val_loss: 1.6921 - val_acc: 0.6456\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.6849 - acc: 0.6513 - val_loss: 1.6788 - val_acc: 0.6489\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.6715 - acc: 0.6542 - val_loss: 1.6657 - val_acc: 0.6506\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.6582 - acc: 0.6568 - val_loss: 1.6533 - val_acc: 0.6539\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.6454 - acc: 0.6575 - val_loss: 1.6412 - val_acc: 0.6539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.6329 - acc: 0.6577 - val_loss: 1.6295 - val_acc: 0.6539\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.6208 - acc: 0.6581 - val_loss: 1.6181 - val_acc: 0.6522\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.6091 - acc: 0.6598 - val_loss: 1.6070 - val_acc: 0.6522\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.5978 - acc: 0.6605 - val_loss: 1.5961 - val_acc: 0.6522\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.5867 - acc: 0.6607 - val_loss: 1.5855 - val_acc: 0.6522\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.5759 - acc: 0.6607 - val_loss: 1.5752 - val_acc: 0.6522\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5655 - acc: 0.6611 - val_loss: 1.5652 - val_acc: 0.6522\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.5554 - acc: 0.6614 - val_loss: 1.5553 - val_acc: 0.6522\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5454 - acc: 0.6614 - val_loss: 1.5457 - val_acc: 0.6522\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.5356 - acc: 0.6614 - val_loss: 1.5362 - val_acc: 0.6522\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.5259 - acc: 0.6616 - val_loss: 1.5270 - val_acc: 0.6522\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.5166 - acc: 0.6624 - val_loss: 1.5182 - val_acc: 0.6522\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.5076 - acc: 0.6636 - val_loss: 1.5095 - val_acc: 0.6522\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.4988 - acc: 0.6651 - val_loss: 1.5009 - val_acc: 0.6522\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.4903 - acc: 0.6653 - val_loss: 1.4924 - val_acc: 0.6522\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.4818 - acc: 0.6657 - val_loss: 1.4842 - val_acc: 0.6539\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.4736 - acc: 0.6657 - val_loss: 1.4763 - val_acc: 0.6539\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.4657 - acc: 0.6661 - val_loss: 1.4686 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.4580 - acc: 0.6666 - val_loss: 1.4612 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4505 - acc: 0.6670 - val_loss: 1.4541 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4433 - acc: 0.6673 - val_loss: 1.4472 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.4363 - acc: 0.6673 - val_loss: 1.4405 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4296 - acc: 0.6675 - val_loss: 1.4341 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.4230 - acc: 0.6675 - val_loss: 1.4277 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.4166 - acc: 0.6675 - val_loss: 1.4216 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.4104 - acc: 0.6677 - val_loss: 1.4156 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.4044 - acc: 0.6677 - val_loss: 1.4098 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.3977 - acc: 0.6681- ETA: 0s - loss: 1.4142 - ac - 1s 203us/step - loss: 1.3985 - acc: 0.6677 - val_loss: 1.4042 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3928 - acc: 0.6675 - val_loss: 1.3987 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.3873 - acc: 0.6675 - val_loss: 1.3933 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.3818 - acc: 0.6675 - val_loss: 1.3881 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.3765 - acc: 0.6675 - val_loss: 1.3830 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3714 - acc: 0.6675 - val_loss: 1.3781 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3664 - acc: 0.6675 - val_loss: 1.3732 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.3615 - acc: 0.6675 - val_loss: 1.3685 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.3568 - acc: 0.6677 - val_loss: 1.3641 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.3522 - acc: 0.6677 - val_loss: 1.3597 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.3478 - acc: 0.6683 - val_loss: 1.3555 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.3435 - acc: 0.6683 - val_loss: 1.3514 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.3394 - acc: 0.6683 - val_loss: 1.3474 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.3353 - acc: 0.6683 - val_loss: 1.3434 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.3313 - acc: 0.6683 - val_loss: 1.3396 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.3274 - acc: 0.6683 - val_loss: 1.3360 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3237 - acc: 0.6683 - val_loss: 1.3324 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.3200 - acc: 0.6683 - val_loss: 1.3289 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.3165 - acc: 0.6683 - val_loss: 1.3256 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3131 - acc: 0.6683 - val_loss: 1.3223 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.3097 - acc: 0.6683 - val_loss: 1.3192 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.3065 - acc: 0.6683 - val_loss: 1.3162 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.3033 - acc: 0.6683 - val_loss: 1.3132 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3003 - acc: 0.6683 - val_loss: 1.3103 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.2973 - acc: 0.6683 - val_loss: 1.3075 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2944 - acc: 0.6685 - val_loss: 1.3048 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.2916 - acc: 0.6685 - val_loss: 1.3022 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.2889 - acc: 0.6683 - val_loss: 1.2996 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.2863 - acc: 0.6685 - val_loss: 1.2970 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2836 - acc: 0.6685 - val_loss: 1.2946 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2811 - acc: 0.6683 - val_loss: 1.2922 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.2786 - acc: 0.6685 - val_loss: 1.2899 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2763 - acc: 0.6685 - val_loss: 1.2878 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2739 - acc: 0.6685 - val_loss: 1.2857 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.2717 - acc: 0.6685 - val_loss: 1.2835 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.2695 - acc: 0.6685 - val_loss: 1.2815 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.2674 - acc: 0.6685 - val_loss: 1.2794 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2653 - acc: 0.6685 - val_loss: 1.2775 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2633 - acc: 0.6685 - val_loss: 1.2756 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2613 - acc: 0.6685 - val_loss: 1.2737 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2594 - acc: 0.6685 - val_loss: 1.2719 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.2575 - acc: 0.6685 - val_loss: 1.2702 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2557 - acc: 0.6685 - val_loss: 1.2690 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.2540 - acc: 0.6683 - val_loss: 1.2672 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2522 - acc: 0.6683 - val_loss: 1.2661 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.2506 - acc: 0.6683 - val_loss: 1.2642 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.2489 - acc: 0.6683 - val_loss: 1.2625 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.2473 - acc: 0.6685 - val_loss: 1.2610 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.2457 - acc: 0.6685 - val_loss: 1.2594 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2441 - acc: 0.6685 - val_loss: 1.2575 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.2426 - acc: 0.6685 - val_loss: 1.2561 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.2412 - acc: 0.6685 - val_loss: 1.2548 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.2397 - acc: 0.6685 - val_loss: 1.2535 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.2383 - acc: 0.6685 - val_loss: 1.2522 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.2370 - acc: 0.6685 - val_loss: 1.2510 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.2357 - acc: 0.6685 - val_loss: 1.2498 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 197us/step\n",
      "4006/4006 [==============================] - 1s 196us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.0001\n",
      "regularization strength lambda =  0.001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 2ms/step - loss: 1.7595 - acc: 0.3617 - val_loss: 1.7262 - val_acc: 0.4626\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.6765 - acc: 0.5218 - val_loss: 1.6397 - val_acc: 0.5641\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.5873 - acc: 0.6071 - val_loss: 1.5601 - val_acc: 0.6156\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.5175 - acc: 0.6372 - val_loss: 1.5233 - val_acc: 0.6306\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.4814 - acc: 0.6437 - val_loss: 1.5054 - val_acc: 0.6406\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.4667 - acc: 0.6472 - val_loss: 1.4936 - val_acc: 0.6439\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4560 - acc: 0.6516 - val_loss: 1.4832 - val_acc: 0.6456\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.4458 - acc: 0.6551 - val_loss: 1.4730 - val_acc: 0.6489\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4365 - acc: 0.6579 - val_loss: 1.4638 - val_acc: 0.6506\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.4272 - acc: 0.6599 - val_loss: 1.4547 - val_acc: 0.6522\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4182 - acc: 0.6620 - val_loss: 1.4463 - val_acc: 0.6556\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4100 - acc: 0.6629 - val_loss: 1.4381 - val_acc: 0.6539\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4025 - acc: 0.6642 - val_loss: 1.4305 - val_acc: 0.6539\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.3950 - acc: 0.6662 - val_loss: 1.4236 - val_acc: 0.6556\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3878 - acc: 0.6659 - val_loss: 1.4155 - val_acc: 0.6556\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3809 - acc: 0.6672 - val_loss: 1.4089 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.3745 - acc: 0.6673 - val_loss: 1.4030 - val_acc: 0.6556\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3683 - acc: 0.6690 - val_loss: 1.3968 - val_acc: 0.6606\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.3622 - acc: 0.6675 - val_loss: 1.3918 - val_acc: 0.6606\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.3564 - acc: 0.6677 - val_loss: 1.3841 - val_acc: 0.6589\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.3507 - acc: 0.6661 - val_loss: 1.3810 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3453 - acc: 0.6675 - val_loss: 1.3752 - val_acc: 0.6556\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.3399 - acc: 0.6673 - val_loss: 1.3705 - val_acc: 0.6539\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.3348 - acc: 0.6673 - val_loss: 1.3654 - val_acc: 0.6556\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3301 - acc: 0.6683 - val_loss: 1.3613 - val_acc: 0.6556\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3254 - acc: 0.6672 - val_loss: 1.3567 - val_acc: 0.6556\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.3211 - acc: 0.6673 - val_loss: 1.3565 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3167 - acc: 0.6690 - val_loss: 1.3500 - val_acc: 0.6556\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.3123 - acc: 0.6686 - val_loss: 1.3460 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.3085 - acc: 0.6686 - val_loss: 1.3424 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3046 - acc: 0.6686 - val_loss: 1.3392 - val_acc: 0.6572\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3008 - acc: 0.6686 - val_loss: 1.3359 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2972 - acc: 0.6688 - val_loss: 1.3307 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2937 - acc: 0.6685 - val_loss: 1.3284 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2905 - acc: 0.6685 - val_loss: 1.3265 - val_acc: 0.6589\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2875 - acc: 0.6692 - val_loss: 1.3248 - val_acc: 0.6572 0s - loss: 1.2\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2842 - acc: 0.6688 - val_loss: 1.3212 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2808 - acc: 0.6690 - val_loss: 1.3175 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.2779 - acc: 0.6683 - val_loss: 1.3151 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2750 - acc: 0.6685 - val_loss: 1.3132 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.2722 - acc: 0.6688 - val_loss: 1.3111 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.2696 - acc: 0.6690 - val_loss: 1.3082 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.2668 - acc: 0.6690 - val_loss: 1.3069 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.2643 - acc: 0.6688 - val_loss: 1.3051 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.2619 - acc: 0.6690 - val_loss: 1.3029 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2596 - acc: 0.6688 - val_loss: 1.3013 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2571 - acc: 0.6690 - val_loss: 1.2991 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2549 - acc: 0.6690 - val_loss: 1.2976 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.2527 - acc: 0.6688 - val_loss: 1.2971 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.2507 - acc: 0.6688 - val_loss: 1.2945 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.2487 - acc: 0.6688 - val_loss: 1.2915 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2467 - acc: 0.6685 - val_loss: 1.2909 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.2446 - acc: 0.6686 - val_loss: 1.2910 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.2429 - acc: 0.6686 - val_loss: 1.2876 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2410 - acc: 0.6686 - val_loss: 1.2866 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2391 - acc: 0.6686 - val_loss: 1.2851 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2374 - acc: 0.6686 - val_loss: 1.2836 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2356 - acc: 0.6686 - val_loss: 1.2824 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2340 - acc: 0.6688 - val_loss: 1.2809 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2321 - acc: 0.6688 - val_loss: 1.2786 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2301 - acc: 0.6686 - val_loss: 1.2768 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2284 - acc: 0.6686 - val_loss: 1.2761 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2266 - acc: 0.6688 - val_loss: 1.2745 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.2249 - acc: 0.6688 - val_loss: 1.2717 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.2233 - acc: 0.6683 - val_loss: 1.2708 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.2217 - acc: 0.6686 - val_loss: 1.2696 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2199 - acc: 0.6686 - val_loss: 1.2683 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.2185 - acc: 0.6685 - val_loss: 1.2664 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.2168 - acc: 0.6685 - val_loss: 1.2649 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2153 - acc: 0.6686 - val_loss: 1.2622 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2139 - acc: 0.6685 - val_loss: 1.2615 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2124 - acc: 0.6685 - val_loss: 1.2607 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2109 - acc: 0.6686 - val_loss: 1.2590 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2096 - acc: 0.6685 - val_loss: 1.2574 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2081 - acc: 0.6686 - val_loss: 1.2561 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2070 - acc: 0.6686 - val_loss: 1.2547 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2056 - acc: 0.6685 - val_loss: 1.2527 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2042 - acc: 0.6685 - val_loss: 1.2525 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2010 - acc: 0.6685 - val_loss: 1.2484 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1973 - acc: 0.6686 - val_loss: 1.2452 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1950 - acc: 0.6686 - val_loss: 1.2435 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1933 - acc: 0.6686 - val_loss: 1.2416 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1919 - acc: 0.6686 - val_loss: 1.2410 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1903 - acc: 0.6686 - val_loss: 1.2399 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1890 - acc: 0.6685 - val_loss: 1.2370 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1822 - acc: 0.6715- ETA: 0s - loss: 1.1581 -  - 1s 236us/step - loss: 1.1878 - acc: 0.6685 - val_loss: 1.2356 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1864 - acc: 0.6686 - val_loss: 1.2351 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1852 - acc: 0.6685 - val_loss: 1.2334 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1840 - acc: 0.6685 - val_loss: 1.2322 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1828 - acc: 0.6685 - val_loss: 1.2300 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1818 - acc: 0.6685 - val_loss: 1.2295 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1806 - acc: 0.6685 - val_loss: 1.2291 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1797 - acc: 0.6685 - val_loss: 1.2286 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1785 - acc: 0.6685 - val_loss: 1.2265 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1776 - acc: 0.6685 - val_loss: 1.2245 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1766 - acc: 0.6685 - val_loss: 1.2223 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1758 - acc: 0.6685 - val_loss: 1.2230 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1748 - acc: 0.6685 - val_loss: 1.2206 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1741 - acc: 0.6685 - val_loss: 1.2236 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1733 - acc: 0.6685 - val_loss: 1.2195 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 204us/step\n",
      "4006/4006 [==============================] - 1s 212us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.0001\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 8s 2ms/step - loss: 2.3580 - acc: 0.0594 - val_loss: 2.3437 - val_acc: 0.0599\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 2.3280 - acc: 0.0801 - val_loss: 2.3130 - val_acc: 0.0932\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 2.2593 - acc: 0.2093 - val_loss: 2.1707 - val_acc: 0.4260\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 2.1130 - acc: 0.5521 - val_loss: 2.0852 - val_acc: 0.6306\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 2.0673 - acc: 0.6322 - val_loss: 2.0612 - val_acc: 0.6439\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 2.0469 - acc: 0.6433 - val_loss: 2.0424 - val_acc: 0.6456\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 2.0319 - acc: 0.6481 - val_loss: 2.0301 - val_acc: 0.6456\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 2.0192 - acc: 0.6501 - val_loss: 2.0196 - val_acc: 0.6456\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 2.0080 - acc: 0.6527 - val_loss: 2.0092 - val_acc: 0.6456\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.9976 - acc: 0.6540 - val_loss: 1.9992 - val_acc: 0.6473\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.9879 - acc: 0.6568 - val_loss: 1.9898 - val_acc: 0.6506\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.9784 - acc: 0.6588 - val_loss: 1.9804 - val_acc: 0.6522\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.9692 - acc: 0.6614 - val_loss: 1.9714 - val_acc: 0.6539\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.9604 - acc: 0.6629 - val_loss: 1.9628 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.9520 - acc: 0.6640 - val_loss: 1.9546 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.9438 - acc: 0.6681 - val_loss: 1.9467 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.9360 - acc: 0.6681 - val_loss: 1.9391 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.9283 - acc: 0.6681 - val_loss: 1.9317 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.9210 - acc: 0.6683 - val_loss: 1.9246 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.9138 - acc: 0.6683 - val_loss: 1.9176 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.9067 - acc: 0.6683 - val_loss: 1.9109 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.8999 - acc: 0.6683 - val_loss: 1.9044 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.8933 - acc: 0.6685 - val_loss: 1.8981 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.8868 - acc: 0.6685 - val_loss: 1.8919 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.8805 - acc: 0.6685 - val_loss: 1.8860 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.8744 - acc: 0.6686 - val_loss: 1.8802 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.8685 - acc: 0.6686 - val_loss: 1.8746 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.8627 - acc: 0.6686 - val_loss: 1.8690 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.8569 - acc: 0.6686 - val_loss: 1.8637 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.8513 - acc: 0.6686 - val_loss: 1.8586 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.8457 - acc: 0.6686 - val_loss: 1.8537 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.8403 - acc: 0.6686 - val_loss: 1.8488 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.8350 - acc: 0.6686 - val_loss: 1.8441 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.8298 - acc: 0.6686 - val_loss: 1.8392 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.8249 - acc: 0.6686 - val_loss: 1.8343 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.8199 - acc: 0.6686 - val_loss: 1.8296 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.8152 - acc: 0.6686 - val_loss: 1.8250 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.8106 - acc: 0.6686 - val_loss: 1.8205 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.8060 - acc: 0.6686 - val_loss: 1.8161 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.8016 - acc: 0.6686 - val_loss: 1.8119 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.7973 - acc: 0.6686 - val_loss: 1.8077 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.7930 - acc: 0.6686 - val_loss: 1.8036 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.7889 - acc: 0.6686 - val_loss: 1.7996 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.7849 - acc: 0.6686 - val_loss: 1.7957 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.7810 - acc: 0.6686 - val_loss: 1.7919 - val_acc: 0.6572\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.7771 - acc: 0.6686 - val_loss: 1.7882 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.7733 - acc: 0.6686 - val_loss: 1.7845 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.7696 - acc: 0.6686 - val_loss: 1.7809 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.7660 - acc: 0.6686 - val_loss: 1.7774 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.7625 - acc: 0.6686 - val_loss: 1.7740 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.7590 - acc: 0.6686 - val_loss: 1.7707 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.7556 - acc: 0.6686 - val_loss: 1.7673 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.7523 - acc: 0.6686 - val_loss: 1.7642 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.7491 - acc: 0.6686 - val_loss: 1.7611 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7460 - acc: 0.6686 - val_loss: 1.7582 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.7429 - acc: 0.6686 - val_loss: 1.7551 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7398 - acc: 0.6686 - val_loss: 1.7522 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.7369 - acc: 0.6686 - val_loss: 1.7494 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.7340 - acc: 0.6686 - val_loss: 1.7466 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7311 - acc: 0.6686 - val_loss: 1.7439 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.7283 - acc: 0.6686 - val_loss: 1.7412 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.7256 - acc: 0.6686 - val_loss: 1.7387 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7230 - acc: 0.6686 - val_loss: 1.7361 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7204 - acc: 0.6686 - val_loss: 1.7336 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.7179 - acc: 0.6686 - val_loss: 1.7312 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.7154 - acc: 0.6686 - val_loss: 1.7288 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.7130 - acc: 0.6686 - val_loss: 1.7265 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.7106 - acc: 0.6686 - val_loss: 1.7242 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.7083 - acc: 0.6686 - val_loss: 1.7220 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.7060 - acc: 0.6686 - val_loss: 1.7198 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.7037 - acc: 0.6686 - val_loss: 1.7176 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.7015 - acc: 0.6686 - val_loss: 1.7156 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.6994 - acc: 0.6686 - val_loss: 1.7135 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.6972 - acc: 0.6686 - val_loss: 1.7115 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.6952 - acc: 0.6686 - val_loss: 1.7095 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.6931 - acc: 0.6686 - val_loss: 1.7076 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.6911 - acc: 0.6686 - val_loss: 1.7057 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.6892 - acc: 0.6686 - val_loss: 1.7038 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.6873 - acc: 0.6686 - val_loss: 1.7021 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.6854 - acc: 0.6686 - val_loss: 1.7002 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.6836 - acc: 0.6686 - val_loss: 1.6985 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.6818 - acc: 0.6686 - val_loss: 1.6968 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.6800 - acc: 0.6686 - val_loss: 1.6951 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.6783 - acc: 0.6686 - val_loss: 1.6935 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.6766 - acc: 0.6686 - val_loss: 1.6919 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.6749 - acc: 0.6686 - val_loss: 1.6903 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.6733 - acc: 0.6686 - val_loss: 1.6887 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.6717 - acc: 0.6686 - val_loss: 1.6871 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.6701 - acc: 0.6686 - val_loss: 1.6856 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 1.6685 - acc: 0.6686 - val_loss: 1.6842 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.6671 - acc: 0.6686 - val_loss: 1.6827 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.6656 - acc: 0.6686 - val_loss: 1.6813 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.6641 - acc: 0.6686 - val_loss: 1.6799 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.6626 - acc: 0.6686 - val_loss: 1.6786 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.6613 - acc: 0.6686 - val_loss: 1.6772 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.6599 - acc: 0.6686 - val_loss: 1.6759 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.6585 - acc: 0.6686 - val_loss: 1.6746 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.6571 - acc: 0.6686 - val_loss: 1.6733 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.6558 - acc: 0.6686 - val_loss: 1.6720 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.6545 - acc: 0.6686 - val_loss: 1.6708 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 199us/step\n",
      "4006/4006 [==============================] - 1s 197us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.0001\n",
      "regularization strength lambda =  1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 8s 2ms/step - loss: 42.6933 - acc: 0.0501 - val_loss: 42.2026 - val_acc: 0.0582\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 41.7142 - acc: 0.0525 - val_loss: 41.2327 - val_acc: 0.1381\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 40.7702 - acc: 0.2006 - val_loss: 40.3223 - val_acc: 0.2047\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 39.8849 - acc: 0.2777 - val_loss: 39.4570 - val_acc: 0.2812\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 39.0333 - acc: 0.3539 - val_loss: 38.6154 - val_acc: 0.3544\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 38.2026 - acc: 0.4135 - val_loss: 37.7966 - val_acc: 0.4143\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 37.3911 - acc: 0.4604 - val_loss: 36.9965 - val_acc: 0.4642\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 36.5986 - acc: 0.5111 - val_loss: 36.2135 - val_acc: 0.5092\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 35.8250 - acc: 0.5468 - val_loss: 35.4489 - val_acc: 0.5507\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 35.0688 - acc: 0.6444 - val_loss: 34.7015 - val_acc: 0.6456\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 34.3296 - acc: 0.6598 - val_loss: 33.9714 - val_acc: 0.6506\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 33.6074 - acc: 0.6662 - val_loss: 33.2581 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 32.9014 - acc: 0.6679 - val_loss: 32.5604 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 32.2111 - acc: 0.6681 - val_loss: 31.8781 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 31.5362 - acc: 0.6683 - val_loss: 31.2110 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 30.8763 - acc: 0.6683 - val_loss: 30.5587 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 30.2311 - acc: 0.6683 - val_loss: 29.9210 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 29.6005 - acc: 0.6685 - val_loss: 29.2977 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 28.9838 - acc: 0.6685 - val_loss: 28.6881 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 28.3807 - acc: 0.6685 - val_loss: 28.0918 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 27.7910 - acc: 0.6686 - val_loss: 27.5088 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 27.2143 - acc: 0.6686 - val_loss: 26.9387 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 26.6503 - acc: 0.6686 - val_loss: 26.3811 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 26.0988 - acc: 0.6686 - val_loss: 25.8358 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 25.5594 - acc: 0.6686 - val_loss: 25.3024 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 25.0318 - acc: 0.6686 - val_loss: 24.7809 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 24.5160 - acc: 0.6686 - val_loss: 24.2709 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 24.0116 - acc: 0.6686 - val_loss: 23.7720 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 23.5182 - acc: 0.6686 - val_loss: 23.2843 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 23.0356 - acc: 0.6686 - val_loss: 22.8072 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 22.5637 - acc: 0.6686 - val_loss: 22.3407 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 22.1023 - acc: 0.6686 - val_loss: 21.8844 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 21.6508 - acc: 0.6686 - val_loss: 21.4381 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 21.2093 - acc: 0.6686 - val_loss: 21.0017 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 20.7775 - acc: 0.6686 - val_loss: 20.5747 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 20.3552 - acc: 0.6686 - val_loss: 20.1572 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 19.9422 - acc: 0.6686 - val_loss: 19.7489 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 19.5381 - acc: 0.6686 - val_loss: 19.3495 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 19.1444 - acc: 0.67 - 1s 187us/step - loss: 19.1430 - acc: 0.6686 - val_loss: 18.9588 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 18.7565 - acc: 0.6686 - val_loss: 18.5767 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 18.3785 - acc: 0.6686 - val_loss: 18.2029 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 18.0088 - acc: 0.6686 - val_loss: 17.8374 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 17.6471 - acc: 0.6686 - val_loss: 17.4799 - val_acc: 0.6572 loss: 17.7025 -\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 17.2934 - acc: 0.6686 - val_loss: 17.1301 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 16.9474 - acc: 0.6686 - val_loss: 16.7880 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 16.6090 - acc: 0.6686 - val_loss: 16.4534 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 16.2780 - acc: 0.6686 - val_loss: 16.1261 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 15.9542 - acc: 0.6686 - val_loss: 15.8060 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 15.6375 - acc: 0.6686 - val_loss: 15.4929 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 15.3278 - acc: 0.6686 - val_loss: 15.1866 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 15.0248 - acc: 0.6686 - val_loss: 14.8871 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 14.7285 - acc: 0.6686 - val_loss: 14.5941 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 14.4386 - acc: 0.6686 - val_loss: 14.3075 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 14.1551 - acc: 0.6686 - val_loss: 14.0271 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 13.8777 - acc: 0.6686 - val_loss: 13.7529 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 13.6064 - acc: 0.6686 - val_loss: 13.4847 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 13.3411 - acc: 0.6686 - val_loss: 13.2223 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 13.0816 - acc: 0.6686 - val_loss: 12.9657 - val_acc: 0.6572\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 190us/step - loss: 12.8277 - acc: 0.6686 - val_loss: 12.7147 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 12.5794 - acc: 0.6686 - val_loss: 12.4691 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 12.3365 - acc: 0.6686 - val_loss: 12.2289 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 12.0988 - acc: 0.6686 - val_loss: 11.9940 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 11.8664 - acc: 0.6686 - val_loss: 11.7642 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 11.6391 - acc: 0.6686 - val_loss: 11.5394 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 11.4167 - acc: 0.6686 - val_loss: 11.3195 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 11.1991 - acc: 0.6686 - val_loss: 11.1044 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 10.9863 - acc: 0.6686 - val_loss: 10.8940 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 10.7782 - acc: 0.6686 - val_loss: 10.6882 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 10.5746 - acc: 0.6686 - val_loss: 10.4869 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 10.3754 - acc: 0.6686 - val_loss: 10.2899 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 10.1806 - acc: 0.6686 - val_loss: 10.0973 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 9.9900 - acc: 0.6686 - val_loss: 9.9088 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 9.8036 - acc: 0.6686 - val_loss: 9.7245 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 9.6212 - acc: 0.6686 - val_loss: 9.5442 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 9.4428 - acc: 0.6686 - val_loss: 9.3678 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 9.2684 - acc: 0.6686 - val_loss: 9.1953 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 9.0977 - acc: 0.6686 - val_loss: 9.0265 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 8.9307 - acc: 0.6686 - val_loss: 8.8613 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 8.7674 - acc: 0.6686 - val_loss: 8.6998 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 8.6076 - acc: 0.6686 - val_loss: 8.5418 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 8.4513 - acc: 0.6686 - val_loss: 8.3873 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 8.2984 - acc: 0.6686 - val_loss: 8.2361 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 8.1488 - acc: 0.6686 - val_loss: 8.0882 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 8.0026 - acc: 0.6686 - val_loss: 7.9436 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 7.8595 - acc: 0.6686 - val_loss: 7.8021 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 7.7195 - acc: 0.6686 - val_loss: 7.6637 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 7.5826 - acc: 0.6686 - val_loss: 7.5282 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 7.4486 - acc: 0.6686 - val_loss: 7.3958 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 7.3175 - acc: 0.6686 - val_loss: 7.2662 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 7.1894 - acc: 0.6686 - val_loss: 7.1394 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 7.0640 - acc: 0.6686 - val_loss: 7.0155 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 6.9413 - acc: 0.6686 - val_loss: 6.8941 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 6.8213 - acc: 0.6686 - val_loss: 6.7755 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 6.7039 - acc: 0.6686 - val_loss: 6.6594 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 6.5891 - acc: 0.6686 - val_loss: 6.5459 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 6.4768 - acc: 0.6686 - val_loss: 6.4348 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 6.3669 - acc: 0.6686 - val_loss: 6.3261 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 6.2594 - acc: 0.6686 - val_loss: 6.2198 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 6.1543 - acc: 0.6686 - val_loss: 6.1158 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 6.0514 - acc: 0.6686 - val_loss: 6.0141 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 206us/step\n",
      "4006/4006 [==============================] - 1s 197us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.001\n",
      "regularization strength lambda =  1e-05\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 9s 2ms/step - loss: 1.9603 - acc: 0.0115 - val_loss: 1.8838 - val_acc: 0.0100\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.7790 - acc: 0.4273 - val_loss: 1.7438 - val_acc: 0.6240\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.6546 - acc: 0.6487 - val_loss: 1.6363 - val_acc: 0.6522\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.5577 - acc: 0.6646 - val_loss: 1.5527 - val_acc: 0.6522\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4831 - acc: 0.6668 - val_loss: 1.4879 - val_acc: 0.6539\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.4261 - acc: 0.6672 - val_loss: 1.4378 - val_acc: 0.6556\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.3811 - acc: 0.6681 - val_loss: 1.3983 - val_acc: 0.6556\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.3462 - acc: 0.6685 - val_loss: 1.3690 - val_acc: 0.6556\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.3197 - acc: 0.6685 - val_loss: 1.3451 - val_acc: 0.6556\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2982 - acc: 0.6685 - val_loss: 1.3249 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.2807 - acc: 0.6685 - val_loss: 1.3086 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.2666 - acc: 0.6686 - val_loss: 1.2966 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.2551 - acc: 0.6686 - val_loss: 1.2855 - val_acc: 0.6572\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2454 - acc: 0.6686 - val_loss: 1.2759 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2369 - acc: 0.6686 - val_loss: 1.2687 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.2297 - acc: 0.6686 - val_loss: 1.2610 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2233 - acc: 0.6686 - val_loss: 1.2546 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2174 - acc: 0.6686 - val_loss: 1.2470 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2122 - acc: 0.6686 - val_loss: 1.2413 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.2059 - acc: 0.6686 - val_loss: 1.2252 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1985 - acc: 0.6686 - val_loss: 1.2209 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1901 - acc: 0.6686 - val_loss: 1.2012 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1803 - acc: 0.6686 - val_loss: 1.2002 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1749 - acc: 0.6686 - val_loss: 1.1915 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1703 - acc: 0.6686 - val_loss: 1.1870 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1660 - acc: 0.6686 - val_loss: 1.1832 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1618 - acc: 0.6686 - val_loss: 1.1924 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1582 - acc: 0.6686 - val_loss: 1.1734 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1537 - acc: 0.6686 - val_loss: 1.1736 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1510 - acc: 0.6686 - val_loss: 1.1706 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1484 - acc: 0.6686 - val_loss: 1.1631 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1442 - acc: 0.6686 - val_loss: 1.1616 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1418 - acc: 0.6686 - val_loss: 1.1547 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1390 - acc: 0.6686 - val_loss: 1.1519 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1366 - acc: 0.6686 - val_loss: 1.1524 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1331 - acc: 0.6686 - val_loss: 1.1536 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1463 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1296 - acc: 0.6686 - val_loss: 1.1509 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1270 - acc: 0.6686 - val_loss: 1.1398 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1249 - acc: 0.6686 - val_loss: 1.1432 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1229 - acc: 0.6686 - val_loss: 1.1450 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1222 - acc: 0.6686 - val_loss: 1.1324 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1198 - acc: 0.6686 - val_loss: 1.1349 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1174 - acc: 0.6686 - val_loss: 1.1384 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1163 - acc: 0.6686 - val_loss: 1.1273 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1153 - acc: 0.6686 - val_loss: 1.1254 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1128 - acc: 0.6686 - val_loss: 1.1297 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1127 - acc: 0.6686 - val_loss: 1.1217 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1108 - acc: 0.6686 - val_loss: 1.1224 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1093 - acc: 0.6686 - val_loss: 1.1210 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1074 - acc: 0.6686 - val_loss: 1.1197 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1073 - acc: 0.6686 - val_loss: 1.1178 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1050 - acc: 0.6686 - val_loss: 1.1158 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1043 - acc: 0.6686 - val_loss: 1.1251 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1036 - acc: 0.6686 - val_loss: 1.1143 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1015 - acc: 0.6686 - val_loss: 1.1134 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1009 - acc: 0.6686 - val_loss: 1.1144 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0999 - acc: 0.6686 - val_loss: 1.1156 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0991 - acc: 0.6686 - val_loss: 1.1066 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0984 - acc: 0.6686 - val_loss: 1.1054 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0965 - acc: 0.6686 - val_loss: 1.1089 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.0962 - acc: 0.6686 - val_loss: 1.1059 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0947 - acc: 0.6686 - val_loss: 1.1023 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.0934 - acc: 0.6686 - val_loss: 1.1055 - val_acc: 0.65720932 - acc: 0.668\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0927 - acc: 0.6686 - val_loss: 1.1059 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.0923 - acc: 0.6686 - val_loss: 1.0996 - val_acc: 0.6572 0s - loss: 1.0875 - acc: 0.\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0909 - acc: 0.6686 - val_loss: 1.1018 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.0903 - acc: 0.6686 - val_loss: 1.0983 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.0890 - acc: 0.6686 - val_loss: 1.0993 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0882 - acc: 0.6686 - val_loss: 1.1014 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.0879 - acc: 0.6686 - val_loss: 1.0975 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.0866 - acc: 0.6686 - val_loss: 1.1025 - val_acc: 0.6572\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0863 - acc: 0.6686 - val_loss: 1.0947 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.0852 - acc: 0.6686 - val_loss: 1.1007 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.0843 - acc: 0.6686 - val_loss: 1.1003 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0841 - acc: 0.6686 - val_loss: 1.0926 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.0832 - acc: 0.6686 - val_loss: 1.0928 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.0829 - acc: 0.6686 - val_loss: 1.0961 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.0819 - acc: 0.6686 - val_loss: 1.0927 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0821 - acc: 0.6686 - val_loss: 1.0906 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0810 - acc: 0.6686 - val_loss: 1.0899 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0809 - acc: 0.6686 - val_loss: 1.0971 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0804 - acc: 0.6686 - val_loss: 1.0896 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.0789 - acc: 0.6689- ETA: 0s - loss: 1.0874 - acc: 0 - 1s 222us/step - loss: 1.0794 - acc: 0.6686 - val_loss: 1.0909 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0788 - acc: 0.6686 - val_loss: 1.0955 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0779 - acc: 0.6686 - val_loss: 1.0923 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0801 - acc: 0.6686 - val_loss: 1.0927 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0775 - acc: 0.6686 - val_loss: 1.0868 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.0766 - acc: 0.6686 - val_loss: 1.0862 - val_acc: 0.6572s: 1.0889 -\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0755 - acc: 0.6686 - val_loss: 1.0856 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.0757 - acc: 0.6686 - val_loss: 1.0867 - val_acc: 0.6572 - loss: 1.0795 - acc: \n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0752 - acc: 0.6686 - val_loss: 1.0898 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.0751 - acc: 0.6686 - val_loss: 1.0843 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.0741 - acc: 0.6686 - val_loss: 1.0840 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.0739 - acc: 0.6686 - val_loss: 1.0864 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.0737 - acc: 0.6686 - val_loss: 1.0839 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.0734 - acc: 0.6686 - val_loss: 1.0877 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.0733 - acc: 0.6686 - val_loss: 1.0827 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0721 - acc: 0.6686 - val_loss: 1.0856 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.0717 - acc: 0.6686 - val_loss: 1.0861 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 198us/step\n",
      "4006/4006 [==============================] - 1s 200us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.001\n",
      "regularization strength lambda =  0.0001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 9s 2ms/step - loss: 2.1198 - acc: 0.0472 - val_loss: 2.0042 - val_acc: 0.0749\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.8620 - acc: 0.2130 - val_loss: 1.7823 - val_acc: 0.4276\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.6724 - acc: 0.5636 - val_loss: 1.6323 - val_acc: 0.6256\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.5422 - acc: 0.6526 - val_loss: 1.5129 - val_acc: 0.6522\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.4401 - acc: 0.6640 - val_loss: 1.4276 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.3647 - acc: 0.6681 - val_loss: 1.3620 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.3090 - acc: 0.6685 - val_loss: 1.3218 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2663 - acc: 0.6686 - val_loss: 1.2835 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2351 - acc: 0.6686 - val_loss: 1.2555 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2154 - acc: 0.6686 - val_loss: 1.2387 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.2018 - acc: 0.6686 - val_loss: 1.2278 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1921 - acc: 0.6686 - val_loss: 1.2190 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1844 - acc: 0.6686 - val_loss: 1.2114 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1779 - acc: 0.6686 - val_loss: 1.2056 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1733 - acc: 0.6686 - val_loss: 1.2012 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1694 - acc: 0.6686 - val_loss: 1.1975 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1662 - acc: 0.6686 - val_loss: 1.1937 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1633 - acc: 0.6686 - val_loss: 1.1908 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1609 - acc: 0.6686 - val_loss: 1.1878 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1585 - acc: 0.6686 - val_loss: 1.1852 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1565 - acc: 0.6686 - val_loss: 1.1826 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1545 - acc: 0.6686 - val_loss: 1.1802 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1527 - acc: 0.6686 - val_loss: 1.1778 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1511 - acc: 0.6686 - val_loss: 1.1757 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1495 - acc: 0.6686 - val_loss: 1.1734 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1480 - acc: 0.6686 - val_loss: 1.1715 - val_acc: 0.6572\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1467 - acc: 0.6686 - val_loss: 1.1698 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1454 - acc: 0.6686 - val_loss: 1.1681 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1442 - acc: 0.6686 - val_loss: 1.1665 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1432 - acc: 0.6686 - val_loss: 1.1649 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1421 - acc: 0.6686 - val_loss: 1.1635 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.1412 - acc: 0.6686 - val_loss: 1.1622 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1402 - acc: 0.6686 - val_loss: 1.1608 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1394 - acc: 0.6686 - val_loss: 1.1593 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1385 - acc: 0.6686 - val_loss: 1.1582 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1377 - acc: 0.6686 - val_loss: 1.1570 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1369 - acc: 0.6686 - val_loss: 1.1558 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1362 - acc: 0.6686 - val_loss: 1.1548 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1355 - acc: 0.6686 - val_loss: 1.1539 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1348 - acc: 0.6686 - val_loss: 1.1535 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1342 - acc: 0.6686 - val_loss: 1.1526 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1335 - acc: 0.6686 - val_loss: 1.1512 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1505 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1497 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1319 - acc: 0.6686 - val_loss: 1.1490 - val_acc: 0.6572s - loss: 1.1295 - acc: 0.6\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1484 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.1472 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1305 - acc: 0.6686 - val_loss: 1.1474 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1300 - acc: 0.6686 - val_loss: 1.1468 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1296 - acc: 0.6686 - val_loss: 1.1459 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1291 - acc: 0.6686 - val_loss: 1.1454 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1287 - acc: 0.6686 - val_loss: 1.1442 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1283 - acc: 0.6686 - val_loss: 1.1435 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1280 - acc: 0.6686 - val_loss: 1.1436 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1276 - acc: 0.6686 - val_loss: 1.1429 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1420 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1268 - acc: 0.6686 - val_loss: 1.1414 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1265 - acc: 0.6686 - val_loss: 1.1414 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1262 - acc: 0.6686 - val_loss: 1.1406 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1259 - acc: 0.6686 - val_loss: 1.1402 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1256 - acc: 0.6686 - val_loss: 1.1398 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.1253 - acc: 0.6686 - val_loss: 1.1397 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.1250 - acc: 0.6686 - val_loss: 1.1391 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1247 - acc: 0.6686 - val_loss: 1.1385 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1244 - acc: 0.6686 - val_loss: 1.1377 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1241 - acc: 0.6686 - val_loss: 1.1370 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1239 - acc: 0.6686 - val_loss: 1.1373 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1236 - acc: 0.6686 - val_loss: 1.1368 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1233 - acc: 0.6686 - val_loss: 1.1364 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1229 - acc: 0.6686 - val_loss: 1.1355 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1227 - acc: 0.6686 - val_loss: 1.1358 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1224 - acc: 0.6686 - val_loss: 1.1351 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1221 - acc: 0.6686 - val_loss: 1.1349 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1220 - acc: 0.6686 - val_loss: 1.1346 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1217 - acc: 0.6686 - val_loss: 1.1341 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1213 - acc: 0.6686 - val_loss: 1.1334 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1212 - acc: 0.6686 - val_loss: 1.1337 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1210 - acc: 0.6686 - val_loss: 1.1332 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1207 - acc: 0.6686 - val_loss: 1.1326 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1204 - acc: 0.6686 - val_loss: 1.1324 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1202 - acc: 0.6686 - val_loss: 1.1326 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1200 - acc: 0.6686 - val_loss: 1.1325 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1198 - acc: 0.6686 - val_loss: 1.1321 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1196 - acc: 0.6686 - val_loss: 1.1314 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1195 - acc: 0.6686 - val_loss: 1.1319 - val_acc: 0.6572\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1194 - acc: 0.6686 - val_loss: 1.1313 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1192 - acc: 0.6686 - val_loss: 1.1311 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1189 - acc: 0.6686 - val_loss: 1.1308 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1188 - acc: 0.6686 - val_loss: 1.1308 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1187 - acc: 0.6686 - val_loss: 1.1298 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1185 - acc: 0.6686 - val_loss: 1.1304 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1184 - acc: 0.6686 - val_loss: 1.1297 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 327us/step - loss: 1.1182 - acc: 0.6686 - val_loss: 1.1294 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1180 - acc: 0.6686 - val_loss: 1.1291 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1178 - acc: 0.6686 - val_loss: 1.1289 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1176 - acc: 0.6686 - val_loss: 1.1284 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1173 - acc: 0.6686 - val_loss: 1.1265 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1171 - acc: 0.6686 - val_loss: 1.1271 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1170 - acc: 0.6686 - val_loss: 1.1260 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1168 - acc: 0.6686 - val_loss: 1.1257 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 203us/step\n",
      "4006/4006 [==============================] - 1s 201us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.001\n",
      "regularization strength lambda =  0.001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 9s 2ms/step - loss: 2.0676 - acc: 0.0279 - val_loss: 1.8071 - val_acc: 0.1015\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.7122 - acc: 0.5344 - val_loss: 1.6474 - val_acc: 0.6539\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.5858 - acc: 0.6564 - val_loss: 1.5427 - val_acc: 0.6589\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4915 - acc: 0.6648 - val_loss: 1.4657 - val_acc: 0.6589\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.4222 - acc: 0.6685 - val_loss: 1.4081 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.3708 - acc: 0.6685 - val_loss: 1.3662 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.3334 - acc: 0.6685 - val_loss: 1.3356 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.3059 - acc: 0.6685 - val_loss: 1.3125 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.2849 - acc: 0.6685 - val_loss: 1.2959 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2699 - acc: 0.6685 - val_loss: 1.2831 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2583 - acc: 0.6686 - val_loss: 1.2732 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2492 - acc: 0.6686 - val_loss: 1.2653 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.2419 - acc: 0.6686 - val_loss: 1.2592 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2363 - acc: 0.6686 - val_loss: 1.2543 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2318 - acc: 0.6686 - val_loss: 1.2501 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2279 - acc: 0.6686 - val_loss: 1.2466 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2246 - acc: 0.6686 - val_loss: 1.2435 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.2216 - acc: 0.6686 - val_loss: 1.2408 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.2190 - acc: 0.6686 - val_loss: 1.2386 - val_acc: 0.6572.2226 - acc: 0.66\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.2167 - acc: 0.6686 - val_loss: 1.2365 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.2146 - acc: 0.6686 - val_loss: 1.2344 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2127 - acc: 0.6686 - val_loss: 1.2324 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 1.2110 - acc: 0.6686 - val_loss: 1.2306 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.2093 - acc: 0.6686 - val_loss: 1.2290 - val_acc: 0.6572- loss: 1.2294 - \n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.2078 - acc: 0.6686 - val_loss: 1.2273 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 1.2063 - acc: 0.6686 - val_loss: 1.2257 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2050 - acc: 0.6686 - val_loss: 1.2243 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2037 - acc: 0.6686 - val_loss: 1.2229 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.2024 - acc: 0.6686 - val_loss: 1.2216 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2012 - acc: 0.6686 - val_loss: 1.2203 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.2001 - acc: 0.6686 - val_loss: 1.2193 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1989 - acc: 0.6686 - val_loss: 1.2182 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1979 - acc: 0.6686 - val_loss: 1.2171 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1969 - acc: 0.6686 - val_loss: 1.2160 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1959 - acc: 0.6686 - val_loss: 1.2150 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1950 - acc: 0.6686 - val_loss: 1.2139 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1941 - acc: 0.6686 - val_loss: 1.2129 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1932 - acc: 0.6686 - val_loss: 1.2119 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1924 - acc: 0.6686 - val_loss: 1.2110 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1916 - acc: 0.6686 - val_loss: 1.2099 - val_acc: 0.6572\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1909 - acc: 0.6686 - val_loss: 1.2090 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1902 - acc: 0.6686 - val_loss: 1.2082 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1895 - acc: 0.6686 - val_loss: 1.2073 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1888 - acc: 0.6686 - val_loss: 1.2064 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1881 - acc: 0.6686 - val_loss: 1.2056 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1875 - acc: 0.6686 - val_loss: 1.2048 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1869 - acc: 0.6686 - val_loss: 1.2040 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1863 - acc: 0.6686 - val_loss: 1.2033 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1858 - acc: 0.6686 - val_loss: 1.2025 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1852 - acc: 0.6686 - val_loss: 1.2019 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1847 - acc: 0.6686 - val_loss: 1.2012 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1842 - acc: 0.6686 - val_loss: 1.2005 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1837 - acc: 0.6686 - val_loss: 1.1999 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1832 - acc: 0.6686 - val_loss: 1.1993 - val_acc: 0.6572s - loss: 1.1821 - acc: 0.66\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1827 - acc: 0.6686 - val_loss: 1.1987 - val_acc: 0.65720s - loss: 1.1885 - acc\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1823 - acc: 0.6686 - val_loss: 1.1981 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1818 - acc: 0.6686 - val_loss: 1.1976 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.1814 - acc: 0.6686 - val_loss: 1.1971 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1810 - acc: 0.6686 - val_loss: 1.1966 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1806 - acc: 0.6686 - val_loss: 1.1960 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1802 - acc: 0.6686 - val_loss: 1.1956 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.1799 - acc: 0.6686 - val_loss: 1.1951 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1795 - acc: 0.6686 - val_loss: 1.1946 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1792 - acc: 0.6686 - val_loss: 1.1942 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1789 - acc: 0.6686 - val_loss: 1.1938 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1786 - acc: 0.6686 - val_loss: 1.1933 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1783 - acc: 0.6686 - val_loss: 1.1930 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1780 - acc: 0.6686 - val_loss: 1.1926 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1777 - acc: 0.6686 - val_loss: 1.1922 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1774 - acc: 0.6686 - val_loss: 1.1919 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1772 - acc: 0.6686 - val_loss: 1.1914 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1769 - acc: 0.6686 - val_loss: 1.1910 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.1766 - acc: 0.6686 - val_loss: 1.1907 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1764 - acc: 0.6686 - val_loss: 1.1904 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1761 - acc: 0.6686 - val_loss: 1.1901 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1759 - acc: 0.6686 - val_loss: 1.1898 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1757 - acc: 0.6686 - val_loss: 1.1896 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1755 - acc: 0.6686 - val_loss: 1.1893 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1753 - acc: 0.6686 - val_loss: 1.1889 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1751 - acc: 0.6686 - val_loss: 1.1887 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1749 - acc: 0.6686 - val_loss: 1.1885 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1747 - acc: 0.6686 - val_loss: 1.1882 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1746 - acc: 0.6686 - val_loss: 1.1879 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1744 - acc: 0.6686 - val_loss: 1.1877 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.1742 - acc: 0.6686 - val_loss: 1.1875 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1741 - acc: 0.6686 - val_loss: 1.1872 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1739 - acc: 0.6686 - val_loss: 1.1869 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 178us/step - loss: 1.1737 - acc: 0.6686 - val_loss: 1.1866 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.1736 - acc: 0.6686 - val_loss: 1.1863 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1734 - acc: 0.6686 - val_loss: 1.1861 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1733 - acc: 0.6686 - val_loss: 1.1859 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1731 - acc: 0.6686 - val_loss: 1.1856 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1730 - acc: 0.6686 - val_loss: 1.1855 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1728 - acc: 0.6686 - val_loss: 1.1853 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.1727 - acc: 0.6686 - val_loss: 1.1851 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1726 - acc: 0.6686 - val_loss: 1.1847 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1725 - acc: 0.6686 - val_loss: 1.1846 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1723 - acc: 0.6686 - val_loss: 1.1844 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1722 - acc: 0.6686 - val_loss: 1.1842 - val_acc: 0.6572\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 179us/step - loss: 1.1721 - acc: 0.6686 - val_loss: 1.1840 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 197us/step\n",
      "4006/4006 [==============================] - 1s 197us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.001\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 9s 2ms/step - loss: 2.6636 - acc: 0.0152 - val_loss: 2.3002 - val_acc: 0.0116\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 2.1519 - acc: 0.0668 - val_loss: 2.0606 - val_acc: 0.5125\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.9609 - acc: 0.6289 - val_loss: 1.8901 - val_acc: 0.6423\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.8195 - acc: 0.6640 - val_loss: 1.7716 - val_acc: 0.6589\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.7281 - acc: 0.6688 - val_loss: 1.7056 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.6739 - acc: 0.6685 - val_loss: 1.6617 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.6359 - acc: 0.6686 - val_loss: 1.6309 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.6076 - acc: 0.6686 - val_loss: 1.6063 - val_acc: 0.6572 loss: 1.6071 - acc: 0.66\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.5862 - acc: 0.6686 - val_loss: 1.5907 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.5705 - acc: 0.6686 - val_loss: 1.5778 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.5579 - acc: 0.6686 - val_loss: 1.5665 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.5463 - acc: 0.6686 - val_loss: 1.5566 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.5376 - acc: 0.6686 - val_loss: 1.5469 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.5306 - acc: 0.6686 - val_loss: 1.5439 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.5245 - acc: 0.6686 - val_loss: 1.5362 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.5185 - acc: 0.6686 - val_loss: 1.5347 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.5140 - acc: 0.6686 - val_loss: 1.5269 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.5092 - acc: 0.6686 - val_loss: 1.5240 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.5053 - acc: 0.6686 - val_loss: 1.5199 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.5019 - acc: 0.6686 - val_loss: 1.5164 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.4990 - acc: 0.6686 - val_loss: 1.5143 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.4949 - acc: 0.6686 - val_loss: 1.5099 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4926 - acc: 0.6686 - val_loss: 1.5092 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.4896 - acc: 0.6686 - val_loss: 1.5039 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.4871 - acc: 0.6686 - val_loss: 1.5012 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.4840 - acc: 0.6686 - val_loss: 1.4979 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.4809 - acc: 0.6686 - val_loss: 1.4961 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.4787 - acc: 0.6686 - val_loss: 1.4916 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.4756 - acc: 0.6686 - val_loss: 1.4956 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4739 - acc: 0.6686 - val_loss: 1.5115 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.4720 - acc: 0.6686 - val_loss: 1.4859 - val_acc: 0.6572loss: 1.4683 - acc:\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.4678 - acc: 0.6686 - val_loss: 1.4817 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.4661 - acc: 0.6686 - val_loss: 1.4803 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.4639 - acc: 0.6686 - val_loss: 1.4781 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.4614 - acc: 0.6686 - val_loss: 1.4766 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4600 - acc: 0.6686 - val_loss: 1.4753 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.4583 - acc: 0.6686 - val_loss: 1.4800 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.4568 - acc: 0.6686 - val_loss: 1.4750 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.4540 - acc: 0.6686 - val_loss: 1.4702 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.4530 - acc: 0.6686 - val_loss: 1.4695 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.4512 - acc: 0.6686 - val_loss: 1.4662 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.4496 - acc: 0.6686 - val_loss: 1.4661 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.4479 - acc: 0.6686 - val_loss: 1.4632 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4465 - acc: 0.6686 - val_loss: 1.4606 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4444 - acc: 0.6686 - val_loss: 1.4589 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4434 - acc: 0.6686 - val_loss: 1.4594 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.4417 - acc: 0.6686 - val_loss: 1.4562 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 180us/step - loss: 1.4405 - acc: 0.6686 - val_loss: 1.4540 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4391 - acc: 0.6686 - val_loss: 1.4525 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4376 - acc: 0.6686 - val_loss: 1.4514 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.4363 - acc: 0.6686 - val_loss: 1.4538 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.4349 - acc: 0.6686 - val_loss: 1.4505 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4335 - acc: 0.6686 - val_loss: 1.4465 - val_acc: 0.6572\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4319 - acc: 0.6686 - val_loss: 1.4465 - val_acc: 0.6572 loss: 1.4316 - acc: 0.668\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.4300 - acc: 0.6686 - val_loss: 1.4626 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.4311 - acc: 0.6685 - val_loss: 1.4455 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.4278 - acc: 0.6686 - val_loss: 1.4409 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4264 - acc: 0.6685 - val_loss: 1.4424 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4259 - acc: 0.6686 - val_loss: 1.4431 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.4244 - acc: 0.6685 - val_loss: 1.4389 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4230 - acc: 0.6685 - val_loss: 1.4395 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4224 - acc: 0.6685 - val_loss: 1.4396 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4209 - acc: 0.6685 - val_loss: 1.4352 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.4179 - acc: 0.6685 - val_loss: 1.4334 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4174 - acc: 0.6685 - val_loss: 1.4347 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4171 - acc: 0.6685 - val_loss: 1.4688 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4182 - acc: 0.6685 - val_loss: 1.4270 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.4145 - acc: 0.6685 - val_loss: 1.4268 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4130 - acc: 0.6685 - val_loss: 1.4247 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4124 - acc: 0.6685 - val_loss: 1.4302 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.4110 - acc: 0.6685 - val_loss: 1.4290 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.4098 - acc: 0.6685 - val_loss: 1.4210 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4088 - acc: 0.6685 - val_loss: 1.4242 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.4075 - acc: 0.6685 - val_loss: 1.4259 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.4067 - acc: 0.6685 - val_loss: 1.4267 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.4052 - acc: 0.6685 - val_loss: 1.4201 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.4038 - acc: 0.6685 - val_loss: 1.4157 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.4033 - acc: 0.6685 - val_loss: 1.4206 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.4017 - acc: 0.6685 - val_loss: 1.4145 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4011 - acc: 0.6685 - val_loss: 1.4136 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.3995 - acc: 0.6685 - val_loss: 1.4108 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.3990 - acc: 0.6685 - val_loss: 1.4112 - val_acc: 0.6572s - loss: 1.3973 - acc\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3974 - acc: 0.6685 - val_loss: 1.4177 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.3973 - acc: 0.6685 - val_loss: 1.4079 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.3957 - acc: 0.6685 - val_loss: 1.4061 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.3954 - acc: 0.6685 - val_loss: 1.4066 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.3922 - acc: 0.6685 - val_loss: 1.4341 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3954 - acc: 0.6685 - val_loss: 1.4039 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.3917 - acc: 0.6685 - val_loss: 1.4035 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3897 - acc: 0.6685 - val_loss: 1.4022 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.3895 - acc: 0.6685 - val_loss: 1.4035 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.3901 - acc: 0.667 - 1s 243us/step - loss: 1.3890 - acc: 0.6685 - val_loss: 1.4000 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.3871 - acc: 0.6685 - val_loss: 1.4019 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.3861 - acc: 0.6685 - val_loss: 1.3978 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.3849 - acc: 0.6685 - val_loss: 1.3970 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.3842 - acc: 0.6685 - val_loss: 1.4081 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.3821 - acc: 0.6685 - val_loss: 1.3973 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.3824 - acc: 0.6685 - val_loss: 1.3935 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.3812 - acc: 0.6685 - val_loss: 1.4341 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.3825 - acc: 0.6685 - val_loss: 1.3939 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 265us/step\n",
      "4006/4006 [==============================] - 1s 262us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.001\n",
      "regularization strength lambda =  1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 38.4109 - acc: 0.6324 - val_loss: 34.3255 - val_acc: 0.6539\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 31.0534 - acc: 0.6666 - val_loss: 27.7963 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 25.1752 - acc: 0.6686 - val_loss: 22.5673 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 20.4460 - acc: 0.6686 - val_loss: 18.3594 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 16.6722 - acc: 0.6686 - val_loss: 15.0116 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 13.6601 - acc: 0.6686 - val_loss: 12.3398 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 11.2535 - acc: 0.6686 - val_loss: 10.1969 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 9.3228 - acc: 0.6686 - val_loss: 8.4777 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 7.7737 - acc: 0.6686 - val_loss: 7.0980 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 6.5305 - acc: 0.6686 - val_loss: 5.9908 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 5.5326 - acc: 0.6686 - val_loss: 5.1021 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 4.7318 - acc: 0.6686 - val_loss: 4.3888 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 4.0889 - acc: 0.6686 - val_loss: 3.8162 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 3.5726 - acc: 0.6686 - val_loss: 3.3557 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 3.1547 - acc: 0.6686 - val_loss: 2.9709 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 2.8064 - acc: 0.6686 - val_loss: 2.6705 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.5380 - acc: 0.6686 - val_loss: 2.4310 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 2.3213 - acc: 0.6686 - val_loss: 2.2362 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 2.1396 - acc: 0.6686 - val_loss: 2.0707 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.9948 - acc: 0.6686 - val_loss: 1.9450 - val_acc: 0.6572 loss: 2.0055 - acc: 0.\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.8813 - acc: 0.6686 - val_loss: 1.8441 - val_acc: 0.6572: 1.8973 - acc: \n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.7899 - acc: 0.6686 - val_loss: 1.7627 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.7161 - acc: 0.6686 - val_loss: 1.6969 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.6564 - acc: 0.6686 - val_loss: 1.6436 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.6080 - acc: 0.6686 - val_loss: 1.6003 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.5686 - acc: 0.6686 - val_loss: 1.5650 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.5364 - acc: 0.6686 - val_loss: 1.5360 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.5096 - acc: 0.6686 - val_loss: 1.5114 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.4865 - acc: 0.6686 - val_loss: 1.4901 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.4666 - acc: 0.6690- ETA: 1s - loss: 1.44 - 1s 235us/step - loss: 1.4670 - acc: 0.6686 - val_loss: 1.4724 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4505 - acc: 0.6686 - val_loss: 1.4572 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.4357 - acc: 0.6686 - val_loss: 1.4434 - val_acc: 0.65720s - loss: 1.4322 - acc: 0.6\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.4223 - acc: 0.6686 - val_loss: 1.4308 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.4101 - acc: 0.6686 - val_loss: 1.4193 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.3990 - acc: 0.6686 - val_loss: 1.4087 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3887 - acc: 0.6686 - val_loss: 1.3986 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3789 - acc: 0.6686 - val_loss: 1.3895 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3702 - acc: 0.6686 - val_loss: 1.3816 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3628 - acc: 0.6686 - val_loss: 1.3748 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.3567 - acc: 0.6686 - val_loss: 1.3693 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3515 - acc: 0.6686 - val_loss: 1.3647 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.3470 - acc: 0.6686 - val_loss: 1.3606 - val_acc: 0.6572 - loss: 1.3490 - acc: 0.\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.3432 - acc: 0.6686 - val_loss: 1.3570 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3399 - acc: 0.6686 - val_loss: 1.3538 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.3389 - acc: 0.6675- ETA: 0s - loss: 1.3370 - acc: 0.66 - 1s 211us/step - loss: 1.3370 - acc: 0.6686 - val_loss: 1.3511 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.3344 - acc: 0.6686 - val_loss: 1.3485 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.3320 - acc: 0.6686 - val_loss: 1.3462 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.3296 - acc: 0.6686 - val_loss: 1.3438 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3272 - acc: 0.6686 - val_loss: 1.3414 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3248 - acc: 0.6686 - val_loss: 1.3393 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.3226 - acc: 0.6686 - val_loss: 1.3373 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3207 - acc: 0.6686 - val_loss: 1.3355 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.3189 - acc: 0.6686 - val_loss: 1.3337 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.3172 - acc: 0.6686 - val_loss: 1.3322 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.3157 - acc: 0.6686 - val_loss: 1.3307 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.3143 - acc: 0.6686 - val_loss: 1.3294 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3129 - acc: 0.6686 - val_loss: 1.3280 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.3116 - acc: 0.6686 - val_loss: 1.3267 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3103 - acc: 0.6686 - val_loss: 1.3254 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.3091 - acc: 0.6686 - val_loss: 1.3243 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3080 - acc: 0.6686 - val_loss: 1.3230 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.3068 - acc: 0.6686 - val_loss: 1.3219 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.3057 - acc: 0.6686 - val_loss: 1.3207 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3046 - acc: 0.6686 - val_loss: 1.3195 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.3036 - acc: 0.6686 - val_loss: 1.3185 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.3025 - acc: 0.6686 - val_loss: 1.3175 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3015 - acc: 0.6686 - val_loss: 1.3165 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.3005 - acc: 0.6686 - val_loss: 1.3154 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.2995 - acc: 0.6686 - val_loss: 1.3144 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2985 - acc: 0.6686 - val_loss: 1.3134 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.2975 - acc: 0.6686 - val_loss: 1.3125 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2971 - acc: 0.668 - 1s 220us/step - loss: 1.2965 - acc: 0.6686 - val_loss: 1.3116 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.2955 - acc: 0.6686 - val_loss: 1.3106 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.2945 - acc: 0.6686 - val_loss: 1.3095 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.2936 - acc: 0.6686 - val_loss: 1.3086 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.2926 - acc: 0.6686 - val_loss: 1.3076 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2917 - acc: 0.6686 - val_loss: 1.3068 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2908 - acc: 0.6686 - val_loss: 1.3058 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.2899 - acc: 0.6686 - val_loss: 1.3050 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.2889 - acc: 0.6686 - val_loss: 1.3040 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2880 - acc: 0.6686 - val_loss: 1.3031 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.2871 - acc: 0.6686 - val_loss: 1.3022 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2862 - acc: 0.6686 - val_loss: 1.3013 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.2853 - acc: 0.6686 - val_loss: 1.3004 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.2845 - acc: 0.6686 - val_loss: 1.2996 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2836 - acc: 0.6686 - val_loss: 1.2987 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.2827 - acc: 0.6686 - val_loss: 1.2979 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2818 - acc: 0.6686 - val_loss: 1.2970 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.2810 - acc: 0.6686 - val_loss: 1.2961 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2801 - acc: 0.6686 - val_loss: 1.2952 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.2792 - acc: 0.6686 - val_loss: 1.2944 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.2784 - acc: 0.6686 - val_loss: 1.2935 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2776 - acc: 0.6686 - val_loss: 1.2928 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2767 - acc: 0.6686 - val_loss: 1.2919 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.2759 - acc: 0.6686 - val_loss: 1.2910 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.2751 - acc: 0.6686 - val_loss: 1.2903 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2743 - acc: 0.6686 - val_loss: 1.2894 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.2735 - acc: 0.6686 - val_loss: 1.2886 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.2727 - acc: 0.6686 - val_loss: 1.2878 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2719 - acc: 0.6686 - val_loss: 1.2870 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 240us/step\n",
      "4006/4006 [==============================] - 1s 229us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  1e-05\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 1.3044 - acc: 0.5836 - val_loss: 1.1760 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.1486 - acc: 0.6686 - val_loss: 1.1545 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1375 - acc: 0.6686 - val_loss: 1.1473 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1437 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1419 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1297 - acc: 0.6686 - val_loss: 1.1397 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1290 - acc: 0.6686 - val_loss: 1.1389 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1283 - acc: 0.6686 - val_loss: 1.1393 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1281 - acc: 0.6686 - val_loss: 1.1377 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1236 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1069 - acc: 0.6686 - val_loss: 1.1121 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0939 - acc: 0.6686 - val_loss: 1.1091 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.0848 - acc: 0.6686 - val_loss: 1.1248 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.0808 - acc: 0.6686 - val_loss: 1.0955 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.0734 - acc: 0.6686 - val_loss: 1.0913 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.0746 - acc: 0.6686 - val_loss: 1.0937 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.0669 - acc: 0.6686 - val_loss: 1.0850 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0498 - acc: 0.6686 - val_loss: 1.1733 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1143 - acc: 0.6686 - val_loss: 1.0880 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0531 - acc: 0.6686 - val_loss: 1.1497 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1216 - acc: 0.6686 - val_loss: 1.1407 - val_acc: 0.6572\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.0667 - acc: 0.6686 - val_loss: 1.0797 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0488 - acc: 0.6686 - val_loss: 1.1489 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0572 - acc: 0.6686 - val_loss: 1.0651 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0386 - acc: 0.6686 - val_loss: 1.0738 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.0403 - acc: 0.6686 - val_loss: 1.0717 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0372 - acc: 0.6686 - val_loss: 1.0735 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0330 - acc: 0.6686 - val_loss: 1.1367 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.0295 - acc: 0.6686 - val_loss: 1.1960 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.0385 - acc: 0.6686 - val_loss: 1.0631 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.0322 - acc: 0.6686 - val_loss: 1.0628 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.0283 - acc: 0.6686 - val_loss: 1.1096 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.0303 - acc: 0.6686 - val_loss: 1.0547 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0302 - acc: 0.6686 - val_loss: 1.0573 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0313 - acc: 0.6686 - val_loss: 1.0566 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0279 - acc: 0.6686 - val_loss: 1.0784 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0272 - acc: 0.6686 - val_loss: 1.1841 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0269 - acc: 0.6686 - val_loss: 1.0952 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0244 - acc: 0.6686 - val_loss: 1.0596 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0220 - acc: 0.6686 - val_loss: 1.0785 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0247 - acc: 0.6686 - val_loss: 1.0878 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0228 - acc: 0.6686 - val_loss: 1.0773 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0213 - acc: 0.6686 - val_loss: 1.0920 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.0223 - acc: 0.6686 - val_loss: 1.0561 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.0204 - acc: 0.6686 - val_loss: 1.0818 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.0228 - acc: 0.6686 - val_loss: 1.0701 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.0213 - acc: 0.6686 - val_loss: 1.2039 - val_acc: 0.6556\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1027 - acc: 0.6686 - val_loss: 1.0739 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.0410 - acc: 0.6686 - val_loss: 1.0758 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.0310 - acc: 0.6686 - val_loss: 1.1204 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.0208 - acc: 0.6686 - val_loss: 1.1021 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.0248 - acc: 0.6686 - val_loss: 1.0705 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0193 - acc: 0.6686 - val_loss: 1.0817 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.0218 - acc: 0.6686 - val_loss: 1.0596 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.0231 - acc: 0.6686 - val_loss: 1.0453 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.0247 - acc: 0.6686 - val_loss: 1.0474 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.0171 - acc: 0.6686 - val_loss: 1.0461 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0154 - acc: 0.6686 - val_loss: 1.0483 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.0172 - acc: 0.6686 - val_loss: 1.0488 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0165 - acc: 0.6686 - val_loss: 1.0715 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0188 - acc: 0.6686 - val_loss: 1.0823 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.0181 - acc: 0.6686 - val_loss: 1.2734 - val_acc: 0.6456\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1601 - acc: 0.6685 - val_loss: 1.1402 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1295 - acc: 0.6686 - val_loss: 1.1384 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1285 - acc: 0.6686 - val_loss: 1.1355 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1284 - acc: 0.6686 - val_loss: 1.1374 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1281 - acc: 0.6686 - val_loss: 1.1370 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1277 - acc: 0.6686 - val_loss: 1.1361 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1276 - acc: 0.6686 - val_loss: 1.1350 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1276 - acc: 0.6686 - val_loss: 1.1368 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1275 - acc: 0.6686 - val_loss: 1.1352 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1274 - acc: 0.6686 - val_loss: 1.1344 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1275 - acc: 0.6686 - val_loss: 1.1351 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1274 - acc: 0.6686 - val_loss: 1.1356 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1274 - acc: 0.6686 - val_loss: 1.1351 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1273 - acc: 0.6686 - val_loss: 1.1357 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1274 - acc: 0.6686 - val_loss: 1.1368 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1273 - acc: 0.6686 - val_loss: 1.1354 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1273 - acc: 0.6686 - val_loss: 1.1344 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1274 - acc: 0.6686 - val_loss: 1.1353 - val_acc: 0.6572\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1362 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1350 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1273 - acc: 0.6686 - val_loss: 1.1356 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1358 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1351 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1273 - acc: 0.6686 - val_loss: 1.1347 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1347 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1354 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1271 - acc: 0.6686 - val_loss: 1.1362 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1364 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1357 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1270 - acc: 0.6686 - val_loss: 1.1352 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.1271 - acc: 0.6686 - val_loss: 1.1363 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1271 - acc: 0.6686 - val_loss: 1.1361 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1270 - acc: 0.6686 - val_loss: 1.1360 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1271 - acc: 0.6686 - val_loss: 1.1346 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.1348 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1271 - acc: 0.6686 - val_loss: 1.1346 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1271 - acc: 0.6686 - val_loss: 1.1350 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1270 - acc: 0.6686 - val_loss: 1.1349 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 270us/step\n",
      "4006/4006 [==============================] - 1s 273us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.0001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 1.2956 - acc: 0.6241 - val_loss: 1.1678 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1505 - acc: 0.6686 - val_loss: 1.1508 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1384 - acc: 0.6686 - val_loss: 1.1447 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1300 - acc: 0.6686 - val_loss: 1.1395 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.1258 - acc: 0.6686 - val_loss: 1.1346 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1232 - acc: 0.6686 - val_loss: 1.1282 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1206 - acc: 0.6686 - val_loss: 1.1327 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1201 - acc: 0.6686 - val_loss: 1.1311 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1180 - acc: 0.6686 - val_loss: 1.1368 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1167 - acc: 0.6686 - val_loss: 1.1337 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1138 - acc: 0.6686 - val_loss: 1.1202 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1126 - acc: 0.6686 - val_loss: 1.1151 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1107 - acc: 0.6686 - val_loss: 1.1220 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1087 - acc: 0.6686 - val_loss: 1.1173 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1070 - acc: 0.6686 - val_loss: 1.1197 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1043 - acc: 0.6686 - val_loss: 1.1156 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1023 - acc: 0.6686 - val_loss: 1.0901 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0840 - acc: 0.6686 - val_loss: 1.1084 - val_acc: 0.6572s - loss: 1.1044 - ac\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.0818 - acc: 0.6686 - val_loss: 1.1446 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.0982 - acc: 0.6686 - val_loss: 1.1481 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1059 - acc: 0.6686 - val_loss: 1.1066 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0928 - acc: 0.6686 - val_loss: 1.1014 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0800 - acc: 0.6686 - val_loss: 1.0635 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0645 - acc: 0.6686 - val_loss: 1.0617 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0650 - acc: 0.6686 - val_loss: 1.0618 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0648 - acc: 0.6688 - val_loss: 1.0648 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.0543 - acc: 0.6686 - val_loss: 1.0573 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0413 - acc: 0.6686 - val_loss: 1.0915 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0452 - acc: 0.6686 - val_loss: 1.0449 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0439 - acc: 0.6686 - val_loss: 1.0297 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0322 - acc: 0.6686 - val_loss: 1.0478 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.0303 - acc: 0.6686 - val_loss: 1.0762 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.0231 - acc: 0.6686 - val_loss: 1.1383 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 1.0728 - acc: 0.6686 - val_loss: 1.0603 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0363 - acc: 0.6686 - val_loss: 1.0308 - val_acc: 0.6572\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.0175 - acc: 0.6686 - val_loss: 1.0205 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.0178 - acc: 0.6686 - val_loss: 1.0462 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0125 - acc: 0.6686 - val_loss: 1.0500 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0107 - acc: 0.6686 - val_loss: 1.0207 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.0064 - acc: 0.6686 - val_loss: 1.0346 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0042 - acc: 0.6686 - val_loss: 1.1790 - val_acc: 0.6589\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0129 - acc: 0.6688 - val_loss: 1.0309 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 0.9994 - acc: 0.6686 - val_loss: 1.0378 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0278 - acc: 0.6686 - val_loss: 1.2232 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0117 - acc: 0.6686 - val_loss: 0.9959 - val_acc: 0.6572 loss: 1.0162 - acc: 0.\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 0.9934 - acc: 0.6686 - val_loss: 1.0072 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 0.9937 - acc: 0.6685 - val_loss: 1.0125 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 0.9933 - acc: 0.6685 - val_loss: 1.0168 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 0.9929 - acc: 0.6681 - val_loss: 1.0400 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9967 - acc: 0.6686 - val_loss: 1.1107 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 0.9864 - acc: 0.6686 - val_loss: 0.9982 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 0.9810 - acc: 0.6686 - val_loss: 1.0015 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.9781 - acc: 0.669 - 1s 202us/step - loss: 0.9799 - acc: 0.6686 - val_loss: 1.0268 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9734 - acc: 0.6686 - val_loss: 1.0113 - val_acc: 0.6572 0s - loss: 0.9783 \n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 0.9710 - acc: 0.6685 - val_loss: 0.9685 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 0.9693 - acc: 0.6686 - val_loss: 1.0317 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 0.9686 - acc: 0.6681 - val_loss: 1.0607 - val_acc: 0.6556\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 0.9784 - acc: 0.6683 - val_loss: 1.0016 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 0.9707 - acc: 0.6686 - val_loss: 1.0540 - val_acc: 0.6506s - loss: 0.9623 - acc\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 0.9786 - acc: 0.6688 - val_loss: 1.0308 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 0.9777 - acc: 0.6686 - val_loss: 1.0029 - val_acc: 0.6572s - loss: 0.9767 - acc: 0\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 0.9727 - acc: 0.6686 - val_loss: 1.0123 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 0.9689 - acc: 0.6683 - val_loss: 0.9829 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 0.9673 - acc: 0.6683 - val_loss: 1.0298 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 0.9724 - acc: 0.6670 - val_loss: 1.0133 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 0.9617 - acc: 0.6683 - val_loss: 1.0483 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 0.9604 - acc: 0.6681 - val_loss: 0.9984 - val_acc: 0.6572ss: 0.9646 - acc: 0.6\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 0.9673 - acc: 0.6697 - val_loss: 0.9594 - val_acc: 0.6589\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 0.9543 - acc: 0.6688 - val_loss: 0.9639 - val_acc: 0.6589\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9535 - acc: 0.6688 - val_loss: 1.0342 - val_acc: 0.6589\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 0.9554 - acc: 0.6681 - val_loss: 0.9777 - val_acc: 0.6589\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 0.9569 - acc: 0.6685 - val_loss: 0.9468 - val_acc: 0.6589\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9510 - acc: 0.6679 - val_loss: 0.9724 - val_acc: 0.6589\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.9504 - acc: 0.6679 - val_loss: 0.9597 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 0.9469 - acc: 0.6677 - val_loss: 0.9364 - val_acc: 0.6639\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 0.9472 - acc: 0.6636 - val_loss: 1.1950 - val_acc: 0.6589\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0321 - acc: 0.6675 - val_loss: 1.0150 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 0.9873 - acc: 0.6686 - val_loss: 0.9884 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 0.9519 - acc: 0.6679 - val_loss: 0.9465 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 0.9483 - acc: 0.6709 - val_loss: 0.9435 - val_acc: 0.6589\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 0.9409 - acc: 0.6685 - val_loss: 1.0112 - val_acc: 0.6556\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 0.9482 - acc: 0.6703 - val_loss: 0.9848 - val_acc: 0.6589\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 0.9559 - acc: 0.6677 - val_loss: 0.9478 - val_acc: 0.6456\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 0.9431 - acc: 0.6681 - val_loss: 0.9419 - val_acc: 0.6589\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 0.9357 - acc: 0.6692 - val_loss: 0.9400 - val_acc: 0.6689\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9366 - acc: 0.6718 - val_loss: 0.9490 - val_acc: 0.6522\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 0.9360 - acc: 0.6714 - val_loss: 0.9350 - val_acc: 0.6589\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 0.9348 - acc: 0.6688 - val_loss: 0.9429 - val_acc: 0.6589\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 0.9327 - acc: 0.6696 - val_loss: 0.9931 - val_acc: 0.6556\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 0.9406 - acc: 0.6697 - val_loss: 0.9596 - val_acc: 0.6456\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 0.9340 - acc: 0.6685 - val_loss: 1.0054 - val_acc: 0.6556\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 0.9395 - acc: 0.6703 - val_loss: 1.0354 - val_acc: 0.6556\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 0.9791 - acc: 0.6657 - val_loss: 0.9824 - val_acc: 0.6572\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 195us/step - loss: 0.9419 - acc: 0.6722 - val_loss: 0.9399 - val_acc: 0.6606\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 0.9347 - acc: 0.6718 - val_loss: 1.4098 - val_acc: 0.4293\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0793 - acc: 0.6653 - val_loss: 1.0520 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.0539 - acc: 0.6686 - val_loss: 1.0837 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.0512 - acc: 0.6686 - val_loss: 1.0533 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.0507 - acc: 0.6686 - val_loss: 1.0488 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.0501 - acc: 0.6686 - val_loss: 1.0484 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 205us/step\n",
      "4006/4006 [==============================] - 1s 208us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 9s 2ms/step - loss: 1.3256 - acc: 0.6601 - val_loss: 1.3039 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.2028 - acc: 0.6686 - val_loss: 1.2289 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1465 - acc: 0.6686 - val_loss: 1.1578 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.1138 - acc: 0.6686 - val_loss: 1.2294 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.1011 - acc: 0.6686 - val_loss: 1.2774 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.1865 - acc: 0.6686 - val_loss: 1.1280 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 181us/step - loss: 1.0857 - acc: 0.6686 - val_loss: 1.1329 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.0749 - acc: 0.6686 - val_loss: 1.0981 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.0678 - acc: 0.6686 - val_loss: 1.0854 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0625 - acc: 0.6686 - val_loss: 1.1126 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0549 - acc: 0.6686 - val_loss: 1.1975 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.0575 - acc: 0.6686 - val_loss: 1.0924 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.0460 - acc: 0.6686 - val_loss: 1.1924 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.0432 - acc: 0.6686 - val_loss: 1.0563 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.0329 - acc: 0.6686 - val_loss: 1.0427 - val_acc: 0.6556\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.0298 - acc: 0.6686 - val_loss: 1.3215 - val_acc: 0.6556\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.0393 - acc: 0.6685 - val_loss: 1.0803 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 1.0197 - acc: 0.6688 - val_loss: 1.0478 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.0155 - acc: 0.6683 - val_loss: 1.1565 - val_acc: 0.6389\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.0175 - acc: 0.6675 - val_loss: 1.0697 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 184us/step - loss: 1.0069 - acc: 0.6692 - val_loss: 1.0250 - val_acc: 0.6556\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 1.0085 - acc: 0.6697 - val_loss: 1.0288 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.0049 - acc: 0.6690 - val_loss: 1.0142 - val_acc: 0.6589\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 183us/step - loss: 1.0012 - acc: 0.6703 - val_loss: 1.0580 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 0.9964 - acc: 0.6709 - val_loss: 1.0054 - val_acc: 0.6556\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 0.9934 - acc: 0.6720 - val_loss: 1.0306 - val_acc: 0.6506\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 0.9992 - acc: 0.6696 - val_loss: 1.0257 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 2s 308us/step - loss: 0.9962 - acc: 0.6697 - val_loss: 1.0246 - val_acc: 0.6489\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.9906 - acc: 0.6722 - val_loss: 1.0255 - val_acc: 0.64390s - loss: 0.9848 - acc: 0\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.9878 - acc: 0.6720 - val_loss: 1.0174 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 2s 305us/step - loss: 0.9852 - acc: 0.6692 - val_loss: 0.9933 - val_acc: 0.6622\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 0.9823 - acc: 0.6688 - val_loss: 1.0392 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.9858 - acc: 0.6686 - val_loss: 1.0699 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9841 - acc: 0.6734 - val_loss: 0.9887 - val_acc: 0.6672\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 0.9769 - acc: 0.6764 - val_loss: 1.0011 - val_acc: 0.6606\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 0.9830 - acc: 0.6736 - val_loss: 1.0456 - val_acc: 0.6589\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 0.9755 - acc: 0.6720 - val_loss: 1.0964 - val_acc: 0.6656\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 0.9791 - acc: 0.6751 - val_loss: 1.0109 - val_acc: 0.6639\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 0.9781 - acc: 0.6714 - val_loss: 1.0115 - val_acc: 0.6539\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9700 - acc: 0.6738 - val_loss: 0.9895 - val_acc: 0.6622\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 0.9772 - acc: 0.6751 - val_loss: 1.0264 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 0.9776 - acc: 0.6727 - val_loss: 0.9869 - val_acc: 0.6606\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 0.9717 - acc: 0.6755 - val_loss: 1.0071 - val_acc: 0.6589\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 0.9722 - acc: 0.6707 - val_loss: 0.9851 - val_acc: 0.6622\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.9674 - acc: 0.6742 - val_loss: 1.0175 - val_acc: 0.6656\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9675 - acc: 0.6755 - val_loss: 0.9874 - val_acc: 0.6556\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.9792 - acc: 0.6759 - val_loss: 0.9586 - val_acc: 0.6656\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 0.9617 - acc: 0.6779 - val_loss: 0.9954 - val_acc: 0.6589\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 210us/step - loss: 0.9674 - acc: 0.6757 - val_loss: 1.0573 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 0.9807 - acc: 0.6764 - val_loss: 0.9920 - val_acc: 0.6522\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 0.9626 - acc: 0.6757 - val_loss: 1.0537 - val_acc: 0.6606\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 0.9614 - acc: 0.6803 - val_loss: 0.9722 - val_acc: 0.6589\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 0.9624 - acc: 0.6749 - val_loss: 0.9535 - val_acc: 0.6656\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9589 - acc: 0.6760 - val_loss: 0.9681 - val_acc: 0.6672\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 0.9659 - acc: 0.6742 - val_loss: 1.0689 - val_acc: 0.6539\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.0255 - acc: 0.6636 - val_loss: 1.1036 - val_acc: 0.6439\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 0.9608 - acc: 0.6794 - val_loss: 0.9861 - val_acc: 0.6556\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 0.9589 - acc: 0.6764 - val_loss: 0.9941 - val_acc: 0.6589\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 0.9548 - acc: 0.6738 - val_loss: 0.9798 - val_acc: 0.6622\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 0.9577 - acc: 0.6790 - val_loss: 1.1468 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9642 - acc: 0.6770 - val_loss: 1.0554 - val_acc: 0.6672\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 0.9571 - acc: 0.6807 - val_loss: 1.2325 - val_acc: 0.6556\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9719 - acc: 0.6746 - val_loss: 0.9575 - val_acc: 0.6639\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9562 - acc: 0.6755 - val_loss: 0.9628 - val_acc: 0.6722\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 0.9539 - acc: 0.6773 - val_loss: 0.9886 - val_acc: 0.6622\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 0.9542 - acc: 0.6803 - val_loss: 0.9606 - val_acc: 0.6622\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9548 - acc: 0.6794 - val_loss: 0.9455 - val_acc: 0.6622\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9481 - acc: 0.6807 - val_loss: 1.0083 - val_acc: 0.6606\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 0.9497 - acc: 0.6792 - val_loss: 0.9652 - val_acc: 0.6656\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 0.9503 - acc: 0.6790 - val_loss: 0.9492 - val_acc: 0.6689\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 0.9530 - acc: 0.6771 - val_loss: 1.0016 - val_acc: 0.6606\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9528 - acc: 0.6766 - val_loss: 0.9667 - val_acc: 0.6622\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 0.9558 - acc: 0.6744 - val_loss: 0.9754 - val_acc: 0.6539\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9582 - acc: 0.6766 - val_loss: 0.9506 - val_acc: 0.6606\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 0.9489 - acc: 0.6784 - val_loss: 0.9701 - val_acc: 0.6622\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 0.9506 - acc: 0.6762 - val_loss: 0.9529 - val_acc: 0.6689\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 0.9486 - acc: 0.6821 - val_loss: 1.5431 - val_acc: 0.6556\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1186 - acc: 0.6686 - val_loss: 1.0458 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 0.9948 - acc: 0.6685 - val_loss: 0.9897 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 0.9699 - acc: 0.6683 - val_loss: 0.9883 - val_acc: 0.6639\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 0.9465 - acc: 0.6773 - val_loss: 1.1692 - val_acc: 0.6190\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9621 - acc: 0.6757 - val_loss: 0.9803 - val_acc: 0.6506\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9466 - acc: 0.6784 - val_loss: 1.0508 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 185us/step - loss: 0.9493 - acc: 0.6794 - val_loss: 0.9741 - val_acc: 0.6672\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 0.9450 - acc: 0.6792 - val_loss: 0.9513 - val_acc: 0.6672\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9425 - acc: 0.6805 - val_loss: 0.9371 - val_acc: 0.6622\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 0.9459 - acc: 0.6773 - val_loss: 1.3617 - val_acc: 0.5607\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 0.9633 - acc: 0.6771 - val_loss: 0.9638 - val_acc: 0.6622\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 0.9433 - acc: 0.6744 - val_loss: 0.9684 - val_acc: 0.6639\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9426 - acc: 0.6788 - val_loss: 0.9635 - val_acc: 0.6705\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 0.9424 - acc: 0.6792 - val_loss: 0.9381 - val_acc: 0.6672\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 0.9408 - acc: 0.6790 - val_loss: 0.9433 - val_acc: 0.6639\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 0.9432 - acc: 0.6770 - val_loss: 1.1376 - val_acc: 0.6539\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.9493 - acc: 0.6783 - val_loss: 1.5468 - val_acc: 0.6589\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2129 - acc: 0.6686 - val_loss: 1.1644 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.0133 - acc: 0.6686 - val_loss: 0.9689 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9494 - acc: 0.6690 - val_loss: 1.1259 - val_acc: 0.6556\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 0.9535 - acc: 0.6716 - val_loss: 1.0426 - val_acc: 0.6589\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 182us/step - loss: 0.9417 - acc: 0.6723 - val_loss: 1.0149 - val_acc: 0.6639\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 0.9402 - acc: 0.6751 - val_loss: 0.9532 - val_acc: 0.6589\n",
      "5408/5408 [==============================] - 1s 209us/step\n",
      "4006/4006 [==============================] - 1s 208us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 1.6418 - acc: 0.6659 - val_loss: 1.6000 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.5430 - acc: 0.6686 - val_loss: 1.5465 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.5166 - acc: 0.6686 - val_loss: 1.5226 - val_acc: 0.6572\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.4955 - acc: 0.6686 - val_loss: 1.6205 - val_acc: 0.6406\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 186us/step - loss: 1.4980 - acc: 0.6685 - val_loss: 1.4774 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.4458 - acc: 0.6686 - val_loss: 1.4875 - val_acc: 0.6556\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4315 - acc: 0.6683 - val_loss: 1.6206 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.4583 - acc: 0.6686 - val_loss: 1.4675 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.4045 - acc: 0.6686 - val_loss: 1.4048 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.3867 - acc: 0.6686 - val_loss: 1.3994 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3737 - acc: 0.6686 - val_loss: 1.3964 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3617 - acc: 0.6686 - val_loss: 1.4715 - val_acc: 0.6522\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.3621 - acc: 0.6686 - val_loss: 1.4338 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3462 - acc: 0.6686 - val_loss: 1.4474 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.3321 - acc: 0.6686 - val_loss: 1.3450 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3262 - acc: 0.6686 - val_loss: 1.4859 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.3383 - acc: 0.6686 - val_loss: 1.5246 - val_acc: 0.6556\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.3800 - acc: 0.6685 - val_loss: 1.3961 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.3044 - acc: 0.6686 - val_loss: 1.3219 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2953 - acc: 0.6686 - val_loss: 1.4641 - val_acc: 0.6539\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.2992 - acc: 0.6686 - val_loss: 1.4497 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.2815 - acc: 0.6686 - val_loss: 1.2913 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2715 - acc: 0.6686 - val_loss: 1.2731 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2636 - acc: 0.6686 - val_loss: 1.4005 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.2551 - acc: 0.6686 - val_loss: 1.2729 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2470 - acc: 0.6686 - val_loss: 1.4790 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.2531 - acc: 0.6686 - val_loss: 1.2780 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2344 - acc: 0.6686 - val_loss: 1.2478 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.2298 - acc: 0.6686 - val_loss: 1.2311 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2248 - acc: 0.6686 - val_loss: 1.2638 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2196 - acc: 0.6686 - val_loss: 1.3074 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2178 - acc: 0.6688 - val_loss: 1.4604 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.2087 - acc: 0.6686 - val_loss: 1.2077 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1964 - acc: 0.6686 - val_loss: 1.3466 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1957 - acc: 0.6686 - val_loss: 1.2087 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1828 - acc: 0.6686 - val_loss: 1.2490 - val_acc: 0.6589\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1912 - acc: 0.6690 - val_loss: 1.4028 - val_acc: 0.6589\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1770 - acc: 0.6688 - val_loss: 1.2374 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1735 - acc: 0.6688 - val_loss: 1.1789 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1716 - acc: 0.6690 - val_loss: 1.3119 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1628 - acc: 0.6688 - val_loss: 1.2911 - val_acc: 0.6589\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1620 - acc: 0.6688 - val_loss: 1.2329 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1584 - acc: 0.6688 - val_loss: 1.1634 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.1524 - acc: 0.6686 - val_loss: 1.1520 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1451 - acc: 0.6690 - val_loss: 1.1866 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1431 - acc: 0.6686 - val_loss: 1.1539 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1342 - acc: 0.6686 - val_loss: 1.2779 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1376 - acc: 0.6688 - val_loss: 1.4045 - val_acc: 0.6556\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1686 - acc: 0.6690 - val_loss: 1.1408 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1257 - acc: 0.6688 - val_loss: 1.1299 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1233 - acc: 0.6688 - val_loss: 1.1324 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1203 - acc: 0.6688 - val_loss: 1.1823 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1168 - acc: 0.6688 - val_loss: 1.2177 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1125 - acc: 0.6686 - val_loss: 1.1748 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1126 - acc: 0.667 - 1s 194us/step - loss: 1.1112 - acc: 0.6688 - val_loss: 1.1429 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1090 - acc: 0.6690 - val_loss: 1.1087 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1086 - acc: 0.6688 - val_loss: 1.2674 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1052 - acc: 0.6688 - val_loss: 1.1473 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1170 - acc: 0.6694 - val_loss: 1.0968 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0964 - acc: 0.6686 - val_loss: 1.1244 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1045 - acc: 0.6686 - val_loss: 1.1304 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.0945 - acc: 0.6686 - val_loss: 1.1383 - val_acc: 0.6572\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.0906 - acc: 0.6686 - val_loss: 1.1837 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.0879 - acc: 0.6688 - val_loss: 1.2790 - val_acc: 0.6556\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.0936 - acc: 0.6690 - val_loss: 1.1453 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.0867 - acc: 0.6688 - val_loss: 1.1411 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.0848 - acc: 0.6688 - val_loss: 1.0834 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.0778 - acc: 0.6688 - val_loss: 1.0822 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0752 - acc: 0.6688 - val_loss: 1.0821 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.0707 - acc: 0.6688 - val_loss: 1.1391 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0687 - acc: 0.6686 - val_loss: 1.3147 - val_acc: 0.6539\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0818 - acc: 0.6686 - val_loss: 1.0841 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.0687 - acc: 0.6688 - val_loss: 1.1586 - val_acc: 0.6572s: 1.0670 - acc: \n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.0673 - acc: 0.6688 - val_loss: 1.2646 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0681 - acc: 0.6688 - val_loss: 1.4702 - val_acc: 0.6589\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.0709 - acc: 0.6688 - val_loss: 1.3229 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0603 - acc: 0.6688 - val_loss: 1.1780 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.0553 - acc: 0.6690 - val_loss: 1.2202 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0643 - acc: 0.6688 - val_loss: 1.1470 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.0501 - acc: 0.6688 - val_loss: 1.3416 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.0588 - acc: 0.6690 - val_loss: 1.1948 - val_acc: 0.6589\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.0525 - acc: 0.6690 - val_loss: 1.0524 - val_acc: 0.6606\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0483 - acc: 0.6710 - val_loss: 1.1130 - val_acc: 0.6506\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0486 - acc: 0.6701 - val_loss: 1.3422 - val_acc: 0.5874\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0487 - acc: 0.6690 - val_loss: 1.1140 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.0410 - acc: 0.6722 - val_loss: 1.0679 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0343 - acc: 0.6733 - val_loss: 1.0493 - val_acc: 0.6739\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0347 - acc: 0.6716 - val_loss: 1.0889 - val_acc: 0.6606\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.0334 - acc: 0.6722 - val_loss: 1.0470 - val_acc: 0.6639\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0340 - acc: 0.6755 - val_loss: 1.0772 - val_acc: 0.6606\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0338 - acc: 0.6733 - val_loss: 1.0575 - val_acc: 0.6589\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0331 - acc: 0.6714 - val_loss: 1.0721 - val_acc: 0.6672\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.0313 - acc: 0.6764 - val_loss: 1.1533 - val_acc: 0.6622\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.0300 - acc: 0.6801 - val_loss: 1.1271 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.0202 - acc: 0.6783 - val_loss: 1.3421 - val_acc: 0.6273\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.0359 - acc: 0.6731 - val_loss: 1.2022 - val_acc: 0.6622\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.0359 - acc: 0.6751 - val_loss: 1.0528 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.0312 - acc: 0.6766 - val_loss: 1.0380 - val_acc: 0.6606\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.0151 - acc: 0.6783 - val_loss: 1.1007 - val_acc: 0.6689\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.0146 - acc: 0.6794 - val_loss: 1.0425 - val_acc: 0.6722\n",
      "5408/5408 [==============================] - 1s 209us/step\n",
      "4006/4006 [==============================] - 1s 212us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 19.8906 - acc: 0.4519 - val_loss: 6.2130 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 3.4107 - acc: 0.6686 - val_loss: 1.9625 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.6255 - acc: 0.6686 - val_loss: 1.4592 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.3951 - acc: 0.6686 - val_loss: 1.3754 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.3355 - acc: 0.6686 - val_loss: 1.3317 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.3054 - acc: 0.6686 - val_loss: 1.3158 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2930 - acc: 0.6686 - val_loss: 1.3047 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2834 - acc: 0.6686 - val_loss: 1.2953 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2755 - acc: 0.6686 - val_loss: 1.2863 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2673 - acc: 0.6686 - val_loss: 1.2800 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2600 - acc: 0.6686 - val_loss: 1.2726 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2532 - acc: 0.6686 - val_loss: 1.2655 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2468 - acc: 0.6686 - val_loss: 1.2609 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2407 - acc: 0.6686 - val_loss: 1.2566 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2352 - acc: 0.6686 - val_loss: 1.2481 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.2298 - acc: 0.6686 - val_loss: 1.2441 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.2252 - acc: 0.6686 - val_loss: 1.2407 - val_acc: 0.6572\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2201 - acc: 0.6686 - val_loss: 1.2327 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.2158 - acc: 0.6686 - val_loss: 1.2281 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.2116 - acc: 0.6686 - val_loss: 1.2251 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2077 - acc: 0.6686 - val_loss: 1.2220 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.2042 - acc: 0.6686 - val_loss: 1.2176 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.2005 - acc: 0.6686 - val_loss: 1.2140 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1972 - acc: 0.6686 - val_loss: 1.2104 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1941 - acc: 0.6686 - val_loss: 1.2077 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1912 - acc: 0.6686 - val_loss: 1.2052 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1886 - acc: 0.6686 - val_loss: 1.2019 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1859 - acc: 0.6686 - val_loss: 1.2003 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1834 - acc: 0.6686 - val_loss: 1.1975 - val_acc: 0.6572 0s - loss: 1.1810 - acc: 0.\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1811 - acc: 0.6686 - val_loss: 1.1971 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1790 - acc: 0.6686 - val_loss: 1.1939 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1766 - acc: 0.6686 - val_loss: 1.1904 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1745 - acc: 0.6686 - val_loss: 1.1883 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1728 - acc: 0.6686 - val_loss: 1.1877 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1708 - acc: 0.6686 - val_loss: 1.1851 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1692 - acc: 0.6686 - val_loss: 1.1843 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1675 - acc: 0.6686 - val_loss: 1.1811 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1658 - acc: 0.6686 - val_loss: 1.1795 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1640 - acc: 0.668 - 1s 190us/step - loss: 1.1641 - acc: 0.6686 - val_loss: 1.1794 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1628 - acc: 0.6686 - val_loss: 1.1778 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1614 - acc: 0.6686 - val_loss: 1.1761 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1600 - acc: 0.6686 - val_loss: 1.1736 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1586 - acc: 0.6686 - val_loss: 1.1726 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1572 - acc: 0.6686 - val_loss: 1.1713 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1559 - acc: 0.6686 - val_loss: 1.1697 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.1548 - acc: 0.6686 - val_loss: 1.1684 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1534 - acc: 0.6686 - val_loss: 1.1673 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1522 - acc: 0.6686 - val_loss: 1.1660 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1510 - acc: 0.6686 - val_loss: 1.1651 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1497 - acc: 0.6686 - val_loss: 1.1642 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1487 - acc: 0.6686 - val_loss: 1.1627 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1475 - acc: 0.6686 - val_loss: 1.1621 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1465 - acc: 0.6686 - val_loss: 1.1607 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1456 - acc: 0.6686 - val_loss: 1.1598 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1447 - acc: 0.6686 - val_loss: 1.1585 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1440 - acc: 0.6686 - val_loss: 1.1579 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1433 - acc: 0.6686 - val_loss: 1.1570 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1426 - acc: 0.6686 - val_loss: 1.1565 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.1420 - acc: 0.6686 - val_loss: 1.1557 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1414 - acc: 0.6686 - val_loss: 1.1554 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1409 - acc: 0.6686 - val_loss: 1.1546 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1403 - acc: 0.6686 - val_loss: 1.1541 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1399 - acc: 0.6686 - val_loss: 1.1540 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1395 - acc: 0.6686 - val_loss: 1.1534 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1390 - acc: 0.6686 - val_loss: 1.1526 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1385 - acc: 0.6686 - val_loss: 1.1517 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1381 - acc: 0.6686 - val_loss: 1.1518 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1378 - acc: 0.6686 - val_loss: 1.1514 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1374 - acc: 0.6686 - val_loss: 1.1504 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1370 - acc: 0.6686 - val_loss: 1.1502 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.1367 - acc: 0.6686 - val_loss: 1.1500 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1364 - acc: 0.6686 - val_loss: 1.1500 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1362 - acc: 0.6686 - val_loss: 1.1497 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1359 - acc: 0.6686 - val_loss: 1.1492 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1355 - acc: 0.6686 - val_loss: 1.1484 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1353 - acc: 0.6686 - val_loss: 1.1482 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1351 - acc: 0.6686 - val_loss: 1.1480 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1348 - acc: 0.6686 - val_loss: 1.1478 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1346 - acc: 0.6686 - val_loss: 1.1470 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1343 - acc: 0.6686 - val_loss: 1.1472 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1341 - acc: 0.6686 - val_loss: 1.1469 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1339 - acc: 0.6686 - val_loss: 1.1463 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1337 - acc: 0.6686 - val_loss: 1.1459 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1335 - acc: 0.6686 - val_loss: 1.1458 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1333 - acc: 0.6686 - val_loss: 1.1456 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1331 - acc: 0.6686 - val_loss: 1.1452 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1450 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.1446 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1326 - acc: 0.6686 - val_loss: 1.1449 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1446 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1322 - acc: 0.6686 - val_loss: 1.1441 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1443 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1320 - acc: 0.6686 - val_loss: 1.1436 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1319 - acc: 0.6686 - val_loss: 1.1438 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1317 - acc: 0.6686 - val_loss: 1.1437 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1435 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1315 - acc: 0.6686 - val_loss: 1.1430 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1428 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1427 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.1425 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 246us/step\n",
      "4006/4006 [==============================] - 1s 237us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1\n",
      "regularization strength lambda =  1e-05\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 1.5754 - acc: 0.5636 - val_loss: 2.2197 - val_acc: 0.1065\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.6033 - acc: 0.5849 - val_loss: 1.7236 - val_acc: 0.1065\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.5811 - acc: 0.5793 - val_loss: 3.7084 - val_acc: 0.1065\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.6293 - acc: 0.5741 - val_loss: 1.3707 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.4920 - acc: 0.6071 - val_loss: 1.9577 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.5430 - acc: 0.5812 - val_loss: 2.9056 - val_acc: 0.1065\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5757 - acc: 0.5505 - val_loss: 1.2155 - val_acc: 0.6572: 0s - loss: 1.5468 - acc: 0\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.6544 - acc: 0.5525 - val_loss: 3.2627 - val_acc: 0.0582\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.5618 - acc: 0.5601 - val_loss: 1.3000 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5812 - acc: 0.5675 - val_loss: 3.1892 - val_acc: 0.1331\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.5938 - acc: 0.5655 - val_loss: 1.5706 - val_acc: 0.1065\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.5413 - acc: 0.5592 - val_loss: 2.1903 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.5181 - acc: 0.6028 - val_loss: 1.6251 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.4982 - acc: 0.5754 - val_loss: 1.9259 - val_acc: 0.1331\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5581 - acc: 0.5773 - val_loss: 1.7032 - val_acc: 0.1331\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.6503 - acc: 0.5618 - val_loss: 1.3343 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.4816 - acc: 0.5978 - val_loss: 1.3166 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5231 - acc: 0.5941 - val_loss: 1.3939 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5003 - acc: 0.5664 - val_loss: 1.2666 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.5256 - acc: 0.5823 - val_loss: 1.4308 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.5637 - acc: 0.6089 - val_loss: 1.2595 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6550 - acc: 0.5664 - val_loss: 1.4782 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.6149 - acc: 0.5889 - val_loss: 1.5079 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5484 - acc: 0.5741 - val_loss: 3.0035 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.6378 - acc: 0.5575 - val_loss: 1.6262 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.5095 - acc: 0.6100 - val_loss: 2.1592 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.5962 - acc: 0.5379 - val_loss: 1.5572 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.6065 - acc: 0.5949 - val_loss: 1.4783 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5302 - acc: 0.5777 - val_loss: 1.3695 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.5908 - acc: 0.5741 - val_loss: 3.0069 - val_acc: 0.1331\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.5537 - acc: 0.5886 - val_loss: 3.1771 - val_acc: 0.1331\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.5362 - acc: 0.5821 - val_loss: 1.4574 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.5916 - acc: 0.5658 - val_loss: 1.2104 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.4413 - acc: 0.5852 - val_loss: 1.7355 - val_acc: 0.1331\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5089 - acc: 0.5862 - val_loss: 1.3835 - val_acc: 0.1065\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5120 - acc: 0.5486 - val_loss: 1.9457 - val_acc: 0.1331\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.5206 - acc: 0.5989 - val_loss: 1.9206 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5917 - acc: 0.5599 - val_loss: 4.0821 - val_acc: 0.1065\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.5897 - acc: 0.5631 - val_loss: 1.7019 - val_acc: 0.1065\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 1.6552 - acc: 0.5483 - val_loss: 2.5272 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6450 - acc: 0.5412 - val_loss: 2.1738 - val_acc: 0.1331\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.5279 - acc: 0.5993 - val_loss: 1.6021 - val_acc: 0.0582\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.6055 - acc: 0.5488 - val_loss: 3.2346 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.6132 - acc: 0.5521 - val_loss: 1.8459 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.6387 - acc: 0.5457 - val_loss: 1.7849 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.5965 - acc: 0.5740 - val_loss: 1.7667 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.4933 - acc: 0.5725 - val_loss: 1.6718 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5667 - acc: 0.5736 - val_loss: 1.4516 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.5289 - acc: 0.5860 - val_loss: 1.5431 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.5882 - acc: 0.5675 - val_loss: 1.3731 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5542 - acc: 0.5884 - val_loss: 1.6771 - val_acc: 0.6572: 0s - loss: 1.4428 \n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.6045 - acc: 0.5616 - val_loss: 2.2018 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5733 - acc: 0.5806 - val_loss: 1.4085 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.6082 - acc: 0.5734 - val_loss: 1.6608 - val_acc: 0.1065 - loss: 1.5729 - acc: 0.5 - ETA: 0s - loss: 1.5378 - acc: 0.\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.5805 - acc: 0.5773 - val_loss: 1.8475 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.5824 - acc: 0.5668 - val_loss: 1.9861 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.5754 - acc: 0.5464 - val_loss: 4.1696 - val_acc: 0.1065- loss: 1.5543 - acc: 0\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.6213 - acc: 0.5834 - val_loss: 1.5576 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.5396 - acc: 0.5860 - val_loss: 2.3797 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.5324 - acc: 0.5803 - val_loss: 1.2369 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.6493 - acc: 0.5703 - val_loss: 1.3575 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.6071 - acc: 0.5815 - val_loss: 7.0594 - val_acc: 0.1331\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.6347 - acc: 0.5547 - val_loss: 1.7516 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.6067 - acc: 0.5625 - val_loss: 2.8053 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.4677 - acc: 0.6222 - val_loss: 2.4725 - val_acc: 0.1065\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5861 - acc: 0.5693 - val_loss: 1.7175 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.4981 - acc: 0.6045 - val_loss: 1.8405 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.5177 - acc: 0.5629 - val_loss: 1.9347 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.5544 - acc: 0.5780 - val_loss: 1.3345 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.4780 - acc: 0.5729 - val_loss: 1.1995 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.5319 - acc: 0.5740 - val_loss: 1.8358 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.5757 - acc: 0.5766 - val_loss: 2.1831 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4893 - acc: 0.5653 - val_loss: 1.5359 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.5739 - acc: 0.5786 - val_loss: 1.7203 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.4933 - acc: 0.5847 - val_loss: 4.4931 - val_acc: 0.1331\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.5870 - acc: 0.5730 - val_loss: 2.0861 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.5633 - acc: 0.5934 - val_loss: 3.9633 - val_acc: 0.1065\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.6026 - acc: 0.5862 - val_loss: 4.3650 - val_acc: 0.1331\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.5901 - acc: 0.5619 - val_loss: 1.3299 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.4691 - acc: 0.5766 - val_loss: 2.0653 - val_acc: 0.1331\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.6166 - acc: 0.5301 - val_loss: 1.5051 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.5341 - acc: 0.6065 - val_loss: 1.9333 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.4082 - acc: 0.6180 - val_loss: 1.8682 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.5643 - acc: 0.5743 - val_loss: 1.3757 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.5377 - acc: 0.5839 - val_loss: 1.9527 - val_acc: 0.1331\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.6568 - acc: 0.5790 - val_loss: 1.8425 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.4897 - acc: 0.6193 - val_loss: 1.9067 - val_acc: 0.0266\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.5246 - acc: 0.5777 - val_loss: 1.3062 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.5515 - acc: 0.5984 - val_loss: 1.2758 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.5985 - acc: 0.5675 - val_loss: 2.5076 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.6281 - acc: 0.5673 - val_loss: 2.9285 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.5827 - acc: 0.5664 - val_loss: 1.7892 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.6092 - acc: 0.5766 - val_loss: 2.9872 - val_acc: 0.1065\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6472 - acc: 0.5296 - val_loss: 1.3537 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.5321 - acc: 0.5753 - val_loss: 2.0566 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.6388 - acc: 0.5442 - val_loss: 1.4738 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.5755 - acc: 0.5714 - val_loss: 2.2616 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.5696 - acc: 0.5645 - val_loss: 2.4364 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.5623 - acc: 0.5649 - val_loss: 1.2134 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.5382 - acc: 0.5523 - val_loss: 2.0162 - val_acc: 0.1065\n",
      "5408/5408 [==============================] - 1s 218us/step\n",
      "4006/4006 [==============================] - 1s 215us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1\n",
      "regularization strength lambda =  0.0001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 1.4309 - acc: 0.5671 - val_loss: 1.4015 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4347 - acc: 0.6065 - val_loss: 1.3372 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.5121 - acc: 0.5669 - val_loss: 2.4018 - val_acc: 0.1065\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.5286 - acc: 0.5668 - val_loss: 1.7074 - val_acc: 0.1331\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.5385 - acc: 0.6069 - val_loss: 1.3432 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.3453 - acc: 0.6115 - val_loss: 1.1755 - val_acc: 0.6572ss: 1.3325 - acc: 0\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3659 - acc: 0.6209 - val_loss: 1.2702 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4203 - acc: 0.6080 - val_loss: 2.0312 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.4313 - acc: 0.5797 - val_loss: 1.7118 - val_acc: 0.0582\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.4127 - acc: 0.6037 - val_loss: 1.9573 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.5114 - acc: 0.5771 - val_loss: 1.7976 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.4684 - acc: 0.6154 - val_loss: 1.4232 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.3766 - acc: 0.6069 - val_loss: 5.1593 - val_acc: 0.1331\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.5234 - acc: 0.5747 - val_loss: 1.5880 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.4108 - acc: 0.6298 - val_loss: 1.4478 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3938 - acc: 0.6093 - val_loss: 1.5499 - val_acc: 0.1331\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4394 - acc: 0.6163 - val_loss: 1.6553 - val_acc: 0.1065\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.4557 - acc: 0.5653 - val_loss: 1.6671 - val_acc: 0.0582\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.5714 - acc: 0.5714 - val_loss: 2.2047 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.4146 - acc: 0.6187 - val_loss: 1.9393 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.4800 - acc: 0.5939 - val_loss: 1.2087 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.4270 - acc: 0.6048 - val_loss: 1.2319 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.5258 - acc: 0.5936 - val_loss: 2.7429 - val_acc: 0.1065\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.5279 - acc: 0.5943 - val_loss: 2.0127 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.4657 - acc: 0.5999 - val_loss: 1.5249 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.4222 - acc: 0.6263 - val_loss: 1.8885 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.4179 - acc: 0.6159 - val_loss: 1.3471 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.3855 - acc: 0.6311 - val_loss: 1.2724 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.4743 - acc: 0.6063 - val_loss: 1.3655 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.4445 - acc: 0.5782 - val_loss: 2.2498 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.4721 - acc: 0.6071 - val_loss: 3.1698 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.4206 - acc: 0.6180 - val_loss: 2.3462 - val_acc: 0.0582\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.4654 - acc: 0.6163 - val_loss: 1.8941 - val_acc: 0.1065\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.5237 - acc: 0.5838 - val_loss: 1.2243 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.4017 - acc: 0.6209 - val_loss: 2.1672 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.4695 - acc: 0.6087 - val_loss: 1.4031 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.4944 - acc: 0.5808 - val_loss: 1.5840 - val_acc: 0.1065\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.4546 - acc: 0.5803 - val_loss: 1.5581 - val_acc: 0.1065\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.4773 - acc: 0.5629 - val_loss: 1.4157 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.4141 - acc: 0.6174 - val_loss: 1.7041 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.4325 - acc: 0.6004 - val_loss: 1.4130 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.4814 - acc: 0.5640 - val_loss: 1.5360 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.4216 - acc: 0.6076 - val_loss: 1.6292 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.4744 - acc: 0.5906 - val_loss: 1.7694 - val_acc: 0.1065\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4608 - acc: 0.5732 - val_loss: 1.2221 - val_acc: 0.6572\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3803 - acc: 0.6206 - val_loss: 1.5847 - val_acc: 0.1065\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3327 - acc: 0.6501 - val_loss: 1.4284 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3284 - acc: 0.6381 - val_loss: 3.0263 - val_acc: 0.1331\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4281 - acc: 0.6261 - val_loss: 2.0348 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3190 - acc: 0.6581 - val_loss: 1.6780 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3876 - acc: 0.6396 - val_loss: 1.4392 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2902 - acc: 0.6686 - val_loss: 1.2930 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.3170 - acc: 0.6470 - val_loss: 1.6195 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2951 - acc: 0.6387 - val_loss: 1.5664 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.3876 - acc: 0.6317 - val_loss: 1.9133 - val_acc: 0.1065\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.4033 - acc: 0.5952 - val_loss: 1.9847 - val_acc: 0.0582\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4114 - acc: 0.6032 - val_loss: 1.2785 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3240 - acc: 0.6267 - val_loss: 1.3303 - val_acc: 0.65720s - loss: 1.3472 - acc: 0.622 - ETA: 0s - loss: 1.3349 - acc: 0.62\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3362 - acc: 0.6368 - val_loss: 1.5532 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3349 - acc: 0.6291 - val_loss: 2.6141 - val_acc: 0.1331\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.4055 - acc: 0.6178 - val_loss: 1.5961 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.3458 - acc: 0.6383 - val_loss: 2.2206 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.3189 - acc: 0.6492 - val_loss: 1.1967 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3294 - acc: 0.6215 - val_loss: 1.9633 - val_acc: 0.0582\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3999 - acc: 0.5856 - val_loss: 2.3277 - val_acc: 0.0582\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3666 - acc: 0.6045 - val_loss: 1.9633 - val_acc: 0.1065\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.3578 - acc: 0.6085 - val_loss: 1.7719 - val_acc: 0.1331\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3225 - acc: 0.6476 - val_loss: 1.4110 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3091 - acc: 0.6383 - val_loss: 1.2666 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.3212 - acc: 0.6265 - val_loss: 1.5071 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.3622 - acc: 0.6191 - val_loss: 1.2938 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.3541 - acc: 0.6248 - val_loss: 1.5547 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2950 - acc: 0.6374 - val_loss: 1.4745 - val_acc: 0.1065\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.4130 - acc: 0.6156 - val_loss: 1.2228 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.4070 - acc: 0.6161 - val_loss: 2.3695 - val_acc: 0.1331\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.3806 - acc: 0.6366 - val_loss: 2.2946 - val_acc: 0.1331\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.3911 - acc: 0.6121 - val_loss: 3.5840 - val_acc: 0.1331\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.4114 - acc: 0.6280 - val_loss: 1.4267 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.3969 - acc: 0.6389 - val_loss: 3.1920 - val_acc: 0.1331\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3851 - acc: 0.6182 - val_loss: 1.2467 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.3575 - acc: 0.6180 - val_loss: 2.5713 - val_acc: 0.1331\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.3983 - acc: 0.6048 - val_loss: 1.6422 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3175 - acc: 0.6463 - val_loss: 2.1732 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.3310 - acc: 0.6278 - val_loss: 1.6013 - val_acc: 0.1065\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.3349 - acc: 0.6289 - val_loss: 1.3123 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.3269 - acc: 0.6490 - val_loss: 1.4785 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.3945 - acc: 0.6065 - val_loss: 2.1817 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3274 - acc: 0.6182 - val_loss: 3.0651 - val_acc: 0.1331s: 1.3320 - acc: \n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.3997 - acc: 0.6182 - val_loss: 1.2651 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.3348 - acc: 0.6381 - val_loss: 1.5299 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.3352 - acc: 0.6464 - val_loss: 1.4033 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2995 - acc: 0.6355 - val_loss: 2.5355 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3415 - acc: 0.6464 - val_loss: 1.1679 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.3103 - acc: 0.6158 - val_loss: 1.5432 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3588 - acc: 0.6481 - val_loss: 1.6502 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2759 - acc: 0.6494 - val_loss: 2.3090 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3851 - acc: 0.6159 - val_loss: 1.5765 - val_acc: 0.1065\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3344 - acc: 0.6250 - val_loss: 1.9222 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3459 - acc: 0.6440 - val_loss: 2.1629 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.3735 - acc: 0.6128 - val_loss: 2.0325 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 222us/step\n",
      "4006/4006 [==============================] - 1s 239us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1\n",
      "regularization strength lambda =  0.001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 10s 2ms/step - loss: 1.6070 - acc: 0.5643 - val_loss: 2.7307 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.5370 - acc: 0.5936 - val_loss: 1.4100 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.7073 - acc: 0.5494 - val_loss: 6.7295 - val_acc: 0.1065\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.6773 - acc: 0.5766 - val_loss: 2.6967 - val_acc: 0.1331\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.6005 - acc: 0.5895 - val_loss: 2.9332 - val_acc: 0.1065\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6171 - acc: 0.5717 - val_loss: 1.3551 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.5877 - acc: 0.5368 - val_loss: 2.9466 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.5402 - acc: 0.5847 - val_loss: 1.7020 - val_acc: 0.1331\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.5873 - acc: 0.5619 - val_loss: 1.5058 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.6276 - acc: 0.5618 - val_loss: 1.9477 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.5293 - acc: 0.5773 - val_loss: 1.9877 - val_acc: 0.0582\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.5667 - acc: 0.5725 - val_loss: 1.6904 - val_acc: 0.1065\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.4664 - acc: 0.6074 - val_loss: 1.3047 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.4369 - acc: 0.5984 - val_loss: 1.3018 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 1.3951 - acc: 0.5934 - val_loss: 2.6982 - val_acc: 0.1065\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.4235 - acc: 0.6293 - val_loss: 1.8929 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.3393 - acc: 0.6087 - val_loss: 1.3398 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3222 - acc: 0.6359 - val_loss: 1.5306 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.3552 - acc: 0.6468 - val_loss: 3.8933 - val_acc: 0.1065\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2774 - acc: 0.6476 - val_loss: 1.1917 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1938 - acc: 0.6686 - val_loss: 1.3665 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1895 - acc: 0.6686 - val_loss: 1.6697 - val_acc: 0.1331\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1894 - acc: 0.6577 - val_loss: 1.1708 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1804 - acc: 0.6686 - val_loss: 1.1900 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1917 - acc: 0.6686 - val_loss: 1.2179 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1763 - acc: 0.6686 - val_loss: 1.4740 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1880 - acc: 0.6686 - val_loss: 1.7899 - val_acc: 0.1065\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1709 - acc: 0.6568 - val_loss: 1.7761 - val_acc: 0.1331\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1705 - acc: 0.6568 - val_loss: 1.1611 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1439 - acc: 0.6686 - val_loss: 1.2689 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1551 - acc: 0.6686 - val_loss: 1.2064 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1727 - acc: 0.6686 - val_loss: 1.2629 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.1707 - acc: 0.6686 - val_loss: 1.5004 - val_acc: 0.1065\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1708 - acc: 0.6583 - val_loss: 1.1915 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1605 - acc: 0.6686 - val_loss: 1.2318 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1614 - acc: 0.6686 - val_loss: 1.1866 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1530 - acc: 0.6686 - val_loss: 1.2288 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1590 - acc: 0.6686 - val_loss: 1.2206 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1527 - acc: 0.6686 - val_loss: 1.2758 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1476 - acc: 0.6686 - val_loss: 1.1886 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1471 - acc: 0.6686 - val_loss: 1.6255 - val_acc: 0.1065\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1531 - acc: 0.6572 - val_loss: 1.1743 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1379 - acc: 0.6686 - val_loss: 1.2361 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1460 - acc: 0.6686 - val_loss: 1.3275 - val_acc: 0.6572 loss: 1.1424 - acc:\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1479 - acc: 0.6686 - val_loss: 1.2573 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1386 - acc: 0.6686 - val_loss: 1.1533 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1371 - acc: 0.6686 - val_loss: 1.1630 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1374 - acc: 0.6686 - val_loss: 1.1516 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.3736 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1414 - acc: 0.6686 - val_loss: 1.1376 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1376 - acc: 0.6686 - val_loss: 1.1565 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1.1343 - acc: 0.6686 - val_loss: 1.1479 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1380 - acc: 0.6686 - val_loss: 1.1652 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1360 - acc: 0.6686 - val_loss: 1.3392 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1406 - acc: 0.6686 - val_loss: 1.1543 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1358 - acc: 0.6686 - val_loss: 1.1755 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1370 - acc: 0.6686 - val_loss: 1.2082 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1372 - acc: 0.6686 - val_loss: 1.1667 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1350 - acc: 0.6686 - val_loss: 1.4976 - val_acc: 0.1065\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1380 - acc: 0.6609 - val_loss: 1.1672 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.2678 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1353 - acc: 0.6686 - val_loss: 1.2248 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1351 - acc: 0.6686 - val_loss: 1.1547 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1563 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1457 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.2009 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1357 - acc: 0.6686 - val_loss: 1.1762 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1320 - acc: 0.6686 - val_loss: 1.1462 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1521 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1334 - acc: 0.6686 - val_loss: 1.2403 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1338 - acc: 0.6686 - val_loss: 1.1620 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.2351 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1342 - acc: 0.6686 - val_loss: 1.1997 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1361 - acc: 0.6686 - val_loss: 1.1918 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.1528 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1312 - acc: 0.6686 - val_loss: 1.2081 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1355 - acc: 0.6686 - val_loss: 1.1362 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1326 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1430 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1317 - acc: 0.6686 - val_loss: 1.1783 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1301 - acc: 0.6686 - val_loss: 1.1468 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1303 - acc: 0.6686 - val_loss: 1.1614 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.1943 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1318 - acc: 0.6686 - val_loss: 1.1669 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1307 - acc: 0.6686 - val_loss: 1.1822 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.2766 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1344 - acc: 0.6686 - val_loss: 1.1840 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1387 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1301 - acc: 0.6686 - val_loss: 1.1586 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1721 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.1876 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1326 - acc: 0.6686 - val_loss: 1.1611 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1320 - acc: 0.6686 - val_loss: 1.1414 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1300 - acc: 0.6686 - val_loss: 1.1428 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.2343 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1687 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1354 - acc: 0.667 - 1s 247us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.1610 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.2195 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.1519 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.2730 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 2s 288us/step\n",
      "4006/4006 [==============================] - 1s 294us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 11s 2ms/step - loss: 1.7835 - acc: 0.5239 - val_loss: 1.2549 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.4266 - acc: 0.6324 - val_loss: 2.1303 - val_acc: 0.1065\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.7886 - acc: 0.5788 - val_loss: 1.8352 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.5450 - acc: 0.5974 - val_loss: 1.3157 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.2165 - acc: 0.6585 - val_loss: 1.2179 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.1649 - acc: 0.6686 - val_loss: 1.1940 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.1532 - acc: 0.6686 - val_loss: 1.1449 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.1521 - acc: 0.6686 - val_loss: 1.2259 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1405 - acc: 0.6686 - val_loss: 1.5019 - val_acc: 0.1065\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1532 - acc: 0.6588 - val_loss: 1.1892 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1393 - acc: 0.6686 - val_loss: 1.3189 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1491 - acc: 0.6686 - val_loss: 1.1546 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1408 - acc: 0.6686 - val_loss: 1.1655 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1378 - acc: 0.6686 - val_loss: 1.1400 - val_acc: 0.6572\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1426 - acc: 0.6686 - val_loss: 1.1944 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1400 - acc: 0.6686 - val_loss: 1.1573 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1388 - acc: 0.6686 - val_loss: 1.3375 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1399 - acc: 0.6686 - val_loss: 1.2166 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1368 - acc: 0.6686 - val_loss: 1.2624 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1345 - acc: 0.6686 - val_loss: 1.2587 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1377 - acc: 0.6686 - val_loss: 1.9450 - val_acc: 0.1065\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1522 - acc: 0.6581 - val_loss: 1.2753 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1395 - acc: 0.6686 - val_loss: 1.2635 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1368 - acc: 0.6686 - val_loss: 1.1677 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1346 - acc: 0.6686 - val_loss: 1.8651 - val_acc: 0.1331\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.1454 - acc: 0.6601 - val_loss: 1.1388 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1364 - acc: 0.6686 - val_loss: 1.1501 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1326 - acc: 0.6686 - val_loss: 1.3959 - val_acc: 0.1331\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1398 - acc: 0.6570 - val_loss: 1.1383 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1337 - acc: 0.6686 - val_loss: 1.2055 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1363 - acc: 0.6686 - val_loss: 1.1674 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1344 - acc: 0.6686 - val_loss: 1.1476 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1337 - acc: 0.6686 - val_loss: 1.4172 - val_acc: 0.1065\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1351 - acc: 0.6581 - val_loss: 1.2199 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1352 - acc: 0.6686 - val_loss: 1.1690 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1782 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1334 - acc: 0.6686 - val_loss: 1.2560 - val_acc: 0.6572 0s - loss: 1.1465\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1366 - acc: 0.6686 - val_loss: 1.1795 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.1349 - acc: 0.6686 - val_loss: 1.3799 - val_acc: 0.1331\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1364 - acc: 0.6592 - val_loss: 1.1579 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1496 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1315 - acc: 0.6686 - val_loss: 1.2815 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1352 - acc: 0.6686 - val_loss: 1.1788 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1336 - acc: 0.6686 - val_loss: 1.1736 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1474 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1315 - acc: 0.6686 - val_loss: 1.1535 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1312 - acc: 0.6686 - val_loss: 1.1582 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1326 - acc: 0.6686 - val_loss: 1.1495 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1333 - acc: 0.6686 - val_loss: 1.1337 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.2182 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1339 - acc: 0.6686 - val_loss: 1.1447 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1305 - acc: 0.6686 - val_loss: 1.1706 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.1445 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1302 - acc: 0.6686 - val_loss: 1.1369 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1795 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1333 - acc: 0.6686 - val_loss: 1.1648 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1749 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1495 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1496 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1306 - acc: 0.6686 - val_loss: 1.1514 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1604 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1964 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1712 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1306 - acc: 0.6686 - val_loss: 1.1703 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1351 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1307 - acc: 0.6686 - val_loss: 1.1339 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1307 - acc: 0.6686 - val_loss: 1.1402 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1304 - acc: 0.668 - 1s 189us/step - loss: 1.1307 - acc: 0.6686 - val_loss: 1.1357 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1315 - acc: 0.6686 - val_loss: 1.2714 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1333 - acc: 0.6686 - val_loss: 1.1472 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1486 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1393 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1.1305 - acc: 0.6686 - val_loss: 1.1579 - val_acc: 0.6572\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.1425 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1.1300 - acc: 0.6686 - val_loss: 1.1434 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1537 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1643 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1322 - acc: 0.6686 - val_loss: 1.1584 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1697 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.2251 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1317 - acc: 0.6686 - val_loss: 1.1589 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.1858 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1416 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.1352 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1297 - acc: 0.6686 - val_loss: 1.1685 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 187us/step - loss: 1.1320 - acc: 0.6686 - val_loss: 1.1662 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1411 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 193us/step - loss: 1.1296 - acc: 0.6686 - val_loss: 1.1699 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1305 - acc: 0.6686 - val_loss: 1.2087 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 191us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.1461 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1299 - acc: 0.6686 - val_loss: 1.1711 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 188us/step - loss: 1.1301 - acc: 0.6686 - val_loss: 1.1681 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1732 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1905 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 189us/step - loss: 1.1319 - acc: 0.6686 - val_loss: 1.1407 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1298 - acc: 0.6686 - val_loss: 1.1488 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1295 - acc: 0.6686 - val_loss: 1.1352 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1574 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1301 - acc: 0.6686 - val_loss: 1.1435 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.1302 - acc: 0.6686 - val_loss: 1.1722 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 2s 342us/step\n",
      "4006/4006 [==============================] - 1s 278us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  1\n",
      "regularization strength lambda =  1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 1038.8914 - acc: 0.3367 - val_loss: 1109.7480 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1115.3671 - acc: 0.3458 - val_loss: 1121.2006 - val_acc: 0.0083\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.1758 - acc: 0.3382 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1116.5429 - acc: 0.33 - 1s 203us/step - loss: 1116.5361 - acc: 0.3402 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.4526 - acc: 0.3454 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.5152 - acc: 0.3415 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5569 - acc: 0.3389 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5629 - acc: 0.3386 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.5033 - acc: 0.3423 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5122 - acc: 0.3417 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1116.6016 - acc: 0.3362 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5361 - acc: 0.3402 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1116.5432 - acc: 0.33 - ETA: 0s - loss: 1116.4531 - acc: 0.34 - 1s 205us/step - loss: 1116.4645 - acc: 0.3447 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.6225 - acc: 0.3349 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1116.5241 - acc: 0.3410 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1116.5450 - acc: 0.3397 - val_loss: 1121.8859 - val_acc: 0.0083oss: 1116.38\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1116.5390 - acc: 0.3401 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1116.4556 - acc: 0.3452 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1116.5480 - acc: 0.3395 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1116.4079 - acc: 0.3482 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1116.4794 - acc: 0.3438 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1116.5867 - acc: 0.3371 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1116.5539 - acc: 0.3391 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1116.4884 - acc: 0.3432 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.6135 - acc: 0.3354 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1116.5748 - acc: 0.3378 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5629 - acc: 0.3386 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.4735 - acc: 0.3441 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.6046 - acc: 0.3360 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1116.4794 - acc: 0.3438 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.5122 - acc: 0.3417 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1116.5450 - acc: 0.3397 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5450 - acc: 0.3397 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.4556 - acc: 0.3452 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.5241 - acc: 0.3410 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1116.5033 - acc: 0.3423 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1116.4556 - acc: 0.3452 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1116.4914 - acc: 0.3430 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5510 - acc: 0.3393 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5331 - acc: 0.3404 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1116.4645 - acc: 0.3447 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.4914 - acc: 0.3430 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.5450 - acc: 0.3397 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1116.5212 - acc: 0.3412 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.6255 - acc: 0.3347 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5957 - acc: 0.3365 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.4884 - acc: 0.3432 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.5212 - acc: 0.3412 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1116.6612 - acc: 0.3325 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.5450 - acc: 0.3397 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.5778 - acc: 0.3376 - val_loss: 1111.4266 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.5808 - acc: 0.3375 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5748 - acc: 0.3378 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1116.4365 - acc: 0.34 - 1s 202us/step - loss: 1116.5331 - acc: 0.3404 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.4258 - acc: 0.3471 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5212 - acc: 0.3412 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5480 - acc: 0.3395 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.5212 - acc: 0.3412 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1116.5093 - acc: 0.3419 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.4437 - acc: 0.3460 - val_loss: 1121.8861 - val_acc: 0.0083\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1116.5362 - acc: 0.3402 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.4526 - acc: 0.3454 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1116.5897 - acc: 0.3369 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5897 - acc: 0.3369 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.5659 - acc: 0.3384 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.4765 - acc: 0.3439 - val_loss: 1121.8861 - val_acc: 0.0083\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.6733 - acc: 0.3317 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.4080 - acc: 0.3482 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.4586 - acc: 0.3450 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5331 - acc: 0.3404 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5272 - acc: 0.3408 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1116.4497 - acc: 0.3456 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.6345 - acc: 0.3341 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5480 - acc: 0.3395 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.4735 - acc: 0.3441 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.4795 - acc: 0.3437 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.5182 - acc: 0.3413 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1116.5063 - acc: 0.3421 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1116.4675 - acc: 0.3445 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.4735 - acc: 0.3441 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5361 - acc: 0.3402 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 1116.5480 - acc: 0.3395 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.4854 - acc: 0.3434 - val_loss: 1111.4267 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5033 - acc: 0.3423 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1116.5003 - acc: 0.3425 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1116.5033 - acc: 0.3423 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1116.5242 - acc: 0.3410 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 1116.6106 - acc: 0.3356 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 1116.5719 - acc: 0.3380 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1116.4169 - acc: 0.3476 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1116.5808 - acc: 0.3375 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1116.6076 - acc: 0.3358 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1116.4199 - acc: 0.3474 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1116.5570 - acc: 0.3389 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1116.6613 - acc: 0.3325 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1116.5331 - acc: 0.3404 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1116.5808 - acc: 0.3375 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1116.5033 - acc: 0.3423 - val_loss: 1121.8859 - val_acc: 0.0083\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1116.6374 - acc: 0.3339 - val_loss: 1111.4267 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1116.3990 - acc: 0.3487 - val_loss: 1121.8859 - val_acc: 0.008364 - acc: \n",
      "5408/5408 [==============================] - 1s 255us/step\n",
      "4006/4006 [==============================] - 1s 253us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  2\n",
      "regularization strength lambda =  1e-05\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 2.2565 - acc: 0.5142 - val_loss: 1.3813 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.9242 - acc: 0.5292 - val_loss: 1.8359 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 3.4799 - acc: 0.5157 - val_loss: 3.6572 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 3.6207 - acc: 0.5386 - val_loss: 5.4846 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 3.5188 - acc: 0.5481 - val_loss: 5.5221 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 4.2337 - acc: 0.5825 - val_loss: 6.8147 - val_acc: 0.0083\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 3.9962 - acc: 0.5769 - val_loss: 2.7353 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 3.9289 - acc: 0.5607 - val_loss: 5.4774 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 3.7071 - acc: 0.6047 - val_loss: 5.2126 - val_acc: 0.0582\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 3.8747 - acc: 0.6056 - val_loss: 5.2627 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 4.0440 - acc: 0.5986 - val_loss: 4.7193 - val_acc: 0.0582\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 3.7594 - acc: 0.5547 - val_loss: 3.5091 - val_acc: 0.1331\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 4.0698 - acc: 0.5821 - val_loss: 2.9463 - val_acc: 0.0582\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: 3.5258 - acc: 0.5741 - val_loss: 2.5765 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 3.9270 - acc: 0.5908 - val_loss: 4.8731 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 3.7342 - acc: 0.5586 - val_loss: 4.4605 - val_acc: 0.1331\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 4.1224 - acc: 0.5642 - val_loss: 3.0875 - val_acc: 0.0266\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 3.8587 - acc: 0.5431 - val_loss: 4.4405 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 3.8931 - acc: 0.5649 - val_loss: 5.5162 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 3.8390 - acc: 0.5723 - val_loss: 4.2986 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 3.6523 - acc: 0.5239 - val_loss: 5.2307 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 3.7894 - acc: 0.5732 - val_loss: 4.3773 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 3.8389 - acc: 0.5703 - val_loss: 5.4236 - val_acc: 0.0582\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 4.2007 - acc: 0.5577 - val_loss: 4.1215 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 3.6444 - acc: 0.5777 - val_loss: 5.5272 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5272 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5272 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5272 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5272 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 5.3434 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 198us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5271 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 5.3433 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 2s 335us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5270 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 5.3432 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5269 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 5.3800 - acc: 0.6663- ETA: 0s - loss: 5.2026 - acc: - 1s 233us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 5.3431 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5268 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5267 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5267 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 5.3430 - acc: 0.6686 - val_loss: 5.5267 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 4.4410 - acc: 0.5688 - val_loss: 5.3867 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 4.0727 - acc: 0.5969 - val_loss: 4.3081 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 4.0050 - acc: 0.5741 - val_loss: 3.7207 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 3.8746 - acc: 0.5721 - val_loss: 3.3995 - val_acc: 0.1331\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 4.1307 - acc: 0.5782 - val_loss: 3.3930 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 3.9364 - acc: 0.5442 - val_loss: 3.0864 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 3.8133 - acc: 0.5852 - val_loss: 5.4526 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 4.2972 - acc: 0.6566 - val_loss: 4.5729 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 4.2880 - acc: 0.6550 - val_loss: 4.5756 - val_acc: 0.0582\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 4.2157 - acc: 0.6474 - val_loss: 5.2431 - val_acc: 0.0266\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 4.2502 - acc: 0.6566 - val_loss: 4.4973 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 4.1513 - acc: 0.6686 - val_loss: 4.5949 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 4.2063 - acc: 0.6686 - val_loss: 4.5129 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 4.2437 - acc: 0.6470 - val_loss: 4.6023 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 4.1754 - acc: 0.6686 - val_loss: 4.5217 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 4.2390 - acc: 0.6448 - val_loss: 4.7235 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 4.2133 - acc: 0.6574 - val_loss: 4.5826 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 4.1938 - acc: 0.6574 - val_loss: 4.5796 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 4.1828 - acc: 0.6568 - val_loss: 4.5418 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 4.1948 - acc: 0.6590 - val_loss: 4.6177 - val_acc: 0.0582\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 4.2397 - acc: 0.6561 - val_loss: 4.3521 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 4.1790 - acc: 0.6572 - val_loss: 4.2901 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 4.2306 - acc: 0.6577 - val_loss: 4.4732 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 4.2414 - acc: 0.6561 - val_loss: 4.6156 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 4.1448 - acc: 0.6686 - val_loss: 4.4152 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 4.1970 - acc: 0.6686 - val_loss: 5.2812 - val_acc: 0.0582\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 4.2872 - acc: 0.6476 - val_loss: 4.6478 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 4.1844 - acc: 0.6686 - val_loss: 4.2974 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 244us/step\n",
      "4006/4006 [==============================] - 1s 245us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  2\n",
      "regularization strength lambda =  0.0001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 11s 2ms/step - loss: 4.0745 - acc: 0.5477 - val_loss: 3.9328 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 4.3412 - acc: 0.6036 - val_loss: 4.6803 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 4.9392 - acc: 0.6333 - val_loss: 5.5533 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 5.3689 - acc: 0.6686 - val_loss: 5.5520 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 5.3677 - acc: 0.6686 - val_loss: 5.5509 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 5.3666 - acc: 0.6686 - val_loss: 5.5497 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 4.2919 - acc: 0.6074 - val_loss: 3.3058 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 4.3387 - acc: 0.6030 - val_loss: 5.5187 - val_acc: 0.6572 loss: 4.3518 - acc: 0.60\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 4.5933 - acc: 0.6211 - val_loss: 5.4013 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 5.1137 - acc: 0.6686 - val_loss: 4.8830 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 4.8936 - acc: 0.6490 - val_loss: 3.3106 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 4.1543 - acc: 0.5523 - val_loss: 5.3576 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 4.5329 - acc: 0.6098 - val_loss: 3.6596 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 4.6286 - acc: 0.6463 - val_loss: 5.4702 - val_acc: 0.0083\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 4.7657 - acc: 0.6551 - val_loss: 5.0713 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 4.6442 - acc: 0.6585 - val_loss: 5.1453 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 4.6360 - acc: 0.6485 - val_loss: 5.4624 - val_acc: 0.0083\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 4.7693 - acc: 0.6555 - val_loss: 5.7099 - val_acc: 0.0266\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 4.8397 - acc: 0.6572 - val_loss: 5.0457 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 4.1857 - acc: 0.5814 - val_loss: 5.1472 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 4.3296 - acc: 0.6250 - val_loss: 3.9334 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 4.3917 - acc: 0.5995 - val_loss: 5.3304 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 4.4688 - acc: 0.6146 - val_loss: 6.8333 - val_acc: 0.1065\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 4.7456 - acc: 0.6048 - val_loss: 5.5397 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 5.3556 - acc: 0.6686 - val_loss: 5.5390 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 5.3550 - acc: 0.6686 - val_loss: 5.5384 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 5.3544 - acc: 0.6686 - val_loss: 5.5378 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 4.9794 - acc: 0.6422 - val_loss: 5.2630 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 4.7432 - acc: 0.6082 - val_loss: 5.5375 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 5.3535 - acc: 0.6686 - val_loss: 5.5370 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 5.0852 - acc: 0.6352 - val_loss: 3.9571 - val_acc: 0.1065\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 4.1595 - acc: 0.5945 - val_loss: 4.9092 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 4.2542 - acc: 0.5860 - val_loss: 4.2910 - val_acc: 0.1065\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 4.6497 - acc: 0.6065 - val_loss: 4.6253 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 4.4899 - acc: 0.5834 - val_loss: 5.5349 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 5.2285 - acc: 0.6540 - val_loss: 5.5363 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 5.3523 - acc: 0.6686 - val_loss: 5.5358 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 5.3518 - acc: 0.6686 - val_loss: 5.5353 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 5.3514 - acc: 0.6686 - val_loss: 5.5349 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 5.3509 - acc: 0.6686 - val_loss: 5.5344 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 5.3505 - acc: 0.6686 - val_loss: 5.5340 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 5.3501 - acc: 0.6686 - val_loss: 5.5336 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 5.3497 - acc: 0.6686 - val_loss: 5.5332 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 5.3493 - acc: 0.6686 - val_loss: 5.5329 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 5.3489 - acc: 0.6686 - val_loss: 5.5325 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 5.3486 - acc: 0.6686 - val_loss: 5.5322 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 5.3483 - acc: 0.6686 - val_loss: 5.5147 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 4.4021 - acc: 0.6363 - val_loss: 4.0261 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 3.5323 - acc: 0.5163 - val_loss: 2.2791 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 3.7162 - acc: 0.5346 - val_loss: 3.3053 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 3.7736 - acc: 0.5479 - val_loss: 4.6343 - val_acc: 0.6572\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 224us/step - loss: 3.7016 - acc: 0.5392 - val_loss: 2.1006 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 3.5216 - acc: 0.5359 - val_loss: 1.6007 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 3.4485 - acc: 0.5172 - val_loss: 8.8790 - val_acc: 0.1331\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 3.5301 - acc: 0.5531 - val_loss: 1.7354 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 4.2902 - acc: 0.5558 - val_loss: 8.2810 - val_acc: 0.0582\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 3.9583 - acc: 0.5643 - val_loss: 5.1936 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 4.4244 - acc: 0.5806 - val_loss: 11.5484 - val_acc: 0.0083\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 4.7262 - acc: 0.5971 - val_loss: 5.5293 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 2s 312us/step - loss: 5.3454 - acc: 0.6686 - val_loss: 5.5291 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 5.3450 - acc: 0.6686 - val_loss: 4.7959 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 5.2379 - acc: 0.6437 - val_loss: 5.5298 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 4.9814 - acc: 0.6335 - val_loss: 5.2724 - val_acc: 0.1065\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 3.8767 - acc: 0.5462 - val_loss: 9.2801 - val_acc: 0.1065\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 4.0007 - acc: 0.5202 - val_loss: 2.8351 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 3.6479 - acc: 0.5340 - val_loss: 3.1952 - val_acc: 0.1331\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 3.9424 - acc: 0.5290 - val_loss: 3.5989 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 3.9754 - acc: 0.5601 - val_loss: 3.9279 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 3.9134 - acc: 0.6121 - val_loss: 3.6381 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 4.1524 - acc: 0.6250 - val_loss: 3.9144 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 4.0736 - acc: 0.5640 - val_loss: 4.6329 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 3.6786 - acc: 0.5969 - val_loss: 3.1436 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 3.4809 - acc: 0.5261 - val_loss: 3.5489 - val_acc: 0.1331\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 3.7300 - acc: 0.5200 - val_loss: 3.5469 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 3.4436 - acc: 0.5420 - val_loss: 3.1013 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 2.2149 - acc: 0.5433 - val_loss: 3.2947 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 2.7227 - acc: 0.4970 - val_loss: 1.9210 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 2.4959 - acc: 0.4946 - val_loss: 2.8507 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 2.5961 - acc: 0.5207 - val_loss: 3.2435 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 2.5610 - acc: 0.5081 - val_loss: 3.3464 - val_acc: 0.1065\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 2.8384 - acc: 0.4821 - val_loss: 1.8059 - val_acc: 0.1331\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 2.6899 - acc: 0.5028 - val_loss: 1.5269 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 2.5680 - acc: 0.5209 - val_loss: 1.8433 - val_acc: 0.1331\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 2.7074 - acc: 0.4983 - val_loss: 1.4145 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 2.3345 - acc: 0.5257 - val_loss: 2.4114 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 2.8712 - acc: 0.5178 - val_loss: 1.2013 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 2.5395 - acc: 0.5141 - val_loss: 1.8047 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 2.8245 - acc: 0.4867 - val_loss: 2.8128 - val_acc: 0.1331\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 2.7883 - acc: 0.4784 - val_loss: 1.2776 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 2.4699 - acc: 0.5283 - val_loss: 2.2284 - val_acc: 0.1065\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.8753 - acc: 0.5488 - val_loss: 3.0524 - val_acc: 0.1065\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 2.0900 - acc: 0.5335 - val_loss: 4.6200 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 2.1889 - acc: 0.5020 - val_loss: 1.5184 - val_acc: 0.1331\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 2.0256 - acc: 0.5129 - val_loss: 1.5517 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.9253 - acc: 0.5438 - val_loss: 4.2441 - val_acc: 0.1331\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 2.1649 - acc: 0.5170 - val_loss: 1.3099 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.7884 - acc: 0.5725 - val_loss: 1.8789 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 2.0128 - acc: 0.5412 - val_loss: 2.0594 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 2.1020 - acc: 0.5501 - val_loss: 5.1406 - val_acc: 0.0266\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.7423 - acc: 0.5202 - val_loss: 1.5792 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 255us/step\n",
      "4006/4006 [==============================] - 1s 255us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  2\n",
      "regularization strength lambda =  0.001\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 11s 2ms/step - loss: 11.2905 - acc: 0.5183 - val_loss: 10.7039 - val_acc: 0.6572s - loss: 10.4244 - acc: 0. - ETA: 5s - loss: 10.\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 9.8866 - acc: 0.4891 - val_loss: 9.1689 - val_acc: 0.1065\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 7.2803 - acc: 0.4996 - val_loss: 8.4826 - val_acc: 0.1331\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 5.8498 - acc: 0.4978 - val_loss: 4.8627 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 4.1762 - acc: 0.5115 - val_loss: 3.4307 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 3.7432 - acc: 0.5113 - val_loss: 2.2731 - val_acc: 0.6572\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 227us/step - loss: 2.8268 - acc: 0.5146 - val_loss: 2.6778 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 2.5683 - acc: 0.5431 - val_loss: 1.7360 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 2.4347 - acc: 0.5377 - val_loss: 4.0764 - val_acc: 0.1331\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 2.2536 - acc: 0.5242 - val_loss: 2.2124 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.7802 - acc: 0.5699 - val_loss: 1.3156 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4050 - acc: 0.6304 - val_loss: 1.4811 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.4238 - acc: 0.6278 - val_loss: 1.8124 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.5085 - acc: 0.5821 - val_loss: 1.3256 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.4835 - acc: 0.5952 - val_loss: 1.3404 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.4294 - acc: 0.6000 - val_loss: 1.1926 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.4271 - acc: 0.5828 - val_loss: 1.6921 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.4809 - acc: 0.5947 - val_loss: 1.2783 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 2.7330 - acc: 0.6285 - val_loss: 3.0995 - val_acc: 0.1331\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 2.5252 - acc: 0.6378 - val_loss: 2.4317 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 2.0476 - acc: 0.6566 - val_loss: 1.9926 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.7911 - acc: 0.6483 - val_loss: 1.6958 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.5468 - acc: 0.6686 - val_loss: 1.4847 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.5156 - acc: 0.6503 - val_loss: 1.4412 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.3543 - acc: 0.6686 - val_loss: 3.6360 - val_acc: 0.0266\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.4057 - acc: 0.6235 - val_loss: 1.7626 - val_acc: 0.1331\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3493 - acc: 0.6365 - val_loss: 1.4121 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2610 - acc: 0.6686 - val_loss: 1.4032 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1977 - acc: 0.6686 - val_loss: 1.1926 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1632 - acc: 0.6686 - val_loss: 1.2546 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1542 - acc: 0.6686 - val_loss: 1.1579 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1483 - acc: 0.6686 - val_loss: 1.2615 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1481 - acc: 0.6686 - val_loss: 1.2733 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1443 - acc: 0.6686 - val_loss: 1.2855 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1433 - acc: 0.6686 - val_loss: 1.2077 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1382 - acc: 0.6686 - val_loss: 1.1549 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1393 - acc: 0.6686 - val_loss: 1.1974 - val_acc: 0.65720s - loss: 1.1498 - acc: 0.66 - ETA: 0s - loss: 1.1470 - a\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1385 - acc: 0.6686 - val_loss: 1.3552 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1394 - acc: 0.6686 - val_loss: 1.1760 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1350 - acc: 0.6686 - val_loss: 1.2238 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1407 - acc: 0.6686 - val_loss: 1.1609 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1367 - acc: 0.6686 - val_loss: 1.4767 - val_acc: 0.1331\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1402 - acc: 0.6577 - val_loss: 1.1934 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1359 - acc: 0.6686 - val_loss: 1.1659 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.2392 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1335 - acc: 0.6686 - val_loss: 1.2109 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1355 - acc: 0.6686 - val_loss: 1.3177 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1361 - acc: 0.6686 - val_loss: 1.1514 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.1332 - acc: 0.6686 - val_loss: 1.2017 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1346 - acc: 0.6686 - val_loss: 1.2250 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1358 - acc: 0.6686 - val_loss: 1.1952 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1331 - acc: 0.6686 - val_loss: 1.1483 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.2180 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1344 - acc: 0.6686 - val_loss: 1.1442 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1331 - acc: 0.6686 - val_loss: 1.2003 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1335 - acc: 0.6686 - val_loss: 1.2310 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1351 - acc: 0.6686 - val_loss: 1.2004 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.1819 - val_acc: 0.65721s - loss: 1.1398 - acc: 0. - ETA: 0s - loss: 1.1334 -\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1336 - acc: 0.6686 - val_loss: 1.2904 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1331 - acc: 0.6686 - val_loss: 1.1428 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.1739 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1352 - acc: 0.6686 - val_loss: 1.1363 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1540 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1367 - val_acc: 0.6572\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1532 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1318 - acc: 0.6686 - val_loss: 1.1766 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1339 - acc: 0.6686 - val_loss: 1.1903 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1378 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.1441 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.1509 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1962 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1588 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.1840 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1335 - acc: 0.6686 - val_loss: 1.2052 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1333 - acc: 0.6686 - val_loss: 1.1577 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1393 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1445 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1312 - acc: 0.6686 - val_loss: 1.2508 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1354 - acc: 0.6686 - val_loss: 1.1460 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1334 - acc: 0.6686 - val_loss: 1.1605 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1340 - acc: 0.6686 - val_loss: 1.2139 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1614 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1344 - acc: 0.6686 - val_loss: 1.1818 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1518 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1318 - acc: 0.6686 - val_loss: 1.1412 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1349 - acc: 0.6686 - val_loss: 1.2005 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.2467 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 1.1369 - acc: 0.6686 - val_loss: 1.1589 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.1406 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.1308 - acc: 0.6686 - val_loss: 1.2607 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1331 - acc: 0.6686 - val_loss: 1.1503 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1498 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1304 - acc: 0.6686 - val_loss: 1.1427 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1312 - acc: 0.6686 - val_loss: 1.1392 - val_acc: 0.6572s - loss: 1.1301 - acc: 0.6\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1550 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.2550 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1341 - acc: 0.6686 - val_loss: 1.1596 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1315 - acc: 0.6686 - val_loss: 1.1414 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1320 - acc: 0.6686 - val_loss: 1.1488 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.1417 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 253us/step\n",
      "4006/4006 [==============================] - 1s 263us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  2\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 3.8167 - acc: 0.5048 - val_loss: 2.3270 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 20.9420 - acc: 0.5886 - val_loss: 3.3135 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.6403 - acc: 0.6686 - val_loss: 1.1700 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1608 - acc: 0.6686 - val_loss: 1.6431 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2055 - acc: 0.6574 - val_loss: 3.3216 - val_acc: 0.1065\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1906 - acc: 0.6585 - val_loss: 1.3284 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1439 - acc: 0.6686 - val_loss: 1.2846 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.1434 - acc: 0.6686 - val_loss: 1.2983 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1471 - acc: 0.6686 - val_loss: 1.4303 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1417 - acc: 0.6686 - val_loss: 1.1787 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1453 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.1891 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.1619 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1307 - acc: 0.6686 - val_loss: 1.5360 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 5.6464 - acc: 0.6376 - val_loss: 3.1579 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2578 - acc: 0.6686 - val_loss: 1.1612 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1346 - acc: 0.6686 - val_loss: 1.1475 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.1374 - acc: 0.6686 - val_loss: 1.2369 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.2284 - val_acc: 0.6572\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1377 - acc: 0.6686 - val_loss: 1.1514 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1338 - acc: 0.6686 - val_loss: 1.3249 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.2113 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1710 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1353 - acc: 0.6686 - val_loss: 1.3113 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.1346 - acc: 0.6686 - val_loss: 1.1345 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1339 - acc: 0.6686 - val_loss: 1.1786 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: 1.1345 - acc: 0.6686 - val_loss: 1.1562 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1324 - acc: 0.6686 - val_loss: 1.2499 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1382 - acc: 0.6686 - val_loss: 1.1731 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1547 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.2503 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: 1.1352 - acc: 0.6686 - val_loss: 1.1445 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1335 - acc: 0.6686 - val_loss: 1.1393 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1332 - acc: 0.6686 - val_loss: 1.4894 - val_acc: 0.1331\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 1.1402 - acc: 0.6577 - val_loss: 1.1600 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1453 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1343 - acc: 0.6686 - val_loss: 1.1645 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.4477 - val_acc: 0.1065\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1377 - acc: 0.6594 - val_loss: 1.1906 - val_acc: 0.6572oss: 1.1387 - acc: 0.65\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.1459 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: 1.1343 - acc: 0.6686 - val_loss: 1.1891 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1320 - acc: 0.6686 - val_loss: 1.1378 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1349 - acc: 0.6686 - val_loss: 1.1707 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: 1.1338 - acc: 0.6686 - val_loss: 1.1396 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: 1.1314 - acc: 0.6686 - val_loss: 1.2019 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1509 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1317 - acc: 0.6686 - val_loss: 1.1471 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: 1.1322 - acc: 0.6686 - val_loss: 1.1632 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1436 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1312 - acc: 0.6686 - val_loss: 1.1936 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1334 - acc: 0.6686 - val_loss: 1.1370 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1967 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1322 - acc: 0.6686 - val_loss: 1.1599 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1345 - acc: 0.6686 - val_loss: 1.1507 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.2117 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1453 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1304 - acc: 0.6686 - val_loss: 1.1467 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1332 - acc: 0.6686 - val_loss: 1.3138 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1353 - acc: 0.6686 - val_loss: 1.1857 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.1334 - acc: 0.6686 - val_loss: 1.1584 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1326 - acc: 0.6686 - val_loss: 1.4159 - val_acc: 0.1065\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1415 - acc: 0.6551 - val_loss: 1.1877 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1319 - acc: 0.6686 - val_loss: 1.1789 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1317 - acc: 0.6686 - val_loss: 1.1855 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1355 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1296 - acc: 0.6686 - val_loss: 1.1465 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1378 - val_acc: 0.6572 0s - loss: 1.1440 \n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1319 - acc: 0.6686 - val_loss: 1.1655 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1346 - acc: 0.6686 - val_loss: 1.1652 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.1288 - acc: 0.6686 - val_loss: 1.1817 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1299 - acc: 0.6686 - val_loss: 1.2803 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.1356 - acc: 0.6686 - val_loss: 1.1736 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.1766 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1329 - acc: 0.6686 - val_loss: 1.2305 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1305 - acc: 0.6686 - val_loss: 1.1428 - val_acc: 0.6572 0s - loss: 1.1516 -\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1318 - acc: 0.6686 - val_loss: 1.1437 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.1318 - acc: 0.6686 - val_loss: 1.5079 - val_acc: 0.1331\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1386 - acc: 0.6598 - val_loss: 1.1396 - val_acc: 0.6572\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1301 - acc: 0.6686 - val_loss: 1.1423 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 4.5945 - acc: 0.6348 - val_loss: 5.8465 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 4.5435 - acc: 0.6479 - val_loss: 1.2848 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1450 - acc: 0.6686 - val_loss: 1.1352 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.1328 - acc: 0.6686 - val_loss: 1.1394 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1830 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.1317 - acc: 0.6686 - val_loss: 1.1606 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1305 - acc: 0.6686 - val_loss: 1.1874 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.1310 - acc: 0.6686 - val_loss: 1.1376 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.1472 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1349 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.1633 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1313 - acc: 0.6686 - val_loss: 1.1587 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.1298 - acc: 0.6686 - val_loss: 1.1526 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.1300 - acc: 0.6686 - val_loss: 1.2000 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.1332 - acc: 0.6686 - val_loss: 1.1550 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.1323 - acc: 0.6686 - val_loss: 1.1493 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1310 - acc: 0.668 - 1s 261us/step - loss: 1.1312 - acc: 0.6686 - val_loss: 1.1387 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.1327 - acc: 0.6686 - val_loss: 1.1912 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1330 - acc: 0.6686 - val_loss: 1.1415 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1321 - acc: 0.6686 - val_loss: 1.1502 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.1296 - acc: 0.6686 - val_loss: 1.2271 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 2s 348us/step\n",
      "4006/4006 [==============================] - 1s 344us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  2\n",
      "regularization strength lambda =  1\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: nan - acc: 0.0860 - val_loss: nan - val_acc: 0.10657102\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 2s 312us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 2s 321us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065an - acc - ETA: 0s - loss: nan - acc: 0.11\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.10650s -\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 203us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 206us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 201us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 2s 330us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: nan - acc: 0.11 - 1s 200us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 199us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 198us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 202us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 203us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 200us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 192us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 195us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 194us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 196us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 197us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 190us/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.1065\n",
      "5408/5408 [==============================] - 1s 215us/step\n",
      "4006/4006 [==============================] - 1s 225us/step\n",
      "Total time needed to run this loops: 3776.266092348731 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here we use 20 neurons and 5 filters, since it is uncertain what is the best value conbination and to .\n",
    "\n",
    "train_accuracy = np.zeros((len(eta_values), len(lambda_values)))\n",
    "test_accuracy = np.zeros((len(eta_values), len(lambda_values)))\n",
    "\n",
    "\n",
    "t1 = time.clock()\n",
    "for i, eta in enumerate(eta_values):\n",
    "    for j, lmbd in enumerate(lambda_values):\n",
    "        # Creating the model\n",
    "        CNN_model = create_convolutional_NN(input_shape, n_neuron_values[2], n_categories, eta=eta, lmbd=lmbd, \n",
    "                                            n_filters = 5, filter_sizes = receptive_field)\n",
    "        \n",
    "        # Fitting the model with the training data\n",
    "        CNN_model.fit(train, train_labels, epochs = epochs, batch_size = batch_size, verbose = 1, \n",
    "                      validation_data = (valid, valid_labels))\n",
    "        \n",
    "        # Saving accuracy scores \n",
    "        train_accuracy[i][j] = CNN_model.evaluate(train, train_labels)[1]\n",
    "        test_accuracy[i][j] = CNN_model.evaluate(test, test_labels)[1]\n",
    "        \n",
    "t2 = time.clock()\n",
    "print(\"Total time needed to run this loops:\", (t2-t1), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_etaVSlambda(train_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: number of neurons vs. number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  5\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 11s 2ms/step - loss: 2.0391 - acc: 0.1840 - val_loss: 1.7222 - val_acc: 0.6589\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.5575 - acc: 0.6685 - val_loss: 1.4644 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4016 - acc: 0.6686 - val_loss: 1.3878 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3528 - acc: 0.6686 - val_loss: 1.3588 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3330 - acc: 0.6686 - val_loss: 1.3491 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.3235 - acc: 0.6686 - val_loss: 1.3394 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.3156 - acc: 0.6686 - val_loss: 1.3313 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3092 - acc: 0.6686 - val_loss: 1.3248 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.3036 - acc: 0.6686 - val_loss: 1.3189 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2987 - acc: 0.6686 - val_loss: 1.3136 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2941 - acc: 0.6686 - val_loss: 1.3086 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.2899 - acc: 0.6686 - val_loss: 1.3039 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.2859 - acc: 0.6686 - val_loss: 1.2993 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.2822 - acc: 0.6686 - val_loss: 1.2950 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2786 - acc: 0.6686 - val_loss: 1.2911 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2753 - acc: 0.6686 - val_loss: 1.2877 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.2721 - acc: 0.6686 - val_loss: 1.2844 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.2690 - acc: 0.6686 - val_loss: 1.2810 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2660 - acc: 0.6686 - val_loss: 1.2777 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2631 - acc: 0.6686 - val_loss: 1.2740 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2603 - acc: 0.6686 - val_loss: 1.2714 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2576 - acc: 0.6686 - val_loss: 1.2687 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2550 - acc: 0.6686 - val_loss: 1.2658 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2524 - acc: 0.6686 - val_loss: 1.2631 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2500 - acc: 0.6686 - val_loss: 1.2607 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2474 - acc: 0.6686 - val_loss: 1.2581 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2458 - acc: 0.6686 - val_loss: 1.2559 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2430 - acc: 0.6686 - val_loss: 1.2537 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2406 - acc: 0.6686 - val_loss: 1.2513 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2385 - acc: 0.6686 - val_loss: 1.2492 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2363 - acc: 0.6686 - val_loss: 1.2471 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2342 - acc: 0.6686 - val_loss: 1.2450 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.2321 - acc: 0.6686 - val_loss: 1.2427 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2301 - acc: 0.6686 - val_loss: 1.2409 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.2283 - acc: 0.6686 - val_loss: 1.2388 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2263 - acc: 0.6686 - val_loss: 1.2366 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.2300 - acc: 0.6686 - val_loss: 1.2350 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.2227 - acc: 0.6686 - val_loss: 1.2331 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2208 - acc: 0.6686 - val_loss: 1.2306 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2190 - acc: 0.6686 - val_loss: 1.2291 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2174 - acc: 0.6686 - val_loss: 1.2272 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.2157 - acc: 0.6686 - val_loss: 1.2258 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2140 - acc: 0.6686 - val_loss: 1.2241 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2126 - acc: 0.6686 - val_loss: 1.2222 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2109 - acc: 0.6686 - val_loss: 1.2209 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2091 - acc: 0.6686 - val_loss: 1.2195 - val_acc: 0.6572s - loss: 1.1911 - acc: 0. - ETA: 0s - loss: 1.1978 - acc: 0\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2079 - acc: 0.6686 - val_loss: 1.2180 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2059 - acc: 0.6686 - val_loss: 1.2167 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2050 - acc: 0.6686 - val_loss: 1.2152 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2022 - acc: 0.6686 - val_loss: 1.2138 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2022 - acc: 0.6686 - val_loss: 1.2123 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2008 - acc: 0.6686 - val_loss: 1.2111 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.1926 - acc: 0.6686 - val_loss: 1.1965 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1751 - acc: 0.6686 - val_loss: 1.1819 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1665 - acc: 0.6686 - val_loss: 1.1781 - val_acc: 0.6572\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1609 - acc: 0.6686 - val_loss: 1.2473 - val_acc: 0.6572 loss: 1.1641 - acc: 0.66\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1606 - acc: 0.6686 - val_loss: 1.1807 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1477 - acc: 0.6686 - val_loss: 1.1669 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.1415 - acc: 0.6686 - val_loss: 1.1483 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1359 - acc: 0.6686 - val_loss: 1.1953 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1309 - acc: 0.6686 - val_loss: 1.1381 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1281 - acc: 0.6686 - val_loss: 1.1343 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1254 - acc: 0.6686 - val_loss: 1.1248 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1200 - acc: 0.6686 - val_loss: 1.1324 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1228 - acc: 0.6686 - val_loss: 1.1527 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1164 - acc: 0.6686 - val_loss: 1.2088 - val_acc: 0.6572s - loss: 1.1282 - acc: 0.\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1143 - acc: 0.6686 - val_loss: 1.1386 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1096 - acc: 0.6686 - val_loss: 1.1233 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1098 - acc: 0.6686 - val_loss: 1.1074 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1046 - acc: 0.6686 - val_loss: 1.1094 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1036 - acc: 0.6686 - val_loss: 1.1389 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1004 - acc: 0.6686 - val_loss: 1.1157 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0980 - acc: 0.6686 - val_loss: 1.2044 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0910 - acc: 0.6686 - val_loss: 1.3183 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1601 - acc: 0.6686 - val_loss: 1.0760 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.0804 - acc: 0.6686 - val_loss: 1.2067 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0920 - acc: 0.6686 - val_loss: 1.0941 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0737 - acc: 0.6686 - val_loss: 1.1000 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0732 - acc: 0.6686 - val_loss: 1.1004 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0736 - acc: 0.6686 - val_loss: 1.0614 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0707 - acc: 0.6686 - val_loss: 1.3188 - val_acc: 0.6572s - loss: 1.0741 - acc: 0.667 - ETA: 0s - loss: 1.0712 - acc: 0.6\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2059 - acc: 0.6686 - val_loss: 1.2098 - val_acc: 0.6572s - loss: 1.2981 - acc:  - ETA: 0s - loss: 1.2127 - acc: 0.67\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.0752 - acc: 0.6686 - val_loss: 1.0919 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0609 - acc: 0.6686 - val_loss: 1.1189 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.0647 - acc: 0.6686 - val_loss: 1.0986 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0628 - acc: 0.6686 - val_loss: 1.0699 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0602 - acc: 0.6686 - val_loss: 1.2753 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2028 - acc: 0.6686 - val_loss: 1.0979 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0616 - acc: 0.6686 - val_loss: 1.1182 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0569 - acc: 0.6686 - val_loss: 1.0516 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.0542 - acc: 0.6686 - val_loss: 1.1314 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0519 - acc: 0.6686 - val_loss: 1.0478 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.0501 - acc: 0.6686 - val_loss: 1.2450 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0738 - acc: 0.6686 - val_loss: 1.1141 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0503 - acc: 0.6686 - val_loss: 1.1138 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0489 - acc: 0.6686 - val_loss: 1.0483 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.0418 - acc: 0.6685- ETA: 0s - loss: 1.0432 - acc: 0.6 - 1s 257us/step - loss: 1.0416 - acc: 0.6686 - val_loss: 1.0387 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.0447 - acc: 0.6686 - val_loss: 1.0887 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0435 - acc: 0.6686 - val_loss: 1.0326 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0408 - acc: 0.6686 - val_loss: 1.0368 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 2s 278us/step\n",
      "4006/4006 [==============================] - ETA:  - 1s 250us/step\n",
      "5408/5408 [==============================] - 1s 274us/step\n",
      "4006/4006 [==============================] - 1s 308us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  10\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  5\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 1.7338 - acc: 0.6620 - val_loss: 1.5958 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.5164 - acc: 0.6686 - val_loss: 1.4867 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.4427 - acc: 0.6686 - val_loss: 1.4407 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4076 - acc: 0.6686 - val_loss: 1.4140 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3857 - acc: 0.6686 - val_loss: 1.3950 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3695 - acc: 0.6686 - val_loss: 1.3805 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3569 - acc: 0.6686 - val_loss: 1.3687 - val_acc: 0.6572\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3465 - acc: 0.6686 - val_loss: 1.3588 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3377 - acc: 0.6686 - val_loss: 1.3503 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3301 - acc: 0.6686 - val_loss: 1.3427 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3235 - acc: 0.6686 - val_loss: 1.3357 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3175 - acc: 0.6686 - val_loss: 1.3294 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.3119 - acc: 0.6686 - val_loss: 1.3236 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3069 - acc: 0.6686 - val_loss: 1.3188 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3023 - acc: 0.6686 - val_loss: 1.3142 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2980 - acc: 0.6686 - val_loss: 1.3096 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2939 - acc: 0.6686 - val_loss: 1.3054 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2901 - acc: 0.6686 - val_loss: 1.3014 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2863 - acc: 0.6686 - val_loss: 1.2975 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2828 - acc: 0.6686 - val_loss: 1.2941 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2795 - acc: 0.6686 - val_loss: 1.2904 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2762 - acc: 0.6686 - val_loss: 1.2873 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2731 - acc: 0.6686 - val_loss: 1.2838 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2700 - acc: 0.6686 - val_loss: 1.2803 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2670 - acc: 0.6686 - val_loss: 1.2770 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2641 - acc: 0.6686 - val_loss: 1.2741 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2614 - acc: 0.6686 - val_loss: 1.2714 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2586 - acc: 0.6686 - val_loss: 1.2687 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2560 - acc: 0.6686 - val_loss: 1.2661 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2534 - acc: 0.6686 - val_loss: 1.2635 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2510 - acc: 0.6686 - val_loss: 1.2612 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2485 - acc: 0.6686 - val_loss: 1.2586 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2461 - acc: 0.6686 - val_loss: 1.2561 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2438 - acc: 0.6686 - val_loss: 1.2538 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2415 - acc: 0.6686 - val_loss: 1.2515 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2393 - acc: 0.6686 - val_loss: 1.2490 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2371 - acc: 0.6686 - val_loss: 1.2466 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2350 - acc: 0.6686 - val_loss: 1.2446 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2329 - acc: 0.6686 - val_loss: 1.2423 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2309 - acc: 0.6686 - val_loss: 1.2405 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2289 - acc: 0.6686 - val_loss: 1.2387 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2270 - acc: 0.6686 - val_loss: 1.2367 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2251 - acc: 0.6686 - val_loss: 1.2347 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2232 - acc: 0.6686 - val_loss: 1.2328 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2214 - acc: 0.6686 - val_loss: 1.2312 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2189 - acc: 0.6686 - val_loss: 1.2264 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2171 - acc: 0.6686 - val_loss: 1.2261 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2096 - acc: 0.6686 - val_loss: 1.2183 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2040 - acc: 0.6686 - val_loss: 1.2134 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1992 - acc: 0.6686 - val_loss: 1.2257 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1936 - acc: 0.6686 - val_loss: 1.2161 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1880 - acc: 0.6686 - val_loss: 1.2048 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1852 - acc: 0.6686 - val_loss: 1.1950 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1818 - acc: 0.6686 - val_loss: 1.1913 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1770 - acc: 0.6686 - val_loss: 1.1954 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1686 - acc: 0.6686 - val_loss: 1.1806 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1614 - acc: 0.6686 - val_loss: 1.1885 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1576 - acc: 0.6686 - val_loss: 1.2113 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1602 - acc: 0.669 - 1s 217us/step - loss: 1.1595 - acc: 0.6686 - val_loss: 1.2344 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1494 - acc: 0.6686 - val_loss: 1.1630 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1450 - acc: 0.6686 - val_loss: 1.1604 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1367 - acc: 0.6686 - val_loss: 1.2431 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1390 - acc: 0.6686 - val_loss: 1.1523 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1302 - acc: 0.6686 - val_loss: 1.1517 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1304 - acc: 0.6686 - val_loss: 1.1608 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1262 - acc: 0.6686 - val_loss: 1.1489 - val_acc: 0.6572\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1235 - acc: 0.6686 - val_loss: 1.1399 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1204 - acc: 0.6686 - val_loss: 1.1498 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1180 - acc: 0.6686 - val_loss: 1.2204 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1231 - acc: 0.6686 - val_loss: 1.1422 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1124 - acc: 0.6686 - val_loss: 1.1452 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1088 - acc: 0.6686 - val_loss: 1.1269 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1008 - acc: 0.6686 - val_loss: 1.1292 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0923 - acc: 0.6686 - val_loss: 1.1114 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0837 - acc: 0.6686 - val_loss: 1.0917 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0853 - acc: 0.6686 - val_loss: 1.1301 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0621 - acc: 0.6686 - val_loss: 1.1307 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0684 - acc: 0.6686 - val_loss: 1.1205 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0582 - acc: 0.6686 - val_loss: 1.1083 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0453 - acc: 0.6686 - val_loss: 1.0661 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0452 - acc: 0.6686 - val_loss: 1.1122 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0404 - acc: 0.6686 - val_loss: 1.1134 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0375 - acc: 0.6686 - val_loss: 1.2000 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0377 - acc: 0.6686 - val_loss: 1.0704 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0296 - acc: 0.6690 - val_loss: 1.1865 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0378 - acc: 0.6685 - val_loss: 1.0400 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0191 - acc: 0.6686 - val_loss: 1.0569 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0236 - acc: 0.6686 - val_loss: 1.2128 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0224 - acc: 0.6686 - val_loss: 1.0502 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0200 - acc: 0.6686 - val_loss: 1.0448 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0142 - acc: 0.6686 - val_loss: 1.0258 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0081 - acc: 0.6686 - val_loss: 1.0287 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0161 - acc: 0.6686 - val_loss: 1.1077 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0241 - acc: 0.6685 - val_loss: 1.0821 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0127 - acc: 0.6686 - val_loss: 1.0359 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0159 - acc: 0.6690 - val_loss: 1.3967 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0189 - acc: 0.6683 - val_loss: 1.3747 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0165 - acc: 0.6688 - val_loss: 1.0285 - val_acc: 0.6589\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0048 - acc: 0.6686 - val_loss: 1.0206 - val_acc: 0.6556\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0043 - acc: 0.6679 - val_loss: 1.0252 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 229us/step\n",
      "4006/4006 [==============================] - 1s 237us/step\n",
      "5408/5408 [==============================] - 1s 229us/step\n",
      "4006/4006 [==============================] - 1s 266us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  5\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 11s 2ms/step - loss: 2.0219 - acc: 0.2855 - val_loss: 1.6455 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.5143 - acc: 0.6686 - val_loss: 1.4272 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3912 - acc: 0.6686 - val_loss: 1.3763 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.3560 - acc: 0.6686 - val_loss: 1.3573 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3398 - acc: 0.6686 - val_loss: 1.3457 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.3290 - acc: 0.6686 - val_loss: 1.3368 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3206 - acc: 0.6686 - val_loss: 1.3293 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3138 - acc: 0.6686 - val_loss: 1.3232 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.3084 - acc: 0.668 - 1s 226us/step - loss: 1.3085 - acc: 0.6686 - val_loss: 1.3181 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3031 - acc: 0.6686 - val_loss: 1.3137 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2986 - acc: 0.6686 - val_loss: 1.3093 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2944 - acc: 0.6686 - val_loss: 1.3051 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2904 - acc: 0.6686 - val_loss: 1.3014 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2868 - acc: 0.6686 - val_loss: 1.2974 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2835 - acc: 0.6687- ETA: 0s - loss: 1.2745  - 1s 238us/step - loss: 1.2834 - acc: 0.6686 - val_loss: 1.2936 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2800 - acc: 0.6686 - val_loss: 1.2904 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2767 - acc: 0.6686 - val_loss: 1.2872 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.2736 - acc: 0.6686 - val_loss: 1.2839 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 1.2706 - acc: 0.6686 - val_loss: 1.2807 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2676 - acc: 0.6686 - val_loss: 1.2779 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2648 - acc: 0.6686 - val_loss: 1.2748 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2619 - acc: 0.6686 - val_loss: 1.2716 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2593 - acc: 0.6686 - val_loss: 1.2688 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.2566 - acc: 0.6686 - val_loss: 1.2665 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2539 - acc: 0.6686 - val_loss: 1.2640 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2516 - acc: 0.6686 - val_loss: 1.2611 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.2491 - acc: 0.6686 - val_loss: 1.2587 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2467 - acc: 0.6686 - val_loss: 1.2567 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.2444 - acc: 0.6686 - val_loss: 1.2543 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.2422 - acc: 0.6686 - val_loss: 1.2518 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.2399 - acc: 0.6686 - val_loss: 1.2497 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2377 - acc: 0.6686 - val_loss: 1.2473 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.2357 - acc: 0.6686 - val_loss: 1.2454 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.2363 - acc: 0.6686 - val_loss: 1.2460 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.2432 - acc: 0.6686 - val_loss: 1.2397 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2353 - acc: 0.6686 - val_loss: 1.2358 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2307 - acc: 0.6686 - val_loss: 1.2333 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.2271 - acc: 0.6686 - val_loss: 1.2775 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.2556 - acc: 0.6686 - val_loss: 1.2461 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2356 - acc: 0.6686 - val_loss: 1.2389 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2288 - acc: 0.6686 - val_loss: 1.2352 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2248 - acc: 0.6686 - val_loss: 1.2330 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.2220 - acc: 0.6686 - val_loss: 1.2310 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2197 - acc: 0.6686 - val_loss: 1.2292 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2178 - acc: 0.6686 - val_loss: 1.2272 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2158 - acc: 0.6686 - val_loss: 1.2253 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2140 - acc: 0.6686 - val_loss: 1.2235 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2123 - acc: 0.6686 - val_loss: 1.2219 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2106 - acc: 0.6686 - val_loss: 1.2202 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2090 - acc: 0.6686 - val_loss: 1.2185 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.2074 - acc: 0.6686 - val_loss: 1.2170 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2058 - acc: 0.6686 - val_loss: 1.2157 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.2044 - acc: 0.6686 - val_loss: 1.2137 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2030 - acc: 0.6686 - val_loss: 1.2124 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.2015 - acc: 0.6686 - val_loss: 1.2110 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2001 - acc: 0.6686 - val_loss: 1.2099 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1988 - acc: 0.6686 - val_loss: 1.2085 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1974 - acc: 0.6686 - val_loss: 1.2074 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1962 - acc: 0.6686 - val_loss: 1.2057 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1949 - acc: 0.6686 - val_loss: 1.2046 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1939 - acc: 0.6686 - val_loss: 1.2037 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1925 - acc: 0.6686 - val_loss: 1.2104 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1914 - acc: 0.6686 - val_loss: 1.2013 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1901 - acc: 0.6686 - val_loss: 1.2001 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1942 - acc: 0.6686 - val_loss: 1.2020 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1874 - acc: 0.6686 - val_loss: 1.1954 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1843 - acc: 0.6686 - val_loss: 1.1928 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1827 - acc: 0.6686 - val_loss: 1.1912 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1815 - acc: 0.6686 - val_loss: 1.1900 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1803 - acc: 0.6686 - val_loss: 1.1888 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1792 - acc: 0.6686 - val_loss: 1.1873 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1782 - acc: 0.6686 - val_loss: 1.1866 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1772 - acc: 0.6686 - val_loss: 1.1859 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.1763 - acc: 0.6686 - val_loss: 1.1854 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.1754 - acc: 0.6686 - val_loss: 1.1840 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 1.1745 - acc: 0.6686 - val_loss: 1.1836 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1737 - acc: 0.6686 - val_loss: 1.1824 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.1729 - acc: 0.6686 - val_loss: 1.1819 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1720 - acc: 0.6686 - val_loss: 1.1811 - val_acc: 0.6572\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1713 - acc: 0.6686 - val_loss: 1.1804 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1705 - acc: 0.6686 - val_loss: 1.1790 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1698 - acc: 0.6686 - val_loss: 1.1787 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1691 - acc: 0.6686 - val_loss: 1.1781 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1683 - acc: 0.6686 - val_loss: 1.1777 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1677 - acc: 0.6686 - val_loss: 1.1769 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1670 - acc: 0.6686 - val_loss: 1.1762 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1664 - acc: 0.6686 - val_loss: 1.1760 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.1657 - acc: 0.6686 - val_loss: 1.1747 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.1650 - acc: 0.6686 - val_loss: 1.1744 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.1651 - acc: 0.6686 - val_loss: 1.1737 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.1650 - acc: 0.6686 - val_loss: 1.1737 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1649 - acc: 0.6686 - val_loss: 1.1837 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1688 - acc: 0.6686 - val_loss: 1.1803 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1688 - acc: 0.6686 - val_loss: 1.1771 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1623 - acc: 0.6686 - val_loss: 1.1761 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1574 - acc: 0.6686 - val_loss: 1.1778 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1396 - acc: 0.6686 - val_loss: 1.1562 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1348 - acc: 0.6686 - val_loss: 1.1437 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1295 - acc: 0.6686 - val_loss: 1.1449 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1246 - acc: 0.6686 - val_loss: 1.1904 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 241us/step\n",
      "4006/4006 [==============================] - 1s 239us/step\n",
      "5408/5408 [==============================] - 1s 244us/step\n",
      "4006/4006 [==============================] - 1s 250us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  20\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  5\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 2.1820 - acc: 0.2615 - val_loss: 1.9496 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 302us/step - loss: 1.7798 - acc: 0.6686 - val_loss: 1.6942 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.6005 - acc: 0.6686 - val_loss: 1.5759 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.5135 - acc: 0.6686 - val_loss: 1.5011 - val_acc: 0.6572 loss: 1.5106 - acc: 0.67\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.4562 - acc: 0.6686 - val_loss: 1.4455 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4129 - acc: 0.6686 - val_loss: 1.4124 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3847 - acc: 0.6686 - val_loss: 1.3882 - val_acc: 0.6572: 0s - loss: 1.4054 \n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3638 - acc: 0.6686 - val_loss: 1.3695 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3474 - acc: 0.6686 - val_loss: 1.3541 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.3317 - acc: 0.670 - 1s 231us/step - loss: 1.3340 - acc: 0.6686 - val_loss: 1.3420 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3236 - acc: 0.6686 - val_loss: 1.3321 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3147 - acc: 0.6686 - val_loss: 1.3237 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3072 - acc: 0.6686 - val_loss: 1.3165 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3009 - acc: 0.6686 - val_loss: 1.3110 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2957 - acc: 0.6686 - val_loss: 1.3060 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2908 - acc: 0.6686 - val_loss: 1.3010 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2864 - acc: 0.6686 - val_loss: 1.2967 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2824 - acc: 0.6686 - val_loss: 1.2928 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2787 - acc: 0.6686 - val_loss: 1.2893 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2752 - acc: 0.6686 - val_loss: 1.2858 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2718 - acc: 0.6686 - val_loss: 1.2823 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2686 - acc: 0.6686 - val_loss: 1.2787 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2656 - acc: 0.6686 - val_loss: 1.2757 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2626 - acc: 0.6686 - val_loss: 1.2729 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2598 - acc: 0.6686 - val_loss: 1.2700 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2570 - acc: 0.6686 - val_loss: 1.2675 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2544 - acc: 0.6686 - val_loss: 1.2649 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2518 - acc: 0.6686 - val_loss: 1.2618 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2493 - acc: 0.6686 - val_loss: 1.2590 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2468 - acc: 0.6686 - val_loss: 1.2566 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2444 - acc: 0.6686 - val_loss: 1.2544 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2421 - acc: 0.6686 - val_loss: 1.2520 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2398 - acc: 0.6686 - val_loss: 1.2494 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2376 - acc: 0.6686 - val_loss: 1.2474 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2354 - acc: 0.6686 - val_loss: 1.2452 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2333 - acc: 0.6686 - val_loss: 1.2432 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2312 - acc: 0.6686 - val_loss: 1.2409 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2292 - acc: 0.6686 - val_loss: 1.2388 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2271 - acc: 0.6686 - val_loss: 1.2368 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2252 - acc: 0.6686 - val_loss: 1.2349 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2233 - acc: 0.6686 - val_loss: 1.2331 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2215 - acc: 0.6686 - val_loss: 1.2310 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2196 - acc: 0.6686 - val_loss: 1.2294 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2179 - acc: 0.6686 - val_loss: 1.2275 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2161 - acc: 0.6686 - val_loss: 1.2258 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2144 - acc: 0.6686 - val_loss: 1.2243 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2127 - acc: 0.6686 - val_loss: 1.2225 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2111 - acc: 0.6686 - val_loss: 1.2207 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2095 - acc: 0.6686 - val_loss: 1.2189 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.2079 - acc: 0.6686 - val_loss: 1.2176 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2064 - acc: 0.6686 - val_loss: 1.2162 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2049 - acc: 0.6686 - val_loss: 1.2147 - val_acc: 0.6572 - loss: 1.2079 - acc: 0.\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2034 - acc: 0.6686 - val_loss: 1.2131 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2020 - acc: 0.6686 - val_loss: 1.2117 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2006 - acc: 0.6686 - val_loss: 1.2104 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1992 - acc: 0.6686 - val_loss: 1.2087 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1979 - acc: 0.6686 - val_loss: 1.2075 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1965 - acc: 0.6686 - val_loss: 1.2062 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1952 - acc: 0.6686 - val_loss: 1.2051 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1940 - acc: 0.6686 - val_loss: 1.2039 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1927 - acc: 0.6686 - val_loss: 1.2026 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1915 - acc: 0.6686 - val_loss: 1.2014 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1903 - acc: 0.6686 - val_loss: 1.2002 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1892 - acc: 0.6686 - val_loss: 1.1989 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1880 - acc: 0.6686 - val_loss: 1.1979 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1869 - acc: 0.6686 - val_loss: 1.1969 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1858 - acc: 0.6686 - val_loss: 1.1958 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1848 - acc: 0.6686 - val_loss: 1.1943 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1837 - acc: 0.6686 - val_loss: 1.1933 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1827 - acc: 0.6686 - val_loss: 1.1922 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1817 - acc: 0.6686 - val_loss: 1.1914 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1807 - acc: 0.6686 - val_loss: 1.1904 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1797 - acc: 0.6686 - val_loss: 1.1894 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1788 - acc: 0.6686 - val_loss: 1.1885 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1779 - acc: 0.6686 - val_loss: 1.1874 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1770 - acc: 0.6686 - val_loss: 1.1867 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2074 - acc: 0.6686 - val_loss: 1.2166 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1967 - acc: 0.6686 - val_loss: 1.2056 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1886 - acc: 0.6686 - val_loss: 1.2007 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1821 - acc: 0.6686 - val_loss: 1.1972 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1858 - acc: 0.6686 - val_loss: 1.1916 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1794 - acc: 0.6686 - val_loss: 1.1892 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1684 - acc: 0.6686 - val_loss: 1.1874 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1579 - acc: 0.6686 - val_loss: 1.1759 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1482 - acc: 0.6686 - val_loss: 1.1580 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1411 - acc: 0.6686 - val_loss: 1.1755 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1275 - acc: 0.6686 - val_loss: 1.1764 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1561 - acc: 0.6686 - val_loss: 1.1792 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1159 - acc: 0.6686 - val_loss: 1.1012 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0839 - acc: 0.6686 - val_loss: 1.0977 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0703 - acc: 0.6686 - val_loss: 1.0808 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0704 - acc: 0.6686 - val_loss: 1.1126 - val_acc: 0.6572\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0700 - acc: 0.6686 - val_loss: 1.1121 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0633 - acc: 0.6686 - val_loss: 1.0745 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0551 - acc: 0.6686 - val_loss: 1.0552 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0475 - acc: 0.6686 - val_loss: 1.0588 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0442 - acc: 0.6686 - val_loss: 1.1508 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.0704 - acc: 0.6686 - val_loss: 1.0640 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0324 - acc: 0.6686 - val_loss: 1.0974 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0346 - acc: 0.6686 - val_loss: 1.1259 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 246us/step\n",
      "4006/4006 [==============================] - 1s 249us/step\n",
      "5408/5408 [==============================] - 1s 247us/step\n",
      "4006/4006 [==============================] - 1s 254us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  25\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  5\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: 1.6729 - acc: 0.6625 - val_loss: 1.5733 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 1.4987 - acc: 0.6686 - val_loss: 1.4723 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 1.4282 - acc: 0.6686 - val_loss: 1.4284 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.3960 - acc: 0.6686 - val_loss: 1.4064 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.3787 - acc: 0.6686 - val_loss: 1.3921 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.3668 - acc: 0.6686 - val_loss: 1.3811 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.3575 - acc: 0.6686 - val_loss: 1.3723 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.3499 - acc: 0.6686 - val_loss: 1.3645 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.3432 - acc: 0.6686 - val_loss: 1.3574 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 295us/step - loss: 1.3371 - acc: 0.6686 - val_loss: 1.3510 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.3315 - acc: 0.6686 - val_loss: 1.3447 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.3262 - acc: 0.6686 - val_loss: 1.3394 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.3214 - acc: 0.6686 - val_loss: 1.3341 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.3168 - acc: 0.6686 - val_loss: 1.3292 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.3124 - acc: 0.6686 - val_loss: 1.3247 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.3083 - acc: 0.6686 - val_loss: 1.3202 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3043 - acc: 0.6686 - val_loss: 1.3161 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.3005 - acc: 0.6686 - val_loss: 1.3121 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.2968 - acc: 0.6686 - val_loss: 1.3081 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.2933 - acc: 0.6686 - val_loss: 1.3046 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.2898 - acc: 0.6686 - val_loss: 1.3007 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.2867 - acc: 0.6686 - val_loss: 1.2972 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.2833 - acc: 0.6686 - val_loss: 1.2929 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2803 - acc: 0.6686 - val_loss: 1.2912 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.2772 - acc: 0.6686 - val_loss: 1.2881 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2742 - acc: 0.6686 - val_loss: 1.2851 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2713 - acc: 0.6686 - val_loss: 1.2819 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.2685 - acc: 0.6686 - val_loss: 1.2790 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.2657 - acc: 0.6686 - val_loss: 1.2761 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2631 - acc: 0.6686 - val_loss: 1.2734 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.2605 - acc: 0.6686 - val_loss: 1.2709 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.2579 - acc: 0.6686 - val_loss: 1.2683 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2554 - acc: 0.6686 - val_loss: 1.2658 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2530 - acc: 0.6686 - val_loss: 1.2634 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.2506 - acc: 0.6686 - val_loss: 1.2610 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.2483 - acc: 0.6686 - val_loss: 1.2584 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.2460 - acc: 0.6686 - val_loss: 1.2561 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.2437 - acc: 0.6686 - val_loss: 1.2536 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2416 - acc: 0.6686 - val_loss: 1.2514 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.2394 - acc: 0.6686 - val_loss: 1.2492 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.2373 - acc: 0.6686 - val_loss: 1.2472 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.2354 - acc: 0.6686 - val_loss: 1.2452 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.2333 - acc: 0.6686 - val_loss: 1.2432 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.2314 - acc: 0.6686 - val_loss: 1.2412 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.2295 - acc: 0.6686 - val_loss: 1.2393 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.2276 - acc: 0.6686 - val_loss: 1.2375 - val_acc: 0.6572\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.2258 - acc: 0.6686 - val_loss: 1.2357 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.2240 - acc: 0.6686 - val_loss: 1.2338 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.2222 - acc: 0.6686 - val_loss: 1.2320 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2205 - acc: 0.6686 - val_loss: 1.2303 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2188 - acc: 0.6686 - val_loss: 1.2286 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2172 - acc: 0.6686 - val_loss: 1.2269 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.2156 - acc: 0.6686 - val_loss: 1.2251 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.2140 - acc: 0.6686 - val_loss: 1.2236 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.2124 - acc: 0.6686 - val_loss: 1.2219 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.2107 - acc: 0.6686 - val_loss: 1.2205 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2093 - acc: 0.6686 - val_loss: 1.2190 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.2079 - acc: 0.6686 - val_loss: 1.2177 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.2064 - acc: 0.6686 - val_loss: 1.2162 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.2050 - acc: 0.6686 - val_loss: 1.2147 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.2046 - acc: 0.6686 - val_loss: 1.2135 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.2025 - acc: 0.6686 - val_loss: 1.2122 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.2012 - acc: 0.6686 - val_loss: 1.2111 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.1999 - acc: 0.6686 - val_loss: 1.2097 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.1987 - acc: 0.6686 - val_loss: 1.2085 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 2s 295us/step - loss: 1.1974 - acc: 0.6686 - val_loss: 1.2073 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 1.1962 - acc: 0.6686 - val_loss: 1.2060 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.1950 - acc: 0.6686 - val_loss: 1.2046 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.1939 - acc: 0.6686 - val_loss: 1.2034 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.1927 - acc: 0.6686 - val_loss: 1.2025 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1916 - acc: 0.6686 - val_loss: 1.2014 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1905 - acc: 0.6686 - val_loss: 1.2003 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.1894 - acc: 0.6686 - val_loss: 1.1993 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1884 - acc: 0.6686 - val_loss: 1.1981 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.1873 - acc: 0.6686 - val_loss: 1.1972 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.1863 - acc: 0.6686 - val_loss: 1.1961 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 1.1853 - acc: 0.6686 - val_loss: 1.1951 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.1844 - acc: 0.6686 - val_loss: 1.1940 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1834 - acc: 0.6686 - val_loss: 1.1929 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1822 - acc: 0.668 - 2s 298us/step - loss: 1.1825 - acc: 0.6686 - val_loss: 1.1921 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 2s 344us/step - loss: 1.1816 - acc: 0.6686 - val_loss: 1.1913 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.1807 - acc: 0.6686 - val_loss: 1.1906 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.1798 - acc: 0.6686 - val_loss: 1.1898 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.1789 - acc: 0.6686 - val_loss: 1.1888 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.1776 - acc: 0.6686 - val_loss: 1.1856 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.1774 - acc: 0.6686 - val_loss: 1.1865 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 295us/step - loss: 1.1758 - acc: 0.6686 - val_loss: 1.1863 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.1757 - acc: 0.6686 - val_loss: 1.1857 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.1749 - acc: 0.6686 - val_loss: 1.1850 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.1741 - acc: 0.6686 - val_loss: 1.1841 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.1734 - acc: 0.6686 - val_loss: 1.1835 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.1726 - acc: 0.6686 - val_loss: 1.1825 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1719 - acc: 0.6686 - val_loss: 1.1813 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.1699 - acc: 0.6686 - val_loss: 1.1823 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.1683 - acc: 0.6686 - val_loss: 1.1814 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.1701 - acc: 0.6686 - val_loss: 1.1808 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1694 - acc: 0.6686 - val_loss: 1.1800 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1687 - acc: 0.6686 - val_loss: 1.1792 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1680 - acc: 0.6686 - val_loss: 1.1784 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1674 - acc: 0.6686 - val_loss: 1.1778 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 269us/step\n",
      "4006/4006 [==============================] - 1s 254us/step\n",
      "5408/5408 [==============================] - 1s 260us/step\n",
      "4006/4006 [==============================] - 1s 254us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  10\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 11s 2ms/step - loss: 1.7628 - acc: 0.6420 - val_loss: 1.5999 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.5291 - acc: 0.6686 - val_loss: 1.5227 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4770 - acc: 0.6686 - val_loss: 1.4873 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4502 - acc: 0.6686 - val_loss: 1.4652 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4326 - acc: 0.6686 - val_loss: 1.4485 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.4191 - acc: 0.6686 - val_loss: 1.4351 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.4080 - acc: 0.6686 - val_loss: 1.4235 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3985 - acc: 0.6686 - val_loss: 1.4133 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3902 - acc: 0.6686 - val_loss: 1.4042 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3825 - acc: 0.6686 - val_loss: 1.3963 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3758 - acc: 0.6686 - val_loss: 1.3890 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3693 - acc: 0.6686 - val_loss: 1.3817 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.3632 - acc: 0.6686 - val_loss: 1.3756 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.3576 - acc: 0.6686 - val_loss: 1.3694 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3522 - acc: 0.6686 - val_loss: 1.3639 - val_acc: 0.6572: 0s - loss: 1.3496 - acc: 0.67\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.3472 - acc: 0.6686 - val_loss: 1.3587 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.3423 - acc: 0.6686 - val_loss: 1.3536 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3376 - acc: 0.6686 - val_loss: 1.3487 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.3331 - acc: 0.6686 - val_loss: 1.3438 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3287 - acc: 0.6686 - val_loss: 1.3391 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3244 - acc: 0.6686 - val_loss: 1.3346 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.3203 - acc: 0.6686 - val_loss: 1.3303 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3163 - acc: 0.6686 - val_loss: 1.3260 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3124 - acc: 0.6686 - val_loss: 1.3219 - val_acc: 0.6572 - loss: 1.3113 - acc: \n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3086 - acc: 0.6686 - val_loss: 1.3180 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3049 - acc: 0.6686 - val_loss: 1.3144 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.3013 - acc: 0.6686 - val_loss: 1.3106 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2978 - acc: 0.6686 - val_loss: 1.3070 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2947 - acc: 0.6681- ETA: 0s - loss: 1.2934 - acc: 0 - 1s 219us/step - loss: 1.2944 - acc: 0.6686 - val_loss: 1.3039 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2910 - acc: 0.6686 - val_loss: 1.3006 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2878 - acc: 0.6686 - val_loss: 1.2973 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.2846 - acc: 0.6686 - val_loss: 1.2941 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2815 - acc: 0.6686 - val_loss: 1.2906 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2784 - acc: 0.6686 - val_loss: 1.2875 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2754 - acc: 0.6686 - val_loss: 1.2845 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2725 - acc: 0.6686 - val_loss: 1.2818 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2697 - acc: 0.6686 - val_loss: 1.2786 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2669 - acc: 0.6686 - val_loss: 1.2760 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2641 - acc: 0.6686 - val_loss: 1.2731 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2615 - acc: 0.6686 - val_loss: 1.2705 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2589 - acc: 0.6686 - val_loss: 1.2680 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.2563 - acc: 0.6686 - val_loss: 1.2654 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.2538 - acc: 0.6686 - val_loss: 1.2627 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2514 - acc: 0.6686 - val_loss: 1.2603 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2490 - acc: 0.6686 - val_loss: 1.2580 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.2466 - acc: 0.6686 - val_loss: 1.2558 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2444 - acc: 0.6686 - val_loss: 1.2535 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 1.2421 - acc: 0.6686 - val_loss: 1.2510 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.2399 - acc: 0.6686 - val_loss: 1.2489 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2378 - acc: 0.6686 - val_loss: 1.2470 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2357 - acc: 0.6686 - val_loss: 1.2448 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2336 - acc: 0.6686 - val_loss: 1.2426 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.2317 - acc: 0.6686 - val_loss: 1.2408 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.2297 - acc: 0.6686 - val_loss: 1.2387 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2277 - acc: 0.6686 - val_loss: 1.2368 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2259 - acc: 0.6686 - val_loss: 1.2350 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2240 - acc: 0.6686 - val_loss: 1.2331 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2222 - acc: 0.6686 - val_loss: 1.2312 - val_acc: 0.6572\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2204 - acc: 0.6686 - val_loss: 1.2294 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2187 - acc: 0.6686 - val_loss: 1.2279 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.2170 - acc: 0.6686 - val_loss: 1.2260 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2154 - acc: 0.6686 - val_loss: 1.2243 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.2137 - acc: 0.6686 - val_loss: 1.2229 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.2121 - acc: 0.6686 - val_loss: 1.2215 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.2106 - acc: 0.6686 - val_loss: 1.2199 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2091 - acc: 0.6686 - val_loss: 1.2182 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.2076 - acc: 0.6686 - val_loss: 1.2166 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.2061 - acc: 0.6686 - val_loss: 1.2153 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2047 - acc: 0.6686 - val_loss: 1.2135 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.2033 - acc: 0.6686 - val_loss: 1.2123 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2019 - acc: 0.6686 - val_loss: 1.2111 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2006 - acc: 0.6686 - val_loss: 1.2099 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1992 - acc: 0.6686 - val_loss: 1.2087 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1979 - acc: 0.6686 - val_loss: 1.2073 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1967 - acc: 0.6686 - val_loss: 1.2062 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1954 - acc: 0.6686 - val_loss: 1.2051 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1942 - acc: 0.6686 - val_loss: 1.2036 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1930 - acc: 0.6686 - val_loss: 1.2023 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1919 - acc: 0.6686 - val_loss: 1.2011 - val_acc: 0.6572s - loss: 1.1985 - acc: 0.\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1907 - acc: 0.6686 - val_loss: 1.1999 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1896 - acc: 0.6686 - val_loss: 1.1987 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.1885 - acc: 0.6686 - val_loss: 1.1976 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.1875 - acc: 0.6686 - val_loss: 1.1964 - val_acc: 0.6572s: 1.1772 - acc\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1864 - acc: 0.6686 - val_loss: 1.1952 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1812 - acc: 0.670 - 1s 229us/step - loss: 1.1854 - acc: 0.6686 - val_loss: 1.1944 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1844 - acc: 0.6686 - val_loss: 1.1934 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1834 - acc: 0.6686 - val_loss: 1.1927 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1824 - acc: 0.6686 - val_loss: 1.1918 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1815 - acc: 0.6686 - val_loss: 1.1909 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1806 - acc: 0.6686 - val_loss: 1.1897 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1797 - acc: 0.6686 - val_loss: 1.1889 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1788 - acc: 0.6686 - val_loss: 1.1880 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1779 - acc: 0.6686 - val_loss: 1.1869 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1771 - acc: 0.6686 - val_loss: 1.1860 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1762 - acc: 0.6686 - val_loss: 1.1850 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1755 - acc: 0.6686 - val_loss: 1.1844 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1746 - acc: 0.6686 - val_loss: 1.1839 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1738 - acc: 0.6686 - val_loss: 1.1828 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1731 - acc: 0.6686 - val_loss: 1.1820 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1723 - acc: 0.6686 - val_loss: 1.1813 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 269us/step\n",
      "4006/4006 [==============================] - 1s 258us/step\n",
      "5408/5408 [==============================] - 1s 266us/step\n",
      "4006/4006 [==============================] - 1s 264us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  10\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  10\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 1.7818 - acc: 0.5196 - val_loss: 1.5581 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.5020 - acc: 0.6686 - val_loss: 1.4645 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4478 - acc: 0.6686 - val_loss: 1.4432 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4291 - acc: 0.6686 - val_loss: 1.4313 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.4187 - acc: 0.6686 - val_loss: 1.4218 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4116 - acc: 0.6686 - val_loss: 1.4212 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4069 - acc: 0.6686 - val_loss: 1.4139 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3973 - acc: 0.6686 - val_loss: 1.4006 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3897 - acc: 0.6686 - val_loss: 1.3962 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3846 - acc: 0.6686 - val_loss: 1.3891 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3786 - acc: 0.6686 - val_loss: 1.3856 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.3732 - acc: 0.6686 - val_loss: 1.3789 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.3681 - acc: 0.6686 - val_loss: 1.3765 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.3617 - acc: 0.6686 - val_loss: 1.3699 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.3580 - acc: 0.6686 - val_loss: 1.3600 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.3515 - acc: 0.6686 - val_loss: 1.3781 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3631 - acc: 0.6686 - val_loss: 1.3686 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3544 - acc: 0.6686 - val_loss: 1.3627 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3480 - acc: 0.6686 - val_loss: 1.3577 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.3429 - acc: 0.6686 - val_loss: 1.3525 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.3374 - acc: 0.6686 - val_loss: 1.4097 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3405 - acc: 0.6686 - val_loss: 1.3960 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 295us/step - loss: 1.3281 - acc: 0.6686 - val_loss: 1.3522 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 1.3037 - acc: 0.6686 - val_loss: 1.3036 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.2873 - acc: 0.6686 - val_loss: 1.2995 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.2752 - acc: 0.6686 - val_loss: 1.3134 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.2676 - acc: 0.6686 - val_loss: 1.2758 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.2589 - acc: 0.6686 - val_loss: 1.2743 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.2522 - acc: 0.6686 - val_loss: 1.2737 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.2440 - acc: 0.6686 - val_loss: 1.2410 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2374 - acc: 0.6686 - val_loss: 1.2446 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.2254 - acc: 0.6686 - val_loss: 1.3208 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.2235 - acc: 0.6686 - val_loss: 1.2888 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2123 - acc: 0.6686 - val_loss: 1.2530 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.2071 - acc: 0.6686 - val_loss: 1.3105 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.2087 - acc: 0.6686 - val_loss: 1.2679 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.2067 - acc: 0.6686 - val_loss: 1.2347 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.1909 - acc: 0.6686 - val_loss: 1.2084 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1844 - acc: 0.6686 - val_loss: 1.2132 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1764 - acc: 0.6686 - val_loss: 1.1915 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.1721 - acc: 0.6686 - val_loss: 1.2221 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1687 - acc: 0.6686 - val_loss: 1.1703 - val_acc: 0.6572 - loss: 1.1311\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.1609 - acc: 0.6686 - val_loss: 1.2694 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.1602 - acc: 0.6686 - val_loss: 1.2023 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.1519 - acc: 0.6686 - val_loss: 1.2431 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 1.1505 - acc: 0.6686 - val_loss: 1.1894 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1427 - acc: 0.6686 - val_loss: 1.1550 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1345 - acc: 0.6686 - val_loss: 1.1536 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.1316 - acc: 0.6686 - val_loss: 1.1429 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1307 - acc: 0.6686 - val_loss: 1.1300 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1272 - acc: 0.6686 - val_loss: 1.2072 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 1.1445 - acc: 0.6668 - val_loss: 1.1747 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1181 - acc: 0.6675 - val_loss: 1.2140 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.1328 - acc: 0.6699 - val_loss: 1.1723 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.1322 - acc: 0.6696 - val_loss: 1.1083 - val_acc: 0.6639\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1109 - acc: 0.6688 - val_loss: 1.1341 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1025 - acc: 0.6709 - val_loss: 1.1333 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0991 - acc: 0.6705 - val_loss: 1.3032 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.1080 - acc: 0.6760 - val_loss: 1.1417 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.0991 - acc: 0.6692 - val_loss: 1.7332 - val_acc: 0.2795\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.1167 - acc: 0.6648 - val_loss: 1.1077 - val_acc: 0.6606\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.0782 - acc: 0.6729 - val_loss: 1.0996 - val_acc: 0.6639\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.0713 - acc: 0.6725 - val_loss: 1.0699 - val_acc: 0.6606\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 2s 338us/step - loss: 1.0700 - acc: 0.6707 - val_loss: 1.0939 - val_acc: 0.6556\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 2s 376us/step - loss: 1.0721 - acc: 0.6718 - val_loss: 1.2776 - val_acc: 0.5957\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 2s 365us/step - loss: 1.0730 - acc: 0.6707 - val_loss: 1.1299 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.0609 - acc: 0.6703 - val_loss: 1.0428 - val_acc: 0.6606\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0516 - acc: 0.6722 - val_loss: 1.0494 - val_acc: 0.6539\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 1.0437 - acc: 0.6749 - val_loss: 1.0532 - val_acc: 0.6589\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.0488 - acc: 0.6720 - val_loss: 1.1019 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 2s 350us/step - loss: 1.0470 - acc: 0.6751 - val_loss: 1.1273 - val_acc: 0.6572\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0380 - acc: 0.6790 - val_loss: 1.0433 - val_acc: 0.6739\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.0375 - acc: 0.6820 - val_loss: 1.0411 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.0313 - acc: 0.6757 - val_loss: 1.1100 - val_acc: 0.6656\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.0465 - acc: 0.6696 - val_loss: 1.0931 - val_acc: 0.6589\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.0343 - acc: 0.6788 - val_loss: 1.0242 - val_acc: 0.6722\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0296 - acc: 0.6823 - val_loss: 1.0848 - val_acc: 0.6589\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0241 - acc: 0.6821 - val_loss: 1.0847 - val_acc: 0.6423\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.0231 - acc: 0.6823 - val_loss: 1.1518 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0436 - acc: 0.6777 - val_loss: 1.1508 - val_acc: 0.6373\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.0163 - acc: 0.6840 - val_loss: 1.0258 - val_acc: 0.6755\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0137 - acc: 0.6834 - val_loss: 1.0800 - val_acc: 0.6606\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0154 - acc: 0.6786 - val_loss: 1.0429 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 1.0152 - acc: 0.6847 - val_loss: 1.0688 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.0130 - acc: 0.6812 - val_loss: 1.0686 - val_acc: 0.6639- loss: 1.0122 - acc\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.0122 - acc: 0.6823 - val_loss: 1.1379 - val_acc: 0.6556\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.0153 - acc: 0.6818 - val_loss: 1.0237 - val_acc: 0.6622\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0081 - acc: 0.6840 - val_loss: 1.0929 - val_acc: 0.6489\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.0118 - acc: 0.6783 - val_loss: 1.0176 - val_acc: 0.6722\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.0060 - acc: 0.6818 - val_loss: 1.1111 - val_acc: 0.6323\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 0.9993 - acc: 0.6866 - val_loss: 1.0131 - val_acc: 0.6805\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 0.9994 - acc: 0.6858 - val_loss: 1.0075 - val_acc: 0.6705\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.0015 - acc: 0.6849 - val_loss: 1.1933 - val_acc: 0.5973\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0048 - acc: 0.6770 - val_loss: 1.0515 - val_acc: 0.6556\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 0.9953 - acc: 0.6818 - val_loss: 1.0354 - val_acc: 0.6722\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 0.9986 - acc: 0.6825 - val_loss: 1.0624 - val_acc: 0.6606\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 0.9937 - acc: 0.6844 - val_loss: 1.0406 - val_acc: 0.6755\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 0.9991 - acc: 0.6825 - val_loss: 1.3231 - val_acc: 0.4825\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 0.9998 - acc: 0.6790 - val_loss: 1.0571 - val_acc: 0.6722\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 0.9886 - acc: 0.6847 - val_loss: 1.0425 - val_acc: 0.6606\n",
      "5408/5408 [==============================] - 1s 230us/step\n",
      "4006/4006 [==============================] - 1s 234us/step\n",
      "5408/5408 [==============================] - 1s 237us/step\n",
      "4006/4006 [==============================] - 1s 233us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  10\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 1.8831 - acc: 0.5074 - val_loss: 1.6573 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.5751 - acc: 0.6686 - val_loss: 1.5500 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.5067 - acc: 0.6686 - val_loss: 1.5027 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.4709 - acc: 0.6689- ETA: 0s - loss: 1.4771 - 1s 262us/step - loss: 1.4711 - acc: 0.6686 - val_loss: 1.4756 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.4499 - acc: 0.6686 - val_loss: 1.4561 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.4345 - acc: 0.6686 - val_loss: 1.4421 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.4229 - acc: 0.6686 - val_loss: 1.4313 - val_acc: 0.6572ss: 1.4184 - acc: 0.67\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.4135 - acc: 0.6686 - val_loss: 1.4222 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.4055 - acc: 0.6686 - val_loss: 1.4146 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.3983 - acc: 0.6686 - val_loss: 1.4074 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.3917 - acc: 0.6686 - val_loss: 1.3999 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 2s 313us/step - loss: 1.3854 - acc: 0.6686 - val_loss: 1.3935 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 323us/step - loss: 1.3795 - acc: 0.6686 - val_loss: 1.3870 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 2s 314us/step - loss: 1.3739 - acc: 0.6686 - val_loss: 1.3815 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.3685 - acc: 0.6686 - val_loss: 1.3766 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.3632 - acc: 0.6686 - val_loss: 1.3715 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.3582 - acc: 0.6686 - val_loss: 1.3662 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.3533 - acc: 0.6686 - val_loss: 1.3615 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.3485 - acc: 0.6686 - val_loss: 1.3569 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.3438 - acc: 0.6686 - val_loss: 1.3522 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 2s 298us/step - loss: 1.3392 - acc: 0.6686 - val_loss: 1.3469 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.3347 - acc: 0.6686 - val_loss: 1.3427 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.3305 - acc: 0.6686 - val_loss: 1.3382 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.3261 - acc: 0.6686 - val_loss: 1.3340 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.3220 - acc: 0.6686 - val_loss: 1.3294 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.3180 - acc: 0.6686 - val_loss: 1.3257 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 1.3140 - acc: 0.6686 - val_loss: 1.3216 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.3102 - acc: 0.6686 - val_loss: 1.3180 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3064 - acc: 0.6686 - val_loss: 1.3145 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3026 - acc: 0.6686 - val_loss: 1.3098 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2991 - acc: 0.6686 - val_loss: 1.3064 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2955 - acc: 0.6686 - val_loss: 1.3033 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2920 - acc: 0.6686 - val_loss: 1.2999 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2887 - acc: 0.6686 - val_loss: 1.2970 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2854 - acc: 0.6686 - val_loss: 1.2934 - val_acc: 0.6572s - loss: 1.2855 - acc: 0.668\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2822 - acc: 0.6686 - val_loss: 1.2907 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2790 - acc: 0.6686 - val_loss: 1.2873 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.2759 - acc: 0.6686 - val_loss: 1.2845 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2728 - acc: 0.6686 - val_loss: 1.2809 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2699 - acc: 0.6686 - val_loss: 1.2784 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.2670 - acc: 0.6686 - val_loss: 1.2754 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2642 - acc: 0.6686 - val_loss: 1.2728 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2614 - acc: 0.6686 - val_loss: 1.2698 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2586 - acc: 0.6686 - val_loss: 1.2664 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2561 - acc: 0.6686 - val_loss: 1.2637 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2535 - acc: 0.6686 - val_loss: 1.2615 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2508 - acc: 0.6686 - val_loss: 1.2594 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2483 - acc: 0.6686 - val_loss: 1.2569 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2458 - acc: 0.6686 - val_loss: 1.2546 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2435 - acc: 0.6686 - val_loss: 1.2514 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2412 - acc: 0.6686 - val_loss: 1.2498 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2387 - acc: 0.6686 - val_loss: 1.2474 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2363 - acc: 0.6686 - val_loss: 1.2451 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2341 - acc: 0.6686 - val_loss: 1.2424 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2319 - acc: 0.6686 - val_loss: 1.2416 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2303 - acc: 0.6686 - val_loss: 1.2384 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2280 - acc: 0.6686 - val_loss: 1.2355 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2259 - acc: 0.6686 - val_loss: 1.2337 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2239 - acc: 0.6686 - val_loss: 1.2318 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.2216 - acc: 0.6686 - val_loss: 1.2803 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2386 - acc: 0.6686 - val_loss: 1.2388 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.2088 - acc: 0.6686 - val_loss: 1.2395 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1778 - acc: 0.6686 - val_loss: 1.2265 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1672 - acc: 0.6686 - val_loss: 1.2157 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.1564 - acc: 0.6686 - val_loss: 1.2395 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1504 - acc: 0.6686 - val_loss: 1.2092 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1461 - acc: 0.6686 - val_loss: 1.1526 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1402 - acc: 0.6686 - val_loss: 1.1479 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1311 - acc: 0.6686 - val_loss: 1.2314 - val_acc: 0.65720s - loss: 1.1283 - acc: 0.67\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1405 - acc: 0.6686 - val_loss: 1.1878 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1112 - acc: 0.6686 - val_loss: 1.2184 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1012 - acc: 0.6686 - val_loss: 1.1472 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0949 - acc: 0.6686 - val_loss: 1.2124 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0828 - acc: 0.6686 - val_loss: 1.1198 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0742 - acc: 0.6686 - val_loss: 1.0989 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0641 - acc: 0.6686 - val_loss: 1.0679 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0620 - acc: 0.6686 - val_loss: 1.3094 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1114 - acc: 0.6686 - val_loss: 1.1149 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.0625 - acc: 0.6686 - val_loss: 1.3743 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0791 - acc: 0.6686 - val_loss: 1.1177 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0462 - acc: 0.6686 - val_loss: 1.2701 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0454 - acc: 0.6686 - val_loss: 1.0917 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0403 - acc: 0.6686 - val_loss: 1.1342 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0384 - acc: 0.6686 - val_loss: 1.0609 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0317 - acc: 0.6686 - val_loss: 1.0849 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0312 - acc: 0.6686 - val_loss: 1.0662 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0280 - acc: 0.6686 - val_loss: 1.0562 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0223 - acc: 0.6686 - val_loss: 1.0393 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0181 - acc: 0.6686 - val_loss: 1.1566 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0195 - acc: 0.6688 - val_loss: 1.0837 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0171 - acc: 0.6690 - val_loss: 1.0474 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0096 - acc: 0.6688 - val_loss: 1.3181 - val_acc: 0.6589\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.0229 - acc: 0.6683 - val_loss: 1.0497 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.0017 - acc: 0.6686 - val_loss: 1.0826 - val_acc: 0.6572 - loss: 1.0083 - acc: \n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.0086 - acc: 0.6686 - val_loss: 1.0120 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0031 - acc: 0.6686 - val_loss: 1.0530 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0028 - acc: 0.6686 - val_loss: 1.1321 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0034 - acc: 0.6686 - val_loss: 1.0579 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0018 - acc: 0.6686 - val_loss: 1.0495 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9976 - acc: 0.6685 - val_loss: 1.0190 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 269us/step\n",
      "4006/4006 [==============================] - 1s 276us/step\n",
      "5408/5408 [==============================] - 1s 273us/step\n",
      "4006/4006 [==============================] - 1s 276us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  20\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  10\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 2.0651 - acc: 0.3502 - val_loss: 1.7428 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.6077 - acc: 0.6686 - val_loss: 1.5701 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.5154 - acc: 0.6686 - val_loss: 1.5196 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4814 - acc: 0.6686 - val_loss: 1.4939 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.4615 - acc: 0.6686 - val_loss: 1.4734 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4460 - acc: 0.6686 - val_loss: 1.4572 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4340 - acc: 0.6686 - val_loss: 1.4446 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4235 - acc: 0.6686 - val_loss: 1.4342 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4147 - acc: 0.6686 - val_loss: 1.4246 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4066 - acc: 0.6686 - val_loss: 1.4159 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3993 - acc: 0.6686 - val_loss: 1.4085 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3928 - acc: 0.6686 - val_loss: 1.4015 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3862 - acc: 0.6686 - val_loss: 1.3951 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3802 - acc: 0.6686 - val_loss: 1.3884 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.3732 - acc: 0.6686 - val_loss: 1.3829 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.3691 - acc: 0.6686 - val_loss: 1.3790 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3536 - acc: 0.6686 - val_loss: 1.3659 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.3397 - acc: 0.6686 - val_loss: 1.3722 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.3288 - acc: 0.6686 - val_loss: 1.3436 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3240 - acc: 0.6686 - val_loss: 1.3513 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.3136 - acc: 0.6686 - val_loss: 1.3288 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3042 - acc: 0.6686 - val_loss: 1.3221 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2996 - acc: 0.6686 - val_loss: 1.3063 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2927 - acc: 0.6686 - val_loss: 1.3007 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2882 - acc: 0.6686 - val_loss: 1.2984 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2815 - acc: 0.6686 - val_loss: 1.3204 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2779 - acc: 0.6686 - val_loss: 1.2922 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.2733 - acc: 0.6686 - val_loss: 1.2926 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2638 - acc: 0.6686 - val_loss: 1.2747 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2589 - acc: 0.6686 - val_loss: 1.3227 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2698 - acc: 0.6686 - val_loss: 1.2982 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.2487 - acc: 0.6686 - val_loss: 1.2599 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2457 - acc: 0.6686 - val_loss: 1.2554 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2405 - acc: 0.6686 - val_loss: 1.2510 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2345 - acc: 0.6686 - val_loss: 1.2724 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2332 - acc: 0.6686 - val_loss: 1.2685 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2242 - acc: 0.6686 - val_loss: 1.2414 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2206 - acc: 0.6686 - val_loss: 1.2676 - val_acc: 0.6572\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2151 - acc: 0.6687- ETA: 0s - loss: 1.2173 - acc: 0.669 - ETA: 0s - loss: 1.2218 -  - 1s 215us/step - loss: 1.2156 - acc: 0.6686 - val_loss: 1.2313 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2139 - acc: 0.6686 - val_loss: 1.2593 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2091 - acc: 0.6686 - val_loss: 1.2242 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1923 - acc: 0.6686 - val_loss: 1.2255 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1877 - acc: 0.6686 - val_loss: 1.2060 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1812 - acc: 0.6686 - val_loss: 1.2036 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1791 - acc: 0.6686 - val_loss: 1.1994 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.1731 - acc: 0.6686 - val_loss: 1.2083 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1667 - acc: 0.6686 - val_loss: 1.1846 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1453 - acc: 0.6686 - val_loss: 1.3265 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1428 - acc: 0.6686 - val_loss: 1.1534 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1318 - acc: 0.6686 - val_loss: 1.2194 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1197 - acc: 0.6686 - val_loss: 1.1761 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1159 - acc: 0.6686 - val_loss: 1.1894 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1070 - acc: 0.6686 - val_loss: 1.1359 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1012 - acc: 0.6686 - val_loss: 1.1378 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0971 - acc: 0.6686 - val_loss: 1.1426 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0915 - acc: 0.6686 - val_loss: 1.1301 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0892 - acc: 0.6686 - val_loss: 1.1056 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0833 - acc: 0.6686 - val_loss: 1.1401 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0769 - acc: 0.6686 - val_loss: 1.1457 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 212us/step - loss: 1.0794 - acc: 0.6686 - val_loss: 1.0861 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0751 - acc: 0.6686 - val_loss: 1.1537 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0759 - acc: 0.6686 - val_loss: 1.2339 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0728 - acc: 0.6686 - val_loss: 1.1273 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0972 - acc: 0.6686 - val_loss: 1.1430 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0667 - acc: 0.6723 - val_loss: 1.0549 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0529 - acc: 0.6697 - val_loss: 1.1140 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0528 - acc: 0.6701 - val_loss: 1.1692 - val_acc: 0.6273\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0551 - acc: 0.6703 - val_loss: 1.1478 - val_acc: 0.6639\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0469 - acc: 0.6731 - val_loss: 1.0935 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0462 - acc: 0.6781 - val_loss: 1.3852 - val_acc: 0.4143\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0533 - acc: 0.6699 - val_loss: 1.0909 - val_acc: 0.6589\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0379 - acc: 0.6757 - val_loss: 1.1624 - val_acc: 0.6173\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0293 - acc: 0.6757 - val_loss: 1.0600 - val_acc: 0.6589\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0263 - acc: 0.6803 - val_loss: 1.1102 - val_acc: 0.6622\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0240 - acc: 0.6795 - val_loss: 1.3123 - val_acc: 0.6556\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0339 - acc: 0.6807 - val_loss: 1.2815 - val_acc: 0.5641\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0288 - acc: 0.6786 - val_loss: 1.0631 - val_acc: 0.6755\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0098 - acc: 0.6832 - val_loss: 1.1419 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.0140 - acc: 0.6808 - val_loss: 1.0311 - val_acc: 0.6689\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0014 - acc: 0.6860 - val_loss: 1.3386 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0231 - acc: 0.6783 - val_loss: 1.0242 - val_acc: 0.6739\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0099 - acc: 0.6827 - val_loss: 1.0513 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 0.9974 - acc: 0.6858 - val_loss: 1.0061 - val_acc: 0.6789\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 0.9983 - acc: 0.6882 - val_loss: 1.0419 - val_acc: 0.6656\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 0.9941 - acc: 0.6897 - val_loss: 1.1475 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0112 - acc: 0.6690 - val_loss: 1.0975 - val_acc: 0.6606: 0s - loss: 0.9987 - acc: 0.\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0055 - acc: 0.6795 - val_loss: 0.9898 - val_acc: 0.6839\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9916 - acc: 0.6858 - val_loss: 1.1953 - val_acc: 0.5424\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.9934 - acc: 0.6845 - val_loss: 1.0185 - val_acc: 0.6722\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 0.9881 - acc: 0.6893 - val_loss: 1.0601 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 0.9815 - acc: 0.6886 - val_loss: 1.0552 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 0.9784 - acc: 0.6888 - val_loss: 1.1393 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 0.9976 - acc: 0.6847 - val_loss: 1.0745 - val_acc: 0.6622\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 0.9831 - acc: 0.6836 - val_loss: 1.0178 - val_acc: 0.6722\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 0.9800 - acc: 0.6890 - val_loss: 1.2757 - val_acc: 0.5790\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 0.9843 - acc: 0.6853 - val_loss: 1.0527 - val_acc: 0.6772\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 214us/step - loss: 0.9850 - acc: 0.6884 - val_loss: 1.0068 - val_acc: 0.6705\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 0.9794 - acc: 0.6871 - val_loss: 0.9846 - val_acc: 0.6872\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 0.9709 - acc: 0.6916 - val_loss: 1.0085 - val_acc: 0.6722\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 0.9736 - acc: 0.6884 - val_loss: 1.2241 - val_acc: 0.6223\n",
      "5408/5408 [==============================] - 1s 231us/step\n",
      "4006/4006 [==============================] - 1s 235us/step\n",
      "5408/5408 [==============================] - 1s 231us/step\n",
      "4006/4006 [==============================] - 1s 235us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  25\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  10\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 1.8692 - acc: 0.4532 - val_loss: 1.6522 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.5772 - acc: 0.6686 - val_loss: 1.5511 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.5133 - acc: 0.6686 - val_loss: 1.5108 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4820 - acc: 0.6686 - val_loss: 1.4850 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4611 - acc: 0.6686 - val_loss: 1.4657 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.4551 - acc: 0.6686 - val_loss: 1.4417 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4338 - acc: 0.6686 - val_loss: 1.4422 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4240 - acc: 0.6686 - val_loss: 1.4317 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.4152 - acc: 0.6686 - val_loss: 1.4230 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.4076 - acc: 0.6686 - val_loss: 1.4156 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4004 - acc: 0.6686 - val_loss: 1.4087 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.3939 - acc: 0.6686 - val_loss: 1.4017 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.3877 - acc: 0.6686 - val_loss: 1.3962 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.3818 - acc: 0.6686 - val_loss: 1.3900 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.3760 - acc: 0.6686 - val_loss: 1.3833 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.3704 - acc: 0.6686 - val_loss: 1.3783 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.3653 - acc: 0.6686 - val_loss: 1.3731 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.3600 - acc: 0.6686 - val_loss: 1.3681 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.3551 - acc: 0.6686 - val_loss: 1.3624 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.3493 - acc: 0.6686 - val_loss: 1.3578 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3447 - acc: 0.6686 - val_loss: 1.3817 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.3363 - acc: 0.6686 - val_loss: 1.3444 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.3241 - acc: 0.6686 - val_loss: 1.3235 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3162 - acc: 0.6686 - val_loss: 1.3575 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.3169 - acc: 0.6686 - val_loss: 1.3483 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3067 - acc: 0.6686 - val_loss: 1.3308 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2957 - acc: 0.6686 - val_loss: 1.2968 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 2s 351us/step - loss: 1.2993 - acc: 0.6686 - val_loss: 1.3033 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2950 - acc: 0.6686 - val_loss: 1.3000 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2820 - acc: 0.6686 - val_loss: 1.3147 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2768 - acc: 0.6686 - val_loss: 1.2822 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2672 - acc: 0.6686 - val_loss: 1.3048 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2623 - acc: 0.6686 - val_loss: 1.3356 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2638 - acc: 0.6686 - val_loss: 1.2865 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2398 - acc: 0.6686 - val_loss: 1.2672 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2267 - acc: 0.6686 - val_loss: 1.2700 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.2192 - acc: 0.6686 - val_loss: 1.2543 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2086 - acc: 0.6686 - val_loss: 1.2173 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1954 - acc: 0.6686 - val_loss: 1.2417 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1905 - acc: 0.6686 - val_loss: 1.3067 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1867 - acc: 0.6686 - val_loss: 1.2133 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1699 - acc: 0.6686 - val_loss: 1.3020 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1636 - acc: 0.6686 - val_loss: 1.1964 - val_acc: 0.6572loss: 1.1729 - acc:\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1400 - acc: 0.6686 - val_loss: 1.1859 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1387 - acc: 0.6686 - val_loss: 1.1835 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1339 - acc: 0.6686 - val_loss: 1.1867 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1282 - acc: 0.6686 - val_loss: 1.2604 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.1206 - acc: 0.6686 - val_loss: 1.1323 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.1080 - acc: 0.6686 - val_loss: 1.1943 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1116 - acc: 0.6686 - val_loss: 1.1270 - val_acc: 0.6572\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1003 - acc: 0.6685 - val_loss: 1.1622 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0957 - acc: 0.6686 - val_loss: 1.1371 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0892 - acc: 0.6688 - val_loss: 1.2582 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0977 - acc: 0.6686 - val_loss: 1.1284 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0828 - acc: 0.6686 - val_loss: 1.2071 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1345 - acc: 0.6686 - val_loss: 1.4688 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1259 - acc: 0.6686 - val_loss: 1.1666 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0922 - acc: 0.6686 - val_loss: 1.1497 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0823 - acc: 0.6686 - val_loss: 1.1085 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0770 - acc: 0.6686 - val_loss: 1.3173 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1034 - acc: 0.6688 - val_loss: 1.0787 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0649 - acc: 0.6686 - val_loss: 1.0642 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0628 - acc: 0.6686 - val_loss: 1.2577 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0842 - acc: 0.6729 - val_loss: 1.1003 - val_acc: 0.6722\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0623 - acc: 0.6807 - val_loss: 1.2097 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0905 - acc: 0.6686 - val_loss: 1.2958 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0821 - acc: 0.6686 - val_loss: 1.1763 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0608 - acc: 0.6779 - val_loss: 1.0740 - val_acc: 0.6805\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0470 - acc: 0.6823 - val_loss: 1.1580 - val_acc: 0.6389\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0436 - acc: 0.6829 - val_loss: 1.0882 - val_acc: 0.6722\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0431 - acc: 0.6823 - val_loss: 1.0961 - val_acc: 0.6622\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0319 - acc: 0.6838 - val_loss: 1.0754 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0279 - acc: 0.6834 - val_loss: 1.0630 - val_acc: 0.6656\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.0262 - acc: 0.6860 - val_loss: 1.0394 - val_acc: 0.6822\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0247 - acc: 0.6853 - val_loss: 1.2692 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0295 - acc: 0.6869 - val_loss: 1.0870 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0283 - acc: 0.6831 - val_loss: 1.3046 - val_acc: 0.5158\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0334 - acc: 0.6827 - val_loss: 1.1800 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0324 - acc: 0.6814 - val_loss: 1.1527 - val_acc: 0.6672\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.0198 - acc: 0.6827 - val_loss: 1.0873 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.0138 - acc: 0.687 - 1s 234us/step - loss: 1.0155 - acc: 0.6862 - val_loss: 1.1832 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0418 - acc: 0.6823 - val_loss: 1.3665 - val_acc: 0.4775\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0251 - acc: 0.6803 - val_loss: 1.3528 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0429 - acc: 0.6747 - val_loss: 1.0287 - val_acc: 0.6639\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0053 - acc: 0.6864 - val_loss: 1.1803 - val_acc: 0.6223\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0125 - acc: 0.6797 - val_loss: 1.1527 - val_acc: 0.6190\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0055 - acc: 0.6888 - val_loss: 1.0646 - val_acc: 0.6705\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9969 - acc: 0.6892 - val_loss: 1.0852 - val_acc: 0.6656\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 0.9987 - acc: 0.6903 - val_loss: 1.1000 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.9991 - acc: 0.6871 - val_loss: 1.0383 - val_acc: 0.6705\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.9935 - acc: 0.6873 - val_loss: 1.0111 - val_acc: 0.6822\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 0.9908 - acc: 0.6879 - val_loss: 1.0921 - val_acc: 0.6389 0s - loss: 0.9924 - acc: 0.6\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9957 - acc: 0.6893 - val_loss: 1.0973 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9969 - acc: 0.6860 - val_loss: 1.1498 - val_acc: 0.6589\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.9935 - acc: 0.6881 - val_loss: 1.0014 - val_acc: 0.6789\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 0.9872 - acc: 0.6881 - val_loss: 1.0193 - val_acc: 0.6789\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9903 - acc: 0.6892 - val_loss: 1.0366 - val_acc: 0.6672\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9868 - acc: 0.6866 - val_loss: 1.0027 - val_acc: 0.6772\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9840 - acc: 0.6869 - val_loss: 1.0332 - val_acc: 0.6805\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.9836 - acc: 0.6858 - val_loss: 1.0078 - val_acc: 0.6656\n",
      "5408/5408 [==============================] - 1s 257us/step\n",
      "4006/4006 [==============================] - 1s 254us/step\n",
      "5408/5408 [==============================] - 1s 254us/step\n",
      "4006/4006 [==============================] - 1s 262us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 1.8267 - acc: 0.5804 - val_loss: 1.6585 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.6129 - acc: 0.6686 - val_loss: 1.5994 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.5781 - acc: 0.6686 - val_loss: 1.5739 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.5583 - acc: 0.6686 - val_loss: 1.5539 - val_acc: 0.6572\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5421 - acc: 0.6686 - val_loss: 1.5726 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5483 - acc: 0.6685 - val_loss: 1.5399 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5272 - acc: 0.6686 - val_loss: 1.5261 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.5152 - acc: 0.6686 - val_loss: 1.5150 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.5048 - acc: 0.6686 - val_loss: 1.5065 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4985 - acc: 0.6686 - val_loss: 1.4972 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.4886 - acc: 0.6686 - val_loss: 1.4869 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4783 - acc: 0.6686 - val_loss: 1.4792 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4693 - acc: 0.6686 - val_loss: 1.4723 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.4614 - acc: 0.6686 - val_loss: 1.4652 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4539 - acc: 0.6686 - val_loss: 1.4578 - val_acc: 0.6572- loss: 1.4796 - ac\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4468 - acc: 0.6686 - val_loss: 1.4516 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.4399 - acc: 0.6686 - val_loss: 1.4458 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.4332 - acc: 0.6686 - val_loss: 1.4386 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.4267 - acc: 0.6686 - val_loss: 1.4327 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4202 - acc: 0.6686 - val_loss: 1.4252 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.4141 - acc: 0.6686 - val_loss: 1.4198 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4080 - acc: 0.6686 - val_loss: 1.4138 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.4020 - acc: 0.6686 - val_loss: 1.4080 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3961 - acc: 0.6686 - val_loss: 1.4015 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3905 - acc: 0.6686 - val_loss: 1.3958 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3849 - acc: 0.6686 - val_loss: 1.3908 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3795 - acc: 0.6686 - val_loss: 1.3855 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3741 - acc: 0.6686 - val_loss: 1.3811 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3689 - acc: 0.6686 - val_loss: 1.3753 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3637 - acc: 0.6686 - val_loss: 1.3710 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3588 - acc: 0.6686 - val_loss: 1.3660 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3539 - acc: 0.6686 - val_loss: 1.3614 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3491 - acc: 0.6686 - val_loss: 1.3560 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3445 - acc: 0.6686 - val_loss: 1.3517 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3399 - acc: 0.6686 - val_loss: 1.3482 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3356 - acc: 0.6686 - val_loss: 1.3424 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.3312 - acc: 0.6686 - val_loss: 1.3385 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3268 - acc: 0.6686 - val_loss: 1.3345 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3228 - acc: 0.6686 - val_loss: 1.3305 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3186 - acc: 0.6686 - val_loss: 1.3263 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3146 - acc: 0.6686 - val_loss: 1.3220 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3107 - acc: 0.6686 - val_loss: 1.3183 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.3068 - acc: 0.6686 - val_loss: 1.3147 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3032 - acc: 0.6686 - val_loss: 1.3104 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2995 - acc: 0.6686 - val_loss: 1.3068 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2959 - acc: 0.6686 - val_loss: 1.3041 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2926 - acc: 0.668 - 1s 222us/step - loss: 1.2925 - acc: 0.6686 - val_loss: 1.3004 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2890 - acc: 0.6686 - val_loss: 1.2970 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2856 - acc: 0.6686 - val_loss: 1.2929 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2824 - acc: 0.6686 - val_loss: 1.2903 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2791 - acc: 0.6686 - val_loss: 1.2875 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2759 - acc: 0.6686 - val_loss: 1.2835 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2729 - acc: 0.6686 - val_loss: 1.2803 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2700 - acc: 0.6686 - val_loss: 1.2776 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2669 - acc: 0.6686 - val_loss: 1.2745 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2641 - acc: 0.6686 - val_loss: 1.2716 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.2613 - acc: 0.6686 - val_loss: 1.2691 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2585 - acc: 0.6686 - val_loss: 1.2664 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.2558 - acc: 0.6686 - val_loss: 1.2640 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2532 - acc: 0.6686 - val_loss: 1.2615 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.2507 - acc: 0.6686 - val_loss: 1.2589 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2481 - acc: 0.6686 - val_loss: 1.2576 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2457 - acc: 0.6686 - val_loss: 1.2535 - val_acc: 0.6572\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.2433 - acc: 0.6686 - val_loss: 1.2516 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.2408 - acc: 0.6686 - val_loss: 1.2494 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2387 - acc: 0.6686 - val_loss: 1.2463 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2363 - acc: 0.6686 - val_loss: 1.2446 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.2341 - acc: 0.6686 - val_loss: 1.2423 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2319 - acc: 0.6686 - val_loss: 1.2393 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2300 - acc: 0.6686 - val_loss: 1.2378 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.2278 - acc: 0.6686 - val_loss: 1.2361 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2258 - acc: 0.6686 - val_loss: 1.2340 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2238 - acc: 0.6686 - val_loss: 1.2320 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2220 - acc: 0.6686 - val_loss: 1.2301 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2201 - acc: 0.6686 - val_loss: 1.2279 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2182 - acc: 0.6686 - val_loss: 1.2261 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2163 - acc: 0.6686 - val_loss: 1.2240 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.2145 - acc: 0.6686 - val_loss: 1.2227 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2127 - acc: 0.6686 - val_loss: 1.2208 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2111 - acc: 0.6686 - val_loss: 1.2190 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.2093 - acc: 0.6686 - val_loss: 1.2173 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 215us/step - loss: 1.2077 - acc: 0.6686 - val_loss: 1.2163 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2062 - acc: 0.6686 - val_loss: 1.2149 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.2046 - acc: 0.6686 - val_loss: 1.2139 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2031 - acc: 0.6686 - val_loss: 1.2120 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2015 - acc: 0.6686 - val_loss: 1.2099 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2000 - acc: 0.6686 - val_loss: 1.2094 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2012 - acc: 0.6686 - val_loss: 1.2154 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1995 - acc: 0.6686 - val_loss: 1.1998 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1909 - acc: 0.6686 - val_loss: 1.2019 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1727 - acc: 0.6686 - val_loss: 1.1677 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1576 - acc: 0.6686 - val_loss: 1.2029 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1431 - acc: 0.6686 - val_loss: 1.1478 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.1352 - acc: 0.6686 - val_loss: 1.2541 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1245 - acc: 0.6686 - val_loss: 1.1778 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1136 - acc: 0.6686 - val_loss: 1.1205 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0948 - acc: 0.6686 - val_loss: 1.2185 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0932 - acc: 0.6686 - val_loss: 1.0955 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0854 - acc: 0.6686 - val_loss: 1.0938 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0735 - acc: 0.6686 - val_loss: 1.0883 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 265us/step\n",
      "4006/4006 [==============================] - 1s 268us/step\n",
      "5408/5408 [==============================] - 1s 266us/step\n",
      "4006/4006 [==============================] - 1s 267us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  10\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 2.7954 - acc: 0.2239 - val_loss: 1.8800 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.7240 - acc: 0.6686 - val_loss: 1.6652 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.6308 - acc: 0.6686 - val_loss: 1.6300 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.6037 - acc: 0.6686 - val_loss: 1.6078 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.5850 - acc: 0.6686 - val_loss: 1.5916 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.5710 - acc: 0.6686 - val_loss: 1.5772 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.5587 - acc: 0.6686 - val_loss: 1.5648 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.5474 - acc: 0.6686 - val_loss: 1.5540 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.5333 - acc: 0.6686 - val_loss: 1.5344 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.5155 - acc: 0.6686 - val_loss: 1.5174 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4989 - acc: 0.6686 - val_loss: 1.5020 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4902 - acc: 0.6686 - val_loss: 1.4889 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.4731 - acc: 0.6686 - val_loss: 1.4873 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.4639 - acc: 0.6686 - val_loss: 1.4668 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.4531 - acc: 0.6686 - val_loss: 1.4635 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4399 - acc: 0.6686 - val_loss: 1.4443 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.4216 - acc: 0.6686 - val_loss: 1.4915 - val_acc: 0.6572\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.4193 - acc: 0.6686 - val_loss: 1.4575 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4070 - acc: 0.6686 - val_loss: 1.4167 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.3902 - acc: 0.6686 - val_loss: 1.4475 - val_acc: 0.6572 0s - loss: 1.4011 - acc\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3832 - acc: 0.6686 - val_loss: 1.4589 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.3739 - acc: 0.6686 - val_loss: 1.4088 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3687 - acc: 0.6686 - val_loss: 1.3747 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3534 - acc: 0.6686 - val_loss: 1.3620 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3531 - acc: 0.6686 - val_loss: 1.3889 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.3338 - acc: 0.6686 - val_loss: 1.3644 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.3241 - acc: 0.6686 - val_loss: 1.3291 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.3181 - acc: 0.6686 - val_loss: 1.3296 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3075 - acc: 0.6686 - val_loss: 1.3442 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.3046 - acc: 0.6686 - val_loss: 1.3157 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.2961 - acc: 0.6686 - val_loss: 1.4485 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.3085 - acc: 0.6686 - val_loss: 1.3636 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2915 - acc: 0.6686 - val_loss: 1.3133 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2766 - acc: 0.6686 - val_loss: 1.2890 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2630 - acc: 0.6686 - val_loss: 1.2613 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2518 - acc: 0.6686 - val_loss: 1.2758 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2460 - acc: 0.6686 - val_loss: 1.3064 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.2416 - acc: 0.6686 - val_loss: 1.3303 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2318 - acc: 0.6686 - val_loss: 1.3182 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2257 - acc: 0.6686 - val_loss: 1.2378 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2157 - acc: 0.6686 - val_loss: 1.2984 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2095 - acc: 0.6686 - val_loss: 1.2335 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2043 - acc: 0.6686 - val_loss: 1.3444 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2023 - acc: 0.6686 - val_loss: 1.3090 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1965 - acc: 0.6686 - val_loss: 1.2739 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1960 - acc: 0.6686 - val_loss: 1.2267 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1831 - acc: 0.6686 - val_loss: 1.2840 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1780 - acc: 0.6686 - val_loss: 1.2791 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1624 - acc: 0.6686 - val_loss: 1.2392 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1594 - acc: 0.6686 - val_loss: 1.1675 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1517 - acc: 0.6685 - val_loss: 1.2623 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1574 - acc: 0.6686 - val_loss: 1.1609 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1383 - acc: 0.6686 - val_loss: 1.4588 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.1516 - acc: 0.6686 - val_loss: 1.2617 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1440 - acc: 0.6686 - val_loss: 1.1503 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1211 - acc: 0.6686 - val_loss: 1.1633 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1189 - acc: 0.670 - 1s 226us/step - loss: 1.1223 - acc: 0.6686 - val_loss: 1.2049 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1191 - acc: 0.6686 - val_loss: 1.1282 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1094 - acc: 0.6686 - val_loss: 1.2080 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1458 - acc: 0.6688 - val_loss: 1.1655 - val_acc: 0.6522\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1030 - acc: 0.6699 - val_loss: 1.2037 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1433 - acc: 0.6686 - val_loss: 1.1705 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1212 - acc: 0.6686 - val_loss: 1.2721 - val_acc: 0.6556\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1094 - acc: 0.6688 - val_loss: 1.1699 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1016 - acc: 0.6703 - val_loss: 1.1750 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0928 - acc: 0.6738 - val_loss: 1.1448 - val_acc: 0.6589\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0831 - acc: 0.6742 - val_loss: 1.1103 - val_acc: 0.6739\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0853 - acc: 0.6736 - val_loss: 1.1425 - val_acc: 0.6589\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0718 - acc: 0.6792 - val_loss: 1.1657 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0703 - acc: 0.6764 - val_loss: 1.0970 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0646 - acc: 0.6784 - val_loss: 1.2939 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0641 - acc: 0.6773 - val_loss: 1.0720 - val_acc: 0.6839\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0462 - acc: 0.6808 - val_loss: 1.1398 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0501 - acc: 0.6820 - val_loss: 1.0606 - val_acc: 0.6606\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0376 - acc: 0.6831 - val_loss: 1.2077 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0650 - acc: 0.6777 - val_loss: 1.0431 - val_acc: 0.6789\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0417 - acc: 0.6825 - val_loss: 1.0671 - val_acc: 0.6622\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0362 - acc: 0.6799 - val_loss: 1.0520 - val_acc: 0.6705\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0401 - acc: 0.6821 - val_loss: 1.3154 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0332 - acc: 0.6842 - val_loss: 1.1101 - val_acc: 0.6689\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0308 - acc: 0.6814 - val_loss: 1.0696 - val_acc: 0.6622\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0200 - acc: 0.6899 - val_loss: 1.5536 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0569 - acc: 0.6781 - val_loss: 1.2227 - val_acc: 0.6622\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0276 - acc: 0.6849 - val_loss: 1.0175 - val_acc: 0.6722\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0212 - acc: 0.6844 - val_loss: 1.0176 - val_acc: 0.6789\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0157 - acc: 0.6879 - val_loss: 1.1368 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0141 - acc: 0.6849 - val_loss: 1.0429 - val_acc: 0.6672\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0059 - acc: 0.6860 - val_loss: 1.3819 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0247 - acc: 0.6873 - val_loss: 1.1481 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0188 - acc: 0.6816 - val_loss: 1.0841 - val_acc: 0.6622\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0127 - acc: 0.6853 - val_loss: 1.0282 - val_acc: 0.6656\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.0007 - acc: 0.6851 - val_loss: 1.2000 - val_acc: 0.6190\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0037 - acc: 0.6849 - val_loss: 1.1348 - val_acc: 0.6639\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.9976 - acc: 0.6895 - val_loss: 1.1662 - val_acc: 0.6240\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 0.9957 - acc: 0.6884 - val_loss: 1.0441 - val_acc: 0.6606\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 0.9931 - acc: 0.6853 - val_loss: 1.0892 - val_acc: 0.6622\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 0.9899 - acc: 0.6886 - val_loss: 1.0698 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 0.9857 - acc: 0.6899 - val_loss: 1.0167 - val_acc: 0.6839\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 0.9894 - acc: 0.6862 - val_loss: 1.2580 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0018 - acc: 0.6858 - val_loss: 1.0533 - val_acc: 0.6556\n",
      "5408/5408 [==============================] - 1s 254us/step\n",
      "4006/4006 [==============================] - 1s 254us/step\n",
      "5408/5408 [==============================] - 1s 260us/step\n",
      "4006/4006 [==============================] - 1s 293us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 16s 3ms/step - loss: 1.8185 - acc: 0.6649 - val_loss: 1.7416 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.6835 - acc: 0.6686 - val_loss: 1.6809 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.6432 - acc: 0.6686 - val_loss: 1.6470 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.6199 - acc: 0.6686 - val_loss: 1.6253 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.6038 - acc: 0.6686 - val_loss: 1.6098 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.5914 - acc: 0.6686 - val_loss: 1.5974 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.5804 - acc: 0.6686 - val_loss: 1.5862 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.5703 - acc: 0.6686 - val_loss: 1.5754 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 1.5619 - acc: 0.6686 - val_loss: 1.5656 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.5512 - acc: 0.6686 - val_loss: 1.5560 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.5423 - acc: 0.6686 - val_loss: 1.5470 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.5330 - acc: 0.6686 - val_loss: 1.5382 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.5244 - acc: 0.6686 - val_loss: 1.5300 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.5158 - acc: 0.6686 - val_loss: 1.5216 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.5075 - acc: 0.6686 - val_loss: 1.5137 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4994 - acc: 0.6686 - val_loss: 1.5061 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.4915 - acc: 0.6686 - val_loss: 1.4977 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4837 - acc: 0.6686 - val_loss: 1.4896 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4761 - acc: 0.6686 - val_loss: 1.4817 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.4686 - acc: 0.6686 - val_loss: 1.4744 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4613 - acc: 0.6686 - val_loss: 1.4663 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4542 - acc: 0.6686 - val_loss: 1.4593 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4467 - acc: 0.6686 - val_loss: 1.4542 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.4407 - acc: 0.6686 - val_loss: 1.4474 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4340 - acc: 0.6686 - val_loss: 1.4411 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4275 - acc: 0.6686 - val_loss: 1.4345 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.4211 - acc: 0.6686 - val_loss: 1.4272 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4125 - acc: 0.6686 - val_loss: 1.4207 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4003 - acc: 0.6686 - val_loss: 1.4172 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.3942 - acc: 0.6686 - val_loss: 1.3912 - val_acc: 0.6572\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3808 - acc: 0.6686 - val_loss: 1.3969 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3749 - acc: 0.6686 - val_loss: 1.3766 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3648 - acc: 0.6686 - val_loss: 1.3553 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3508 - acc: 0.6686 - val_loss: 1.3585 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3393 - acc: 0.6686 - val_loss: 1.3720 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.3308 - acc: 0.6686 - val_loss: 1.3535 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.3132 - acc: 0.6686 - val_loss: 1.3526 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.3013 - acc: 0.6686 - val_loss: 1.2989 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.2818 - acc: 0.6686 - val_loss: 1.3432 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.2654 - acc: 0.6686 - val_loss: 1.3273 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2518 - acc: 0.6686 - val_loss: 1.3636 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2432 - acc: 0.6686 - val_loss: 1.2477 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.2268 - acc: 0.6686 - val_loss: 1.3394 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2179 - acc: 0.6688 - val_loss: 1.2531 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.2023 - acc: 0.6686 - val_loss: 1.2102 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1877 - acc: 0.6688 - val_loss: 1.3445 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1830 - acc: 0.6690 - val_loss: 1.4466 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2130 - acc: 0.6686 - val_loss: 1.2037 - val_acc: 0.6589\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1633 - acc: 0.6688 - val_loss: 1.3059 - val_acc: 0.6556\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1603 - acc: 0.6709 - val_loss: 1.4002 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1464 - acc: 0.6718 - val_loss: 1.2212 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1350 - acc: 0.6740 - val_loss: 1.1738 - val_acc: 0.6722\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1251 - acc: 0.6768 - val_loss: 1.1582 - val_acc: 0.6639\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1201 - acc: 0.6744 - val_loss: 1.1518 - val_acc: 0.6639\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1101 - acc: 0.6746 - val_loss: 1.2570 - val_acc: 0.6622\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.1144 - acc: 0.6771 - val_loss: 1.1335 - val_acc: 0.6589\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1095 - acc: 0.6759 - val_loss: 1.1680 - val_acc: 0.6639\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0954 - acc: 0.6794 - val_loss: 1.2272 - val_acc: 0.6589\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1025 - acc: 0.6790 - val_loss: 1.1249 - val_acc: 0.6639\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0884 - acc: 0.6818 - val_loss: 1.1142 - val_acc: 0.6606\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0857 - acc: 0.6818 - val_loss: 1.1488 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0716 - acc: 0.6818 - val_loss: 1.2260 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0738 - acc: 0.6823 - val_loss: 1.1099 - val_acc: 0.6589\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0692 - acc: 0.6816 - val_loss: 1.1412 - val_acc: 0.6589\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0672 - acc: 0.6823 - val_loss: 1.2995 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0694 - acc: 0.6832 - val_loss: 1.0816 - val_acc: 0.6672\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0546 - acc: 0.6840 - val_loss: 1.1001 - val_acc: 0.6772\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0512 - acc: 0.6849 - val_loss: 1.1074 - val_acc: 0.6622\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0538 - acc: 0.6829 - val_loss: 1.0618 - val_acc: 0.6855\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0434 - acc: 0.6862 - val_loss: 1.0982 - val_acc: 0.6639\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0374 - acc: 0.6860 - val_loss: 1.1214 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0329 - acc: 0.6842 - val_loss: 1.0567 - val_acc: 0.6656\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0365 - acc: 0.6853 - val_loss: 1.1243 - val_acc: 0.6589\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0366 - acc: 0.6847 - val_loss: 1.1595 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0383 - acc: 0.6816 - val_loss: 1.1605 - val_acc: 0.6606\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0344 - acc: 0.6820 - val_loss: 1.0828 - val_acc: 0.6689\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0316 - acc: 0.6818 - val_loss: 1.0937 - val_acc: 0.6755\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0263 - acc: 0.6862 - val_loss: 1.0996 - val_acc: 0.6639\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0252 - acc: 0.6866 - val_loss: 1.0399 - val_acc: 0.6672\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0195 - acc: 0.6882 - val_loss: 1.0444 - val_acc: 0.6672\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0127 - acc: 0.6845 - val_loss: 1.1242 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0126 - acc: 0.6869 - val_loss: 1.0269 - val_acc: 0.6739\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0127 - acc: 0.6849 - val_loss: 1.1561 - val_acc: 0.6739\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0124 - acc: 0.6838 - val_loss: 1.0425 - val_acc: 0.6689\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0026 - acc: 0.6875 - val_loss: 1.1171 - val_acc: 0.6539\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0059 - acc: 0.6864 - val_loss: 1.1383 - val_acc: 0.6622\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9968 - acc: 0.6895 - val_loss: 1.2012 - val_acc: 0.6356\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0051 - acc: 0.6884 - val_loss: 1.0784 - val_acc: 0.6589\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9991 - acc: 0.6875 - val_loss: 1.0221 - val_acc: 0.6672\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9876 - acc: 0.6929 - val_loss: 1.0498 - val_acc: 0.6656\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9864 - acc: 0.6890 - val_loss: 1.2190 - val_acc: 0.6090\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0029 - acc: 0.6842 - val_loss: 1.4129 - val_acc: 0.4775\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0171 - acc: 0.6799 - val_loss: 1.0732 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9860 - acc: 0.6888 - val_loss: 1.0341 - val_acc: 0.6755\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 0.9824 - acc: 0.6912 - val_loss: 1.1440 - val_acc: 0.6689\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9799 - acc: 0.6921 - val_loss: 1.0849 - val_acc: 0.6539\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 0.9814 - acc: 0.6903 - val_loss: 0.9934 - val_acc: 0.6689\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 0.9798 - acc: 0.6882 - val_loss: 1.1293 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 0.9736 - acc: 0.6910 - val_loss: 1.0444 - val_acc: 0.6656\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.9762 - acc: 0.6921 - val_loss: 1.0564 - val_acc: 0.6589\n",
      "5408/5408 [==============================] - 1s 251us/step\n",
      "4006/4006 [==============================] - 1s 246us/step\n",
      "5408/5408 [==============================] - 1s 250us/step\n",
      "4006/4006 [==============================] - 1s 250us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  20\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 12s 2ms/step - loss: 1.7699 - acc: 0.6651 - val_loss: 1.6994 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.6705 - acc: 0.6686 - val_loss: 1.6626 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.6401 - acc: 0.6686 - val_loss: 1.6405 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.6185 - acc: 0.6686 - val_loss: 1.6323 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.6006 - acc: 0.6686 - val_loss: 1.6049 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.5825 - acc: 0.6686 - val_loss: 1.5882 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.5669 - acc: 0.6686 - val_loss: 1.5698 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.5543 - acc: 0.6686 - val_loss: 1.5624 - val_acc: 0.6572 loss: 1.5532 - acc: 0.\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.5369 - acc: 0.6686 - val_loss: 1.5472 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5156 - acc: 0.6686 - val_loss: 1.6157 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.5078 - acc: 0.6686 - val_loss: 1.5086 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4875 - acc: 0.6686 - val_loss: 1.4991 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.4717 - acc: 0.6686 - val_loss: 1.4772 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.4570 - acc: 0.6686 - val_loss: 1.5058 - val_acc: 0.6572: 0s - loss: 1.4668 - acc:\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.4469 - acc: 0.6686 - val_loss: 1.4596 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.4325 - acc: 0.6686 - val_loss: 1.5022 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.4275 - acc: 0.6686 - val_loss: 1.5116 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.4343 - acc: 0.6686 - val_loss: 1.5243 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.4375 - acc: 0.6685 - val_loss: 1.4424 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.3922 - acc: 0.668 - 1s 274us/step - loss: 1.3907 - acc: 0.6688 - val_loss: 1.4144 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.3756 - acc: 0.6688 - val_loss: 1.4206 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.3597 - acc: 0.6686 - val_loss: 1.3946 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.3538 - acc: 0.6686 - val_loss: 1.3859 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.3390 - acc: 0.6686 - val_loss: 1.3962 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.3210 - acc: 0.6686 - val_loss: 1.3724 - val_acc: 0.6556\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.3101 - acc: 0.6688 - val_loss: 1.3105 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 2s 305us/step - loss: 1.2916 - acc: 0.6688 - val_loss: 1.3246 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 2s 312us/step - loss: 1.2776 - acc: 0.6696 - val_loss: 1.3355 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.2753 - acc: 0.6688 - val_loss: 1.2974 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.2644 - acc: 0.6690 - val_loss: 1.2870 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.2542 - acc: 0.6692 - val_loss: 1.3814 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2539 - acc: 0.6690 - val_loss: 1.2830 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2407 - acc: 0.6690 - val_loss: 1.2764 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.2288 - acc: 0.6696 - val_loss: 1.2534 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.2308 - acc: 0.6705 - val_loss: 1.4844 - val_acc: 0.6556\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.2294 - acc: 0.6686 - val_loss: 1.2795 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2063 - acc: 0.6692 - val_loss: 1.4175 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2184 - acc: 0.6697 - val_loss: 1.3485 - val_acc: 0.5757\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2058 - acc: 0.6701 - val_loss: 1.3559 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1982 - acc: 0.6685 - val_loss: 1.2866 - val_acc: 0.6556\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1834 - acc: 0.6696 - val_loss: 1.2180 - val_acc: 0.6639\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.1812 - acc: 0.6727 - val_loss: 1.2202 - val_acc: 0.6572\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.1757 - acc: 0.6746 - val_loss: 1.1813 - val_acc: 0.6556\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.1597 - acc: 0.6736 - val_loss: 1.1991 - val_acc: 0.6539\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.1601 - acc: 0.6749 - val_loss: 1.1846 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1512 - acc: 0.6777 - val_loss: 1.1665 - val_acc: 0.6739\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 243us/step - loss: 1.1479 - acc: 0.6775 - val_loss: 1.2090 - val_acc: 0.6589\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1468 - acc: 0.6744 - val_loss: 1.2534 - val_acc: 0.6306\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1353 - acc: 0.6781 - val_loss: 1.1832 - val_acc: 0.6556\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1269 - acc: 0.6760 - val_loss: 1.2436 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1248 - acc: 0.6773 - val_loss: 1.7014 - val_acc: 0.2812\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2445 - acc: 0.6635 - val_loss: 1.1535 - val_acc: 0.6622\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1194 - acc: 0.6738 - val_loss: 1.2744 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1235 - acc: 0.6779 - val_loss: 1.2938 - val_acc: 0.6556\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.1382 - acc: 0.6710 - val_loss: 1.1323 - val_acc: 0.6622\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.1081 - acc: 0.6751 - val_loss: 1.1239 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.1007 - acc: 0.6773 - val_loss: 1.1392 - val_acc: 0.6772\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0928 - acc: 0.6823 - val_loss: 1.2388 - val_acc: 0.6439\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 1.0967 - acc: 0.6794 - val_loss: 1.1136 - val_acc: 0.6705\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.0891 - acc: 0.6814 - val_loss: 1.1130 - val_acc: 0.6656\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0818 - acc: 0.6821 - val_loss: 1.1471 - val_acc: 0.6556\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0832 - acc: 0.6845 - val_loss: 1.1880 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0826 - acc: 0.6794 - val_loss: 1.3584 - val_acc: 0.6256\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0966 - acc: 0.6738 - val_loss: 1.1450 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0746 - acc: 0.6766 - val_loss: 1.1981 - val_acc: 0.6589\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0624 - acc: 0.6805 - val_loss: 1.1545 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0712 - acc: 0.6762 - val_loss: 1.0994 - val_acc: 0.6606\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0583 - acc: 0.6849 - val_loss: 1.7645 - val_acc: 0.1980\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0826 - acc: 0.6662 - val_loss: 1.5983 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0739 - acc: 0.6807 - val_loss: 1.1725 - val_acc: 0.6589\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0563 - acc: 0.6816 - val_loss: 1.0532 - val_acc: 0.6722\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.0478 - acc: 0.6840 - val_loss: 1.1596 - val_acc: 0.6073\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0490 - acc: 0.6794 - val_loss: 1.2140 - val_acc: 0.6389\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0432 - acc: 0.6844 - val_loss: 1.0912 - val_acc: 0.6622\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0390 - acc: 0.6825 - val_loss: 1.0440 - val_acc: 0.6789\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0475 - acc: 0.6827 - val_loss: 1.0689 - val_acc: 0.6656\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0351 - acc: 0.6855 - val_loss: 1.0606 - val_acc: 0.6772\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0325 - acc: 0.6794 - val_loss: 1.3605 - val_acc: 0.6506\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0443 - acc: 0.6807 - val_loss: 1.0841 - val_acc: 0.6622\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0292 - acc: 0.6803 - val_loss: 1.2709 - val_acc: 0.5774\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0327 - acc: 0.6838 - val_loss: 1.2716 - val_acc: 0.6589\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0395 - acc: 0.6797 - val_loss: 1.3165 - val_acc: 0.6356s - loss: 1.0494 - acc: 0.\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0656 - acc: 0.6690 - val_loss: 1.1366 - val_acc: 0.6589\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0501 - acc: 0.6764 - val_loss: 1.0545 - val_acc: 0.6672\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0237 - acc: 0.6823 - val_loss: 1.0614 - val_acc: 0.6656\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0094 - acc: 0.6869 - val_loss: 1.0952 - val_acc: 0.6822\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0235 - acc: 0.6851 - val_loss: 1.1866 - val_acc: 0.6473\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0184 - acc: 0.6847 - val_loss: 1.0383 - val_acc: 0.6739\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0079 - acc: 0.6842 - val_loss: 1.1867 - val_acc: 0.6439\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0091 - acc: 0.6864 - val_loss: 1.1908 - val_acc: 0.6556\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0171 - acc: 0.6827 - val_loss: 1.1241 - val_acc: 0.6689\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0078 - acc: 0.6853 - val_loss: 1.0251 - val_acc: 0.6755\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 239us/step - loss: 0.9949 - acc: 0.6860 - val_loss: 1.0757 - val_acc: 0.6705\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0015 - acc: 0.6844 - val_loss: 1.0863 - val_acc: 0.6606\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 0.9987 - acc: 0.6834 - val_loss: 1.0249 - val_acc: 0.6689\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 0.9942 - acc: 0.6857 - val_loss: 1.0076 - val_acc: 0.6822\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 0.9902 - acc: 0.6881 - val_loss: 1.0729 - val_acc: 0.6506\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 0.9855 - acc: 0.6864 - val_loss: 0.9965 - val_acc: 0.6789\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 0.9847 - acc: 0.6890 - val_loss: 0.9903 - val_acc: 0.6722\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 0.9836 - acc: 0.6879 - val_loss: 1.1202 - val_acc: 0.6339\n",
      "5408/5408 [==============================] - 1s 251us/step\n",
      "4006/4006 [==============================] - 1s 250us/step\n",
      "5408/5408 [==============================] - 1s 250us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4006/4006 [==============================] - 1s 246us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  25\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  20\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 1.8227 - acc: 0.6522 - val_loss: 1.7557 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.7061 - acc: 0.6686 - val_loss: 1.7117 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.6761 - acc: 0.6686 - val_loss: 1.6834 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.6553 - acc: 0.6686 - val_loss: 1.6630 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.6388 - acc: 0.6686 - val_loss: 1.6457 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.6246 - acc: 0.6686 - val_loss: 1.6316 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.6119 - acc: 0.6686 - val_loss: 1.6178 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.6004 - acc: 0.6686 - val_loss: 1.6056 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.5894 - acc: 0.6686 - val_loss: 1.5950 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.5788 - acc: 0.6686 - val_loss: 1.5845 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.5686 - acc: 0.6686 - val_loss: 1.5736 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.5589 - acc: 0.6686 - val_loss: 1.5641 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.5495 - acc: 0.6686 - val_loss: 1.5548 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.5403 - acc: 0.6686 - val_loss: 1.5451 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.5314 - acc: 0.6686 - val_loss: 1.5365 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.5227 - acc: 0.6686 - val_loss: 1.5276 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5141 - acc: 0.6686 - val_loss: 1.5199 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.5059 - acc: 0.6686 - val_loss: 1.5105 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.4978 - acc: 0.6686 - val_loss: 1.5025 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.4899 - acc: 0.6686 - val_loss: 1.4957 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.4821 - acc: 0.6686 - val_loss: 1.4868 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.4760 - acc: 0.6686 - val_loss: 1.5012 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.4772 - acc: 0.6686 - val_loss: 1.4796 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.4645 - acc: 0.6686 - val_loss: 1.4714 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.4565 - acc: 0.6686 - val_loss: 1.4619 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.4253 - acc: 0.6686 - val_loss: 1.4579 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.4439 - acc: 0.6686 - val_loss: 1.4495 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.4361 - acc: 0.6686 - val_loss: 1.4434 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.4294 - acc: 0.6686 - val_loss: 1.4363 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.4230 - acc: 0.6686 - val_loss: 1.4302 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.4167 - acc: 0.6686 - val_loss: 1.4234 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.4105 - acc: 0.6686 - val_loss: 1.4175 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.4044 - acc: 0.6686 - val_loss: 1.4114 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3986 - acc: 0.6686 - val_loss: 1.4057 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3928 - acc: 0.6686 - val_loss: 1.3995 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3874 - acc: 0.6686 - val_loss: 1.3935 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3818 - acc: 0.6686 - val_loss: 1.3883 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3764 - acc: 0.6686 - val_loss: 1.3832 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3711 - acc: 0.6686 - val_loss: 1.3782 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3660 - acc: 0.6686 - val_loss: 1.3733 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3610 - acc: 0.6686 - val_loss: 1.3677 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.3561 - acc: 0.6686 - val_loss: 1.3628 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3513 - acc: 0.6686 - val_loss: 1.3586 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3464 - acc: 0.6686 - val_loss: 1.3541 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.3420 - acc: 0.6686 - val_loss: 1.3488 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3375 - acc: 0.6686 - val_loss: 1.3441 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.3330 - acc: 0.6686 - val_loss: 1.3396 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3287 - acc: 0.6686 - val_loss: 1.3353 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.3245 - acc: 0.6686 - val_loss: 1.3318 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 2s 337us/step - loss: 1.3204 - acc: 0.6686 - val_loss: 1.3276 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.3165 - acc: 0.6686 - val_loss: 1.3234 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.3125 - acc: 0.6686 - val_loss: 1.3197 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.3086 - acc: 0.6686 - val_loss: 1.3151 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.3048 - acc: 0.6686 - val_loss: 1.3116 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.3011 - acc: 0.6686 - val_loss: 1.3077 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2977 - acc: 0.6686 - val_loss: 1.3040 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2960 - acc: 0.667 - 1s 241us/step - loss: 1.2942 - acc: 0.6686 - val_loss: 1.3006 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2906 - acc: 0.6686 - val_loss: 1.2972 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2872 - acc: 0.6686 - val_loss: 1.2948 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.2839 - acc: 0.6686 - val_loss: 1.2919 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.2806 - acc: 0.6686 - val_loss: 1.2887 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2775 - acc: 0.6686 - val_loss: 1.2850 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.2744 - acc: 0.6686 - val_loss: 1.2819 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2713 - acc: 0.6686 - val_loss: 1.2789 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.2683 - acc: 0.6686 - val_loss: 1.2762 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2654 - acc: 0.6686 - val_loss: 1.2741 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2626 - acc: 0.6686 - val_loss: 1.2711 - val_acc: 0.6572\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.2598 - acc: 0.6686 - val_loss: 1.2685 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.2572 - acc: 0.6686 - val_loss: 1.2655 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2545 - acc: 0.6686 - val_loss: 1.2626 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2519 - acc: 0.6686 - val_loss: 1.2602 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2493 - acc: 0.6686 - val_loss: 1.2572 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2466 - acc: 0.6686 - val_loss: 1.2543 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2445 - acc: 0.6686 - val_loss: 1.2521 - val_acc: 0.6572\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2421 - acc: 0.6686 - val_loss: 1.2501 - val_acc: 0.6572s: 1.2386 - acc: 0.\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2397 - acc: 0.6686 - val_loss: 1.2479 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2373 - acc: 0.6686 - val_loss: 1.2453 - val_acc: 0.6572\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2351 - acc: 0.6686 - val_loss: 1.2429 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.2329 - acc: 0.6686 - val_loss: 1.2416 - val_acc: 0.6572\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2308 - acc: 0.6686 - val_loss: 1.2391 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.2287 - acc: 0.6686 - val_loss: 1.2370 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2267 - acc: 0.6686 - val_loss: 1.2338 - val_acc: 0.6572\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2066 - acc: 0.6686 - val_loss: 1.2102 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1965 - acc: 0.6686 - val_loss: 1.2028 - val_acc: 0.6572\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1905 - acc: 0.6686 - val_loss: 1.2192 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1789 - acc: 0.6686 - val_loss: 1.1993 - val_acc: 0.6572\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.1748 - acc: 0.6686 - val_loss: 1.1852 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.1640 - acc: 0.6686 - val_loss: 1.2045 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1495 - acc: 0.6686 - val_loss: 1.1871 - val_acc: 0.6572\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1386 - acc: 0.6686 - val_loss: 1.1545 - val_acc: 0.6572\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.1237 - acc: 0.6686 - val_loss: 1.1488 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1172 - acc: 0.6686 - val_loss: 1.2010 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1004 - acc: 0.6686 - val_loss: 1.1221 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0945 - acc: 0.6686 - val_loss: 1.1093 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0894 - acc: 0.6686 - val_loss: 1.1033 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0799 - acc: 0.6686 - val_loss: 1.0765 - val_acc: 0.6572\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0614 - acc: 0.6686 - val_loss: 1.1868 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0591 - acc: 0.6686 - val_loss: 1.0924 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.0496 - acc: 0.6688 - val_loss: 1.2661 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.0498 - acc: 0.6686 - val_loss: 1.0794 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 277us/step\n",
      "4006/4006 [==============================] - 1s 332us/step\n",
      "5408/5408 [==============================] - 1s 257us/step\n",
      "4006/4006 [==============================] - 1s 255us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  30\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 1.8340 - acc: 0.6241 - val_loss: 1.7812 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.6765 - acc: 0.6686 - val_loss: 1.6820 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.6310 - acc: 0.6686 - val_loss: 1.6335 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.6044 - acc: 0.6686 - val_loss: 1.6319 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.5902 - acc: 0.6686 - val_loss: 1.6214 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.5750 - acc: 0.6686 - val_loss: 1.5769 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.5584 - acc: 0.6686 - val_loss: 1.5882 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.5448 - acc: 0.6686 - val_loss: 1.5513 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.5320 - acc: 0.6686 - val_loss: 1.5357 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.5175 - acc: 0.6686 - val_loss: 1.5814 - val_acc: 0.6572\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5011 - acc: 0.6686 - val_loss: 1.5644 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.4815 - acc: 0.668 - 1s 228us/step - loss: 1.4809 - acc: 0.6686 - val_loss: 1.5173 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.4691 - acc: 0.6686 - val_loss: 1.4921 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4504 - acc: 0.6686 - val_loss: 1.4727 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.4396 - acc: 0.6686 - val_loss: 1.4582 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.4265 - acc: 0.6686 - val_loss: 1.5544 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4153 - acc: 0.6686 - val_loss: 1.4603 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.4022 - acc: 0.6686 - val_loss: 1.4158 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3909 - acc: 0.6686 - val_loss: 1.4143 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3785 - acc: 0.6686 - val_loss: 1.4191 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3689 - acc: 0.6686 - val_loss: 1.4369 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.3724 - acc: 0.6686 - val_loss: 1.3830 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3505 - acc: 0.6686 - val_loss: 1.3704 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.3420 - acc: 0.6686 - val_loss: 1.4348 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.3317 - acc: 0.6686 - val_loss: 1.3606 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3228 - acc: 0.6686 - val_loss: 1.3579 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3086 - acc: 0.6686 - val_loss: 1.3372 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3005 - acc: 0.6686 - val_loss: 1.3666 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2987 - acc: 0.6686 - val_loss: 1.5389 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.3357 - acc: 0.6686 - val_loss: 1.4031 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.2820 - acc: 0.6686 - val_loss: 1.2929 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2719 - acc: 0.6686 - val_loss: 1.3213 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.2638 - acc: 0.6686 - val_loss: 1.3897 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2604 - acc: 0.6686 - val_loss: 1.2685 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.2437 - acc: 0.6686 - val_loss: 1.3582 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2424 - acc: 0.6686 - val_loss: 1.2501 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2337 - acc: 0.6686 - val_loss: 1.2920 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.2263 - acc: 0.6686 - val_loss: 1.3083 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2160 - acc: 0.6686 - val_loss: 1.2754 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2102 - acc: 0.6686 - val_loss: 1.2323 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.1992 - acc: 0.669 - 1s 225us/step - loss: 1.2027 - acc: 0.6686 - val_loss: 1.2178 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1944 - acc: 0.6685 - val_loss: 1.2277 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1848 - acc: 0.6685 - val_loss: 1.3668 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1851 - acc: 0.6686 - val_loss: 1.2525 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.1700 - acc: 0.6686 - val_loss: 1.1872 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1669 - acc: 0.6685 - val_loss: 1.1880 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1595 - acc: 0.6686 - val_loss: 1.3027 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1579 - acc: 0.6688 - val_loss: 1.2243 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1576 - acc: 0.6685 - val_loss: 1.1780 - val_acc: 0.6589\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1449 - acc: 0.6707 - val_loss: 1.1557 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1365 - acc: 0.6686 - val_loss: 1.3255 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1336 - acc: 0.6696 - val_loss: 1.2078 - val_acc: 0.6589\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1361 - acc: 0.6692 - val_loss: 1.5083 - val_acc: 0.6556\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1372 - acc: 0.6685 - val_loss: 1.2774 - val_acc: 0.6556\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.1197 - acc: 0.6683 - val_loss: 1.1509 - val_acc: 0.6589\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1176 - acc: 0.6686 - val_loss: 1.2176 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1192 - acc: 0.6720 - val_loss: 1.1125 - val_acc: 0.6589\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1094 - acc: 0.6747 - val_loss: 1.1128 - val_acc: 0.6705\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.1087 - acc: 0.6790 - val_loss: 1.1474 - val_acc: 0.6689\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0930 - acc: 0.6807 - val_loss: 1.1268 - val_acc: 0.6622\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0975 - acc: 0.6779 - val_loss: 1.1188 - val_acc: 0.6672\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0863 - acc: 0.6786 - val_loss: 1.2409 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1052 - acc: 0.6733 - val_loss: 1.1370 - val_acc: 0.6656\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0823 - acc: 0.6746 - val_loss: 1.2555 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0847 - acc: 0.6781 - val_loss: 1.1075 - val_acc: 0.6656\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0734 - acc: 0.6814 - val_loss: 1.2540 - val_acc: 0.6606\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0711 - acc: 0.6810 - val_loss: 1.0975 - val_acc: 0.6622\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0681 - acc: 0.6812 - val_loss: 1.1798 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0665 - acc: 0.6808 - val_loss: 1.0715 - val_acc: 0.6739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0564 - acc: 0.6834 - val_loss: 1.2036 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0631 - acc: 0.6784 - val_loss: 1.1710 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0588 - acc: 0.6801 - val_loss: 1.0664 - val_acc: 0.6705\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0508 - acc: 0.6803 - val_loss: 1.1490 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0511 - acc: 0.6814 - val_loss: 1.0795 - val_acc: 0.6606\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0503 - acc: 0.6808 - val_loss: 1.0767 - val_acc: 0.6755\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0426 - acc: 0.6818 - val_loss: 1.0609 - val_acc: 0.6755\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0435 - acc: 0.6814 - val_loss: 1.0923 - val_acc: 0.6722\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0353 - acc: 0.6838 - val_loss: 1.0576 - val_acc: 0.6689\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0314 - acc: 0.6864 - val_loss: 1.1102 - val_acc: 0.6639\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0350 - acc: 0.6829 - val_loss: 1.0464 - val_acc: 0.6772\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0300 - acc: 0.6840 - val_loss: 1.0555 - val_acc: 0.6705\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0290 - acc: 0.6834 - val_loss: 1.0790 - val_acc: 0.6755\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0342 - acc: 0.6816 - val_loss: 1.1195 - val_acc: 0.6423\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0296 - acc: 0.6807 - val_loss: 1.0715 - val_acc: 0.6689\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0196 - acc: 0.6845 - val_loss: 1.0451 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0208 - acc: 0.6812 - val_loss: 1.0834 - val_acc: 0.6689\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0217 - acc: 0.6853 - val_loss: 1.0491 - val_acc: 0.6656\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0230 - acc: 0.6801 - val_loss: 1.0325 - val_acc: 0.6772\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0083 - acc: 0.6840 - val_loss: 1.0801 - val_acc: 0.6389\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0122 - acc: 0.6842 - val_loss: 1.1086 - val_acc: 0.6206\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0155 - acc: 0.6823 - val_loss: 1.1747 - val_acc: 0.6356\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0108 - acc: 0.6823 - val_loss: 1.1220 - val_acc: 0.6639\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0011 - acc: 0.6842 - val_loss: 1.0757 - val_acc: 0.6622\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0011 - acc: 0.6831 - val_loss: 1.0181 - val_acc: 0.6705\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.9964 - acc: 0.6847 - val_loss: 1.0455 - val_acc: 0.6539\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 0.9944 - acc: 0.6842 - val_loss: 1.5525 - val_acc: 0.3428\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0096 - acc: 0.6790 - val_loss: 1.0631 - val_acc: 0.6589\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 0.9978 - acc: 0.6834 - val_loss: 1.1849 - val_acc: 0.6522\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0185 - acc: 0.6812 - val_loss: 1.0399 - val_acc: 0.6689\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 0.9931 - acc: 0.6823 - val_loss: 1.0235 - val_acc: 0.6722\n",
      "5408/5408 [==============================] - 1s 257us/step\n",
      "4006/4006 [==============================] - 1s 258us/step\n",
      "5408/5408 [==============================] - 1s 266us/step\n",
      "4006/4006 [==============================] - 1s 256us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  10\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  30\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 2.0299 - acc: 0.5762 - val_loss: 1.7888 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.7473 - acc: 0.6686 - val_loss: 1.7349 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.7090 - acc: 0.6686 - val_loss: 1.7090 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.6863 - acc: 0.6686 - val_loss: 1.6908 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.6709 - acc: 0.6686 - val_loss: 1.6938 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.6309 - acc: 0.6686 - val_loss: 1.6263 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.6064 - acc: 0.6686 - val_loss: 1.6109 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.5871 - acc: 0.6686 - val_loss: 1.6455 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.5731 - acc: 0.6686 - val_loss: 1.6132 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5587 - acc: 0.6686 - val_loss: 1.5738 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.5425 - acc: 0.6686 - val_loss: 1.5490 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.5260 - acc: 0.6686 - val_loss: 1.5473 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.5133 - acc: 0.6686 - val_loss: 1.5630 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.5000 - acc: 0.6686 - val_loss: 1.6276 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.4884 - acc: 0.6686 - val_loss: 1.5913 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.4748 - acc: 0.6686 - val_loss: 1.4815 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.4499 - acc: 0.6686 - val_loss: 1.4531 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.4322 - acc: 0.6686 - val_loss: 1.4554 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.4160 - acc: 0.6686 - val_loss: 1.4412 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4042 - acc: 0.6686 - val_loss: 1.5839 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.4121 - acc: 0.6686 - val_loss: 1.4084 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3827 - acc: 0.6688 - val_loss: 1.4240 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.3673 - acc: 0.6686 - val_loss: 1.3749 - val_acc: 0.6572\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.3529 - acc: 0.6686 - val_loss: 1.4230 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.3392 - acc: 0.6686 - val_loss: 1.3576 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3243 - acc: 0.6686 - val_loss: 1.4136 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.3273 - acc: 0.6686 - val_loss: 1.4457 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.3109 - acc: 0.6686 - val_loss: 1.3663 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2993 - acc: 0.6686 - val_loss: 1.3403 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2852 - acc: 0.6686 - val_loss: 1.4271 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2865 - acc: 0.6688 - val_loss: 1.3901 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2785 - acc: 0.6688 - val_loss: 1.4385 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.3060 - acc: 0.6673 - val_loss: 1.3721 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2546 - acc: 0.6688 - val_loss: 1.2808 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.2433 - acc: 0.6686 - val_loss: 1.3075 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.2384 - acc: 0.6686 - val_loss: 1.2552 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.2305 - acc: 0.6686 - val_loss: 1.3385 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2214 - acc: 0.6688 - val_loss: 1.4165 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.2229 - acc: 0.6688 - val_loss: 1.4246 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.2133 - acc: 0.6686 - val_loss: 1.2276 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2011 - acc: 0.6688 - val_loss: 1.2523 - val_acc: 0.6556\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1994 - acc: 0.6686 - val_loss: 1.2184 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.1902 - acc: 0.6692 - val_loss: 1.1896 - val_acc: 0.6606\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.1808 - acc: 0.6696 - val_loss: 1.3681 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1843 - acc: 0.6686 - val_loss: 1.2291 - val_acc: 0.6689\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1791 - acc: 0.6686 - val_loss: 1.2494 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1691 - acc: 0.6697 - val_loss: 1.3265 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.1675 - acc: 0.6701 - val_loss: 1.1631 - val_acc: 0.6672\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.1540 - acc: 0.6723 - val_loss: 1.1890 - val_acc: 0.6589\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.1491 - acc: 0.6749 - val_loss: 1.1544 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1401 - acc: 0.6716 - val_loss: 1.5398 - val_acc: 0.5358\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2321 - acc: 0.6644 - val_loss: 1.1689 - val_acc: 0.6572\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1332 - acc: 0.6723 - val_loss: 1.1532 - val_acc: 0.6589\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.1290 - acc: 0.6718 - val_loss: 1.1307 - val_acc: 0.6606\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1209 - acc: 0.6751 - val_loss: 1.2136 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1148 - acc: 0.6747 - val_loss: 1.1714 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1138 - acc: 0.6784 - val_loss: 1.1298 - val_acc: 0.6689\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.1019 - acc: 0.6807 - val_loss: 1.1307 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1020 - acc: 0.6781 - val_loss: 1.1055 - val_acc: 0.6589\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1059 - acc: 0.6823 - val_loss: 1.1057 - val_acc: 0.6689\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0984 - acc: 0.6799 - val_loss: 1.1084 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0850 - acc: 0.6810 - val_loss: 1.1063 - val_acc: 0.6656\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0901 - acc: 0.6801 - val_loss: 1.1054 - val_acc: 0.6772\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0758 - acc: 0.6807 - val_loss: 1.1170 - val_acc: 0.6639\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0777 - acc: 0.6857 - val_loss: 1.2888 - val_acc: 0.6572\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1081 - acc: 0.6740 - val_loss: 1.5212 - val_acc: 0.5008\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0908 - acc: 0.6762 - val_loss: 1.0837 - val_acc: 0.6672\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0636 - acc: 0.6823 - val_loss: 1.1442 - val_acc: 0.6606\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0678 - acc: 0.6825 - val_loss: 1.3325 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0694 - acc: 0.6831 - val_loss: 1.0886 - val_acc: 0.6772\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 236us/step - loss: 1.0547 - acc: 0.6827 - val_loss: 1.0710 - val_acc: 0.6722\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0538 - acc: 0.6825 - val_loss: 1.1007 - val_acc: 0.6639\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0507 - acc: 0.6842 - val_loss: 1.1088 - val_acc: 0.6423\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0450 - acc: 0.6864 - val_loss: 1.0629 - val_acc: 0.6755\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0447 - acc: 0.6886 - val_loss: 1.0523 - val_acc: 0.6822\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0413 - acc: 0.6877 - val_loss: 1.4157 - val_acc: 0.5574\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.0708 - acc: 0.6766 - val_loss: 1.0851 - val_acc: 0.6722\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0366 - acc: 0.6838 - val_loss: 1.1946 - val_acc: 0.6689\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0352 - acc: 0.6831 - val_loss: 1.2292 - val_acc: 0.6023\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.0363 - acc: 0.6857 - val_loss: 1.0451 - val_acc: 0.6755\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0302 - acc: 0.6868 - val_loss: 1.2142 - val_acc: 0.6323\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0333 - acc: 0.6821 - val_loss: 1.2392 - val_acc: 0.6589\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 320us/step - loss: 1.0303 - acc: 0.6860 - val_loss: 1.1039 - val_acc: 0.6606\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.0281 - acc: 0.6847 - val_loss: 1.0156 - val_acc: 0.6805\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0158 - acc: 0.6858 - val_loss: 1.2431 - val_acc: 0.5607\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0261 - acc: 0.6818 - val_loss: 1.1756 - val_acc: 0.6556\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0251 - acc: 0.6842 - val_loss: 1.0562 - val_acc: 0.6755\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0120 - acc: 0.6836 - val_loss: 1.0241 - val_acc: 0.6739\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.0098 - acc: 0.6853 - val_loss: 1.1355 - val_acc: 0.6539\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0126 - acc: 0.6842 - val_loss: 1.1956 - val_acc: 0.6373\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 1.0156 - acc: 0.6820 - val_loss: 1.1853 - val_acc: 0.6606\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 1.0110 - acc: 0.6890 - val_loss: 1.0367 - val_acc: 0.6805\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0055 - acc: 0.6855 - val_loss: 1.0507 - val_acc: 0.6606\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 226us/step - loss: 0.9957 - acc: 0.6890 - val_loss: 1.0479 - val_acc: 0.6473\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9972 - acc: 0.6882 - val_loss: 1.0906 - val_acc: 0.6606\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9980 - acc: 0.6877 - val_loss: 1.0019 - val_acc: 0.6739\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9980 - acc: 0.6862 - val_loss: 1.0500 - val_acc: 0.6689\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9903 - acc: 0.6879 - val_loss: 1.2424 - val_acc: 0.5424\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0056 - acc: 0.6829 - val_loss: 1.0340 - val_acc: 0.6689\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9903 - acc: 0.6882 - val_loss: 1.0026 - val_acc: 0.6839\n",
      "5408/5408 [==============================] - 2s 287us/step\n",
      "4006/4006 [==============================] - 1s 283us/step\n",
      "5408/5408 [==============================] - 1s 273us/step\n",
      "4006/4006 [==============================] - 1s 280us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  30\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: 1.8427 - acc: 0.6494 - val_loss: 1.8204 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.7472 - acc: 0.6686 - val_loss: 1.7553 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.7115 - acc: 0.6686 - val_loss: 1.7383 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.6922 - acc: 0.6686 - val_loss: 1.7327 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.6689 - acc: 0.6686 - val_loss: 1.6661 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.6384 - acc: 0.6686 - val_loss: 1.6826 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.6149 - acc: 0.6686 - val_loss: 1.6582 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.5858 - acc: 0.6686 - val_loss: 1.6531 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.5583 - acc: 0.6686 - val_loss: 1.6704 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.5564 - acc: 0.6686 - val_loss: 1.6396 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.5220 - acc: 0.6686 - val_loss: 1.6281 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.4991 - acc: 0.6686 - val_loss: 1.6473 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.4879 - acc: 0.6688 - val_loss: 1.6043 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.4876 - acc: 0.6686 - val_loss: 1.4983 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.4552 - acc: 0.6683 - val_loss: 1.5325 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.4394 - acc: 0.6688 - val_loss: 1.4329 - val_acc: 0.6556\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.4142 - acc: 0.6692 - val_loss: 1.4560 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.4053 - acc: 0.6692 - val_loss: 1.4241 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.3824 - acc: 0.6697 - val_loss: 1.4381 - val_acc: 0.6556\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 1.3773 - acc: 0.6690 - val_loss: 1.4318 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.3656 - acc: 0.6712 - val_loss: 1.3768 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 1.3411 - acc: 0.6723 - val_loss: 1.4492 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 313us/step - loss: 1.3433 - acc: 0.6757 - val_loss: 1.3427 - val_acc: 0.6589\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 240us/step - loss: 1.3198 - acc: 0.6779 - val_loss: 1.4100 - val_acc: 0.6556\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3151 - acc: 0.6807 - val_loss: 1.4286 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.3054 - acc: 0.6810 - val_loss: 1.4405 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.2940 - acc: 0.6773 - val_loss: 1.3199 - val_acc: 0.6589\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2826 - acc: 0.6788 - val_loss: 1.2981 - val_acc: 0.6739\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2704 - acc: 0.6860 - val_loss: 1.3032 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2622 - acc: 0.6799 - val_loss: 1.3613 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.2512 - acc: 0.6857 - val_loss: 1.2735 - val_acc: 0.6639\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.2449 - acc: 0.6845 - val_loss: 1.2647 - val_acc: 0.6656\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 1.2353 - acc: 0.6829 - val_loss: 1.2821 - val_acc: 0.6656\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.2304 - acc: 0.6834 - val_loss: 1.3840 - val_acc: 0.6556\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 2s 305us/step - loss: 1.2290 - acc: 0.6849 - val_loss: 1.2996 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2127 - acc: 0.6832 - val_loss: 1.3851 - val_acc: 0.6572\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.2318 - acc: 0.6823 - val_loss: 1.2418 - val_acc: 0.6772\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.2000 - acc: 0.6842 - val_loss: 1.2706 - val_acc: 0.6722\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.1966 - acc: 0.6866 - val_loss: 1.2326 - val_acc: 0.6755\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1834 - acc: 0.6890 - val_loss: 1.2680 - val_acc: 0.6622\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.1895 - acc: 0.6853 - val_loss: 1.2082 - val_acc: 0.6722\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 2s 356us/step - loss: 1.1709 - acc: 0.6899 - val_loss: 1.1877 - val_acc: 0.6755\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 2s 353us/step - loss: 1.1603 - acc: 0.6888 - val_loss: 1.1893 - val_acc: 0.6789\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1573 - acc: 0.6908 - val_loss: 1.2061 - val_acc: 0.6622\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 1.1511 - acc: 0.6908 - val_loss: 1.1577 - val_acc: 0.6905\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.1515 - acc: 0.6868 - val_loss: 1.1921 - val_acc: 0.6805\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.1360 - acc: 0.6905 - val_loss: 1.1486 - val_acc: 0.6822\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1375 - acc: 0.6881 - val_loss: 1.1481 - val_acc: 0.6839\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1254 - acc: 0.6936 - val_loss: 1.1366 - val_acc: 0.6822\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1225 - acc: 0.6912 - val_loss: 1.2060 - val_acc: 0.6622\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.1240 - acc: 0.6858 - val_loss: 1.2872 - val_acc: 0.6589\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1195 - acc: 0.6918 - val_loss: 1.1828 - val_acc: 0.6672\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.1038 - acc: 0.6918 - val_loss: 1.1991 - val_acc: 0.6622\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1044 - acc: 0.6932 - val_loss: 1.2474 - val_acc: 0.6306\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1004 - acc: 0.6912 - val_loss: 1.1966 - val_acc: 0.6589\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.0984 - acc: 0.6877 - val_loss: 1.1572 - val_acc: 0.6556\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.0870 - acc: 0.6919 - val_loss: 1.1775 - val_acc: 0.6689\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.0798 - acc: 0.6942 - val_loss: 1.1982 - val_acc: 0.6606\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.0814 - acc: 0.6930 - val_loss: 1.0981 - val_acc: 0.6772\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.0788 - acc: 0.6938 - val_loss: 1.1061 - val_acc: 0.6739\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.0689 - acc: 0.6927 - val_loss: 1.0955 - val_acc: 0.6789\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 2s 358us/step - loss: 1.0583 - acc: 0.6947 - val_loss: 1.2442 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 2s 323us/step - loss: 1.0604 - acc: 0.6927 - val_loss: 1.1206 - val_acc: 0.6689\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 2s 299us/step - loss: 1.0592 - acc: 0.6916 - val_loss: 1.1116 - val_acc: 0.6689\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0545 - acc: 0.6923 - val_loss: 1.0621 - val_acc: 0.6805\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.0499 - acc: 0.6936 - val_loss: 1.2016 - val_acc: 0.6639\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.0627 - acc: 0.6884 - val_loss: 1.1882 - val_acc: 0.6406\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.0507 - acc: 0.6919 - val_loss: 1.1460 - val_acc: 0.6739\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0396 - acc: 0.6943 - val_loss: 1.1739 - val_acc: 0.6572\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.0352 - acc: 0.6921 - val_loss: 1.1376 - val_acc: 0.6522\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0339 - acc: 0.6916 - val_loss: 1.0438 - val_acc: 0.6722\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0269 - acc: 0.6951 - val_loss: 1.1288 - val_acc: 0.6589\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.0192 - acc: 0.6980 - val_loss: 1.1732 - val_acc: 0.6572\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0527 - acc: 0.6849 - val_loss: 1.2003 - val_acc: 0.6007\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.0277 - acc: 0.6869 - val_loss: 1.0791 - val_acc: 0.6672\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.0187 - acc: 0.6932 - val_loss: 1.1014 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.0099 - acc: 0.6940 - val_loss: 1.0921 - val_acc: 0.6656\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.0152 - acc: 0.6914 - val_loss: 1.0371 - val_acc: 0.6689\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.0004 - acc: 0.6967 - val_loss: 1.0223 - val_acc: 0.6789\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.0015 - acc: 0.6949 - val_loss: 1.0898 - val_acc: 0.6622\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.9969 - acc: 0.6953 - val_loss: 1.2008 - val_acc: 0.6656\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0037 - acc: 0.6912 - val_loss: 1.0248 - val_acc: 0.6772\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9916 - acc: 0.6960 - val_loss: 1.0634 - val_acc: 0.6622\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9882 - acc: 0.6984 - val_loss: 1.0308 - val_acc: 0.6755\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 0.9816 - acc: 0.6971 - val_loss: 1.0663 - val_acc: 0.6639\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.9849 - acc: 0.6956 - val_loss: 1.3600 - val_acc: 0.5641\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9899 - acc: 0.6958 - val_loss: 1.0852 - val_acc: 0.6489\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9898 - acc: 0.6960 - val_loss: 1.0499 - val_acc: 0.6789\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9769 - acc: 0.6979 - val_loss: 1.1548 - val_acc: 0.6656\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9778 - acc: 0.6995 - val_loss: 1.2476 - val_acc: 0.5990\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 2s 314us/step - loss: 0.9907 - acc: 0.6903 - val_loss: 1.0172 - val_acc: 0.6739\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.9740 - acc: 0.6956 - val_loss: 1.0129 - val_acc: 0.6772\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 0.9631 - acc: 0.7010 - val_loss: 1.2947 - val_acc: 0.5458\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 2s 298us/step - loss: 0.9717 - acc: 0.7014 - val_loss: 1.0763 - val_acc: 0.6705\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.9770 - acc: 0.6938 - val_loss: 1.1353 - val_acc: 0.6356\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 302us/step - loss: 0.9584 - acc: 0.6999 - val_loss: 0.9884 - val_acc: 0.6772\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 0.9570 - acc: 0.6999 - val_loss: 1.0164 - val_acc: 0.6705\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.9517 - acc: 0.7004 - val_loss: 0.9980 - val_acc: 0.6656\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 2s 298us/step - loss: 0.9504 - acc: 0.7014 - val_loss: 0.9780 - val_acc: 0.6822\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.9523 - acc: 0.7027 - val_loss: 0.9969 - val_acc: 0.6972\n",
      "5408/5408 [==============================] - 2s 350us/step\n",
      "4006/4006 [==============================] - 1s 309us/step\n",
      "5408/5408 [==============================] - 2s 287us/step\n",
      "4006/4006 [==============================] - 1s 305us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  20\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  30\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 1.9286 - acc: 0.6644 - val_loss: 1.8683 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 324us/step - loss: 1.8303 - acc: 0.6686 - val_loss: 1.8293 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.7920 - acc: 0.6686 - val_loss: 1.7999 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.7734 - acc: 0.6686 - val_loss: 1.7741 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.7492 - acc: 0.6686 - val_loss: 1.7568 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.7326 - acc: 0.6686 - val_loss: 1.7511 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.7158 - acc: 0.6686 - val_loss: 1.7334 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.7029 - acc: 0.6686 - val_loss: 1.6933 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.6767 - acc: 0.6686 - val_loss: 1.7265 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.6504 - acc: 0.6686 - val_loss: 1.7039 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.6360 - acc: 0.6686 - val_loss: 1.6993 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.6285 - acc: 0.6686 - val_loss: 1.6651 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.6062 - acc: 0.6686 - val_loss: 1.6096 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.5831 - acc: 0.6686 - val_loss: 1.6031 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.5708 - acc: 0.6686 - val_loss: 1.6006 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.5481 - acc: 0.6686 - val_loss: 1.5643 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.5297 - acc: 0.6686 - val_loss: 1.5394 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.5092 - acc: 0.6686 - val_loss: 1.5088 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.4935 - acc: 0.6686 - val_loss: 1.5123 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.4790 - acc: 0.6686 - val_loss: 1.4703 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.4601 - acc: 0.6686 - val_loss: 1.4730 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.4514 - acc: 0.6686 - val_loss: 1.5030 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.4388 - acc: 0.6686 - val_loss: 1.5152 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.4206 - acc: 0.6686 - val_loss: 1.4813 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.4293 - acc: 0.6686 - val_loss: 1.5512 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.4003 - acc: 0.6686 - val_loss: 1.4139 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.3888 - acc: 0.6686 - val_loss: 1.3882 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.3713 - acc: 0.6686 - val_loss: 1.3828 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3588 - acc: 0.6686 - val_loss: 1.5279 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3613 - acc: 0.6686 - val_loss: 1.3824 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3376 - acc: 0.6686 - val_loss: 1.3929 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.3233 - acc: 0.6686 - val_loss: 1.4206 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 1.3104 - acc: 0.6686 - val_loss: 1.3542 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2999 - acc: 0.6686 - val_loss: 1.3132 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2908 - acc: 0.6686 - val_loss: 1.3871 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.2890 - acc: 0.6686 - val_loss: 1.3344 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2745 - acc: 0.6710 - val_loss: 1.4068 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3019 - acc: 0.6747 - val_loss: 1.6258 - val_acc: 0.4692\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2829 - acc: 0.6709 - val_loss: 1.2630 - val_acc: 0.6755\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2436 - acc: 0.6747 - val_loss: 1.3498 - val_acc: 0.6622\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2400 - acc: 0.6742 - val_loss: 1.4585 - val_acc: 0.6556\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2562 - acc: 0.6753 - val_loss: 1.2612 - val_acc: 0.6755\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2243 - acc: 0.6734 - val_loss: 1.3648 - val_acc: 0.6506\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2189 - acc: 0.6729 - val_loss: 1.3724 - val_acc: 0.6606\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.2142 - acc: 0.6731 - val_loss: 1.2441 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.2007 - acc: 0.6738 - val_loss: 1.3030 - val_acc: 0.6572\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1961 - acc: 0.6760 - val_loss: 1.1959 - val_acc: 0.6772\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.1828 - acc: 0.6770 - val_loss: 1.1892 - val_acc: 0.6689\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1834 - acc: 0.6790 - val_loss: 1.2245 - val_acc: 0.6672\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 306us/step - loss: 1.1666 - acc: 0.6855 - val_loss: 1.1821 - val_acc: 0.6672\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1592 - acc: 0.6814 - val_loss: 1.2120 - val_acc: 0.6572\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1551 - acc: 0.6792 - val_loss: 1.2041 - val_acc: 0.6722\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.1489 - acc: 0.6790 - val_loss: 1.1923 - val_acc: 0.6639\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.1419 - acc: 0.6825 - val_loss: 1.2020 - val_acc: 0.6589\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.1344 - acc: 0.6831 - val_loss: 1.1971 - val_acc: 0.6639\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1332 - acc: 0.6799 - val_loss: 1.2784 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1302 - acc: 0.6807 - val_loss: 1.3326 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1473 - acc: 0.6786 - val_loss: 1.2656 - val_acc: 0.6290\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1183 - acc: 0.6829 - val_loss: 1.2514 - val_acc: 0.6572\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1083 - acc: 0.6840 - val_loss: 1.2269 - val_acc: 0.6473\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1081 - acc: 0.6836 - val_loss: 1.1700 - val_acc: 0.6639\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.1020 - acc: 0.6829 - val_loss: 1.2159 - val_acc: 0.6572\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1029 - acc: 0.6842 - val_loss: 1.1218 - val_acc: 0.6656\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0884 - acc: 0.6840 - val_loss: 1.1047 - val_acc: 0.6805\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0818 - acc: 0.6849 - val_loss: 1.1204 - val_acc: 0.6722\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.0821 - acc: 0.6875 - val_loss: 1.2016 - val_acc: 0.6606\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.0804 - acc: 0.6847 - val_loss: 1.2319 - val_acc: 0.6606\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.1121 - acc: 0.6775 - val_loss: 1.6389 - val_acc: 0.6572\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1270 - acc: 0.6792 - val_loss: 1.1326 - val_acc: 0.6606\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0807 - acc: 0.6869 - val_loss: 1.1156 - val_acc: 0.6772\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0762 - acc: 0.6855 - val_loss: 1.1892 - val_acc: 0.6606\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 2s 316us/step - loss: 1.0698 - acc: 0.6881 - val_loss: 1.4647 - val_acc: 0.4925\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.0640 - acc: 0.6849 - val_loss: 1.1648 - val_acc: 0.6589\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.0549 - acc: 0.6908 - val_loss: 1.1156 - val_acc: 0.6689\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.0431 - acc: 0.6942 - val_loss: 1.1359 - val_acc: 0.6639\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 2s 302us/step - loss: 1.0453 - acc: 0.6873 - val_loss: 1.1551 - val_acc: 0.6522\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.0472 - acc: 0.6864 - val_loss: 1.1088 - val_acc: 0.6722\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.0370 - acc: 0.6947 - val_loss: 1.2382 - val_acc: 0.6606\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0430 - acc: 0.6903 - val_loss: 1.1167 - val_acc: 0.6606\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.0285 - acc: 0.6910 - val_loss: 1.3042 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.0488 - acc: 0.6875 - val_loss: 1.1056 - val_acc: 0.6622\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0245 - acc: 0.6860 - val_loss: 1.1095 - val_acc: 0.6406\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.0185 - acc: 0.6912 - val_loss: 1.0806 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0140 - acc: 0.6910 - val_loss: 1.1837 - val_acc: 0.6639\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.0083 - acc: 0.6947 - val_loss: 1.3916 - val_acc: 0.6572\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.0272 - acc: 0.6868 - val_loss: 1.4178 - val_acc: 0.6589\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.0138 - acc: 0.6930 - val_loss: 1.6739 - val_acc: 0.3661\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.0405 - acc: 0.6818 - val_loss: 1.1494 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 2s 308us/step - loss: 1.0077 - acc: 0.6906 - val_loss: 1.1919 - val_acc: 0.6057\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.0101 - acc: 0.6890 - val_loss: 1.1072 - val_acc: 0.6556\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.0047 - acc: 0.6905 - val_loss: 1.0670 - val_acc: 0.6539\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 2s 316us/step - loss: 0.9944 - acc: 0.6936 - val_loss: 1.1250 - val_acc: 0.6705\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 0.9968 - acc: 0.6903 - val_loss: 1.0699 - val_acc: 0.6456\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.9969 - acc: 0.6918 - val_loss: 1.3749 - val_acc: 0.4359\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9992 - acc: 0.6831 - val_loss: 1.1136 - val_acc: 0.6356\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 0.9967 - acc: 0.6892 - val_loss: 1.0212 - val_acc: 0.6822\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.9819 - acc: 0.6936 - val_loss: 1.2087 - val_acc: 0.6589\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.9904 - acc: 0.6868 - val_loss: 1.0781 - val_acc: 0.6722\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 0.9734 - acc: 0.6962 - val_loss: 1.0772 - val_acc: 0.6572\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 2s 313us/step - loss: 0.9781 - acc: 0.6908 - val_loss: 1.0051 - val_acc: 0.6656\n",
      "5408/5408 [==============================] - 2s 300us/step\n",
      "4006/4006 [==============================] - 1s 270us/step\n",
      "5408/5408 [==============================] - 1s 254us/step\n",
      "4006/4006 [==============================] - 1s 258us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  25\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  30\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 13s 2ms/step - loss: 1.9951 - acc: 0.6501 - val_loss: 1.8853 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.8315 - acc: 0.6686 - val_loss: 1.8393 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.7850 - acc: 0.6686 - val_loss: 1.8049 - val_acc: 0.6572\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.7580 - acc: 0.6686 - val_loss: 1.8038 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 2s 320us/step - loss: 1.7595 - acc: 0.6686 - val_loss: 1.7554 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 1.7362 - acc: 0.6686 - val_loss: 1.7581 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 1.7205 - acc: 0.6686 - val_loss: 1.7412 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.7232 - acc: 0.6686 - val_loss: 1.7285 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 2s 315us/step - loss: 1.6992 - acc: 0.6686 - val_loss: 1.6884 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 318us/step - loss: 1.6697 - acc: 0.6686 - val_loss: 1.6599 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.6366 - acc: 0.6686 - val_loss: 1.6369 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.6229 - acc: 0.6686 - val_loss: 1.6505 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.6038 - acc: 0.6686 - val_loss: 1.6459 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.5901 - acc: 0.6686 - val_loss: 1.6131 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.5756 - acc: 0.6686 - val_loss: 1.6417 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.6021 - acc: 0.6686 - val_loss: 1.6219 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.5869 - acc: 0.6686 - val_loss: 1.6300 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.5952 - acc: 0.6686 - val_loss: 1.5848 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.5630 - acc: 0.6686 - val_loss: 1.5694 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.5500 - acc: 0.6686 - val_loss: 1.5567 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.5373 - acc: 0.6686 - val_loss: 1.5455 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.5264 - acc: 0.6686 - val_loss: 1.5939 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.5660 - acc: 0.6686 - val_loss: 1.5686 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.5487 - acc: 0.6686 - val_loss: 1.5635 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.5330 - acc: 0.6686 - val_loss: 1.5273 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.5038 - acc: 0.6686 - val_loss: 1.4903 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.4591 - acc: 0.6686 - val_loss: 1.4866 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.4434 - acc: 0.6686 - val_loss: 1.4499 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.4188 - acc: 0.6686 - val_loss: 1.5021 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.4021 - acc: 0.6686 - val_loss: 1.4446 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 2s 335us/step - loss: 1.3807 - acc: 0.6686 - val_loss: 1.3868 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 2s 338us/step - loss: 1.3620 - acc: 0.6686 - val_loss: 1.3933 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.3475 - acc: 0.6686 - val_loss: 1.3760 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 2s 331us/step - loss: 1.3311 - acc: 0.6686 - val_loss: 1.3621 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 2s 325us/step - loss: 1.3190 - acc: 0.6686 - val_loss: 1.5059 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 2s 304us/step - loss: 1.3130 - acc: 0.6686 - val_loss: 1.4138 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.2965 - acc: 0.6686 - val_loss: 1.3779 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.2907 - acc: 0.6686 - val_loss: 1.3234 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.2736 - acc: 0.6686 - val_loss: 1.3086 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.2608 - acc: 0.6686 - val_loss: 1.3640 - val_acc: 0.6489\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.2564 - acc: 0.6694 - val_loss: 1.2980 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2397 - acc: 0.6696 - val_loss: 1.3508 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.2331 - acc: 0.6692 - val_loss: 1.3526 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.2332 - acc: 0.6725 - val_loss: 1.2303 - val_acc: 0.6772\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.2195 - acc: 0.6770 - val_loss: 1.2790 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2129 - acc: 0.6768 - val_loss: 1.2293 - val_acc: 0.6556\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2014 - acc: 0.6790 - val_loss: 1.3057 - val_acc: 0.6539\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.2065 - acc: 0.6783 - val_loss: 1.3747 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 2s 325us/step - loss: 1.1950 - acc: 0.6799 - val_loss: 1.2394 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.1865 - acc: 0.6855 - val_loss: 1.2893 - val_acc: 0.6572\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1832 - acc: 0.6810 - val_loss: 1.3394 - val_acc: 0.6622\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.1852 - acc: 0.6821 - val_loss: 1.2005 - val_acc: 0.6705\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.1684 - acc: 0.6849 - val_loss: 1.5534 - val_acc: 0.3993\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 2s 320us/step - loss: 1.1684 - acc: 0.6768 - val_loss: 1.5078 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.1575 - acc: 0.6855 - val_loss: 1.1879 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.1476 - acc: 0.6844 - val_loss: 1.2473 - val_acc: 0.6423\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.1383 - acc: 0.6873 - val_loss: 1.2079 - val_acc: 0.6672\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1324 - acc: 0.6890 - val_loss: 1.2759 - val_acc: 0.6556\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.1374 - acc: 0.6834 - val_loss: 1.2054 - val_acc: 0.6489\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 2s 334us/step - loss: 1.1238 - acc: 0.6884 - val_loss: 1.2008 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 2s 312us/step - loss: 1.1172 - acc: 0.6877 - val_loss: 1.1846 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 2s 363us/step - loss: 1.1097 - acc: 0.6864 - val_loss: 1.1926 - val_acc: 0.6572\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 347us/step - loss: 1.1074 - acc: 0.6820 - val_loss: 1.6124 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 2s 392us/step - loss: 1.1861 - acc: 0.6753 - val_loss: 1.1221 - val_acc: 0.6705\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 2s 323us/step - loss: 1.1058 - acc: 0.6840 - val_loss: 1.1018 - val_acc: 0.6822\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 2s 343us/step - loss: 1.0975 - acc: 0.6814 - val_loss: 1.1072 - val_acc: 0.6722\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 2s 349us/step - loss: 1.0880 - acc: 0.6897 - val_loss: 1.1326 - val_acc: 0.6622\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.0901 - acc: 0.6881 - val_loss: 1.1130 - val_acc: 0.6789\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 2s 345us/step - loss: 1.0787 - acc: 0.6892 - val_loss: 1.1593 - val_acc: 0.6606\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 2s 344us/step - loss: 1.0708 - acc: 0.6897 - val_loss: 1.1846 - val_acc: 0.6722\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 2s 366us/step - loss: 1.0741 - acc: 0.6881 - val_loss: 1.0673 - val_acc: 0.6739\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0579 - acc: 0.6916 - val_loss: 1.0752 - val_acc: 0.6889\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.0544 - acc: 0.6905 - val_loss: 1.0913 - val_acc: 0.6689\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.0502 - acc: 0.6906 - val_loss: 1.1741 - val_acc: 0.6689\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.0660 - acc: 0.6862 - val_loss: 1.0898 - val_acc: 0.6689\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.0454 - acc: 0.6908 - val_loss: 1.1046 - val_acc: 0.6705\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.0406 - acc: 0.6914 - val_loss: 1.0768 - val_acc: 0.6622\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.0428 - acc: 0.6888 - val_loss: 1.1954 - val_acc: 0.6206\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.0309 - acc: 0.6897 - val_loss: 1.4443 - val_acc: 0.4975\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.0509 - acc: 0.6866 - val_loss: 1.1381 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.0331 - acc: 0.6884 - val_loss: 1.1102 - val_acc: 0.6622\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.0207 - acc: 0.6940 - val_loss: 1.0565 - val_acc: 0.6656\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.0218 - acc: 0.6906 - val_loss: 1.0873 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 2s 327us/step - loss: 1.0185 - acc: 0.6914 - val_loss: 1.0687 - val_acc: 0.6722\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 2s 340us/step - loss: 1.0177 - acc: 0.6927 - val_loss: 1.0529 - val_acc: 0.6739\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 322us/step - loss: 1.0084 - acc: 0.6938 - val_loss: 1.0857 - val_acc: 0.6639\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 326us/step - loss: 1.0109 - acc: 0.6895 - val_loss: 1.0789 - val_acc: 0.6572\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 2s 365us/step - loss: 1.0064 - acc: 0.6925 - val_loss: 1.2633 - val_acc: 0.6572\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 2s 320us/step - loss: 1.0064 - acc: 0.6921 - val_loss: 1.0539 - val_acc: 0.6755\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.0027 - acc: 0.6910 - val_loss: 1.0302 - val_acc: 0.6722\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.9944 - acc: 0.6930 - val_loss: 1.0517 - val_acc: 0.6739\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 2s 322us/step - loss: 0.9910 - acc: 0.6934 - val_loss: 1.3500 - val_acc: 0.5574\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 326us/step - loss: 1.0017 - acc: 0.6919 - val_loss: 1.1139 - val_acc: 0.6473\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 0.9918 - acc: 0.6960 - val_loss: 1.3243 - val_acc: 0.6572\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 2s 359us/step - loss: 1.0024 - acc: 0.6916 - val_loss: 1.0546 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 2s 366us/step - loss: 0.9791 - acc: 0.6977 - val_loss: 1.0878 - val_acc: 0.6672\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 2s 328us/step - loss: 0.9763 - acc: 0.6953 - val_loss: 1.0415 - val_acc: 0.6672\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 2s 337us/step - loss: 0.9729 - acc: 0.6960 - val_loss: 1.0280 - val_acc: 0.6805\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.9745 - acc: 0.6953 - val_loss: 0.9977 - val_acc: 0.6772\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.9720 - acc: 0.6932 - val_loss: 1.0037 - val_acc: 0.6739\n",
      "5408/5408 [==============================] - 2s 284us/step\n",
      "4006/4006 [==============================] - 1s 341us/step\n",
      "5408/5408 [==============================] - 2s 346us/step\n",
      "4006/4006 [==============================] - 1s 325us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  5\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  40\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: 1.7869 - acc: 0.6624 - val_loss: 1.7358 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.6982 - acc: 0.6686 - val_loss: 1.6875 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.6648 - acc: 0.6686 - val_loss: 1.6642 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.6448 - acc: 0.6686 - val_loss: 1.6578 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.6241 - acc: 0.6686 - val_loss: 1.6727 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.6138 - acc: 0.6686 - val_loss: 1.6134 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.5896 - acc: 0.6686 - val_loss: 1.6300 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.5744 - acc: 0.6686 - val_loss: 1.5655 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.5490 - acc: 0.6686 - val_loss: 1.5610 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.5260 - acc: 0.668 - 1s 232us/step - loss: 1.5264 - acc: 0.6686 - val_loss: 1.6224 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.5249 - acc: 0.6686 - val_loss: 1.5459 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.5055 - acc: 0.667 - 1s 207us/step - loss: 1.5006 - acc: 0.6686 - val_loss: 1.6639 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.4962 - acc: 0.6686 - val_loss: 1.5006 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.4743 - acc: 0.6686 - val_loss: 1.4919 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.4611 - acc: 0.6686 - val_loss: 1.5258 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.4537 - acc: 0.6686 - val_loss: 1.5025 - val_acc: 0.6572\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 230us/step - loss: 1.4414 - acc: 0.6686 - val_loss: 1.4450 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.4281 - acc: 0.6686 - val_loss: 1.4846 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.4201 - acc: 0.6686 - val_loss: 1.4381 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.4074 - acc: 0.6686 - val_loss: 1.4350 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 1.3915 - acc: 0.6686 - val_loss: 1.4974 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.3828 - acc: 0.6686 - val_loss: 1.4155 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.3778 - acc: 0.6686 - val_loss: 1.4271 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.3642 - acc: 0.6686 - val_loss: 1.4188 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 1.3562 - acc: 0.6686 - val_loss: 1.6119 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3464 - acc: 0.6686 - val_loss: 1.3547 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.3283 - acc: 0.6686 - val_loss: 1.3324 - val_acc: 0.65720s - loss: 1.3189 - ac\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.3173 - acc: 0.6686 - val_loss: 1.4973 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.3130 - acc: 0.6688 - val_loss: 1.3520 - val_acc: 0.6572\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.3068 - acc: 0.6686 - val_loss: 1.3215 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.2902 - acc: 0.6686 - val_loss: 1.2949 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.2817 - acc: 0.6686 - val_loss: 1.3524 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2774 - acc: 0.6688 - val_loss: 1.2858 - val_acc: 0.6572\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.2607 - acc: 0.6686 - val_loss: 1.3057 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2543 - acc: 0.6686 - val_loss: 1.3299 - val_acc: 0.6572\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.2546 - acc: 0.6688 - val_loss: 1.3602 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.2507 - acc: 0.6688 - val_loss: 1.2927 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2401 - acc: 0.6694 - val_loss: 1.2489 - val_acc: 0.6606\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2266 - acc: 0.6692 - val_loss: 1.5074 - val_acc: 0.6290\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.2224 - acc: 0.6688 - val_loss: 1.2458 - val_acc: 0.6656\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.2184 - acc: 0.6696 - val_loss: 1.4394 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.2281 - acc: 0.6701 - val_loss: 1.1984 - val_acc: 0.6606\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 209us/step - loss: 1.2025 - acc: 0.6744 - val_loss: 1.2572 - val_acc: 0.6639\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.1883 - acc: 0.6749 - val_loss: 1.2319 - val_acc: 0.6606\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.1999 - acc: 0.6746 - val_loss: 1.2815 - val_acc: 0.6473\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1800 - acc: 0.6733 - val_loss: 1.1827 - val_acc: 0.6606\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1719 - acc: 0.6753 - val_loss: 1.2188 - val_acc: 0.6639\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.1804 - acc: 0.6736 - val_loss: 1.3871 - val_acc: 0.6622\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1660 - acc: 0.6759 - val_loss: 1.2458 - val_acc: 0.6672\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1661 - acc: 0.6759 - val_loss: 1.2255 - val_acc: 0.6656\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1522 - acc: 0.6777 - val_loss: 1.2935 - val_acc: 0.6672\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1551 - acc: 0.6771 - val_loss: 1.2100 - val_acc: 0.6722\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1508 - acc: 0.6751 - val_loss: 1.1703 - val_acc: 0.6606\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1360 - acc: 0.6751 - val_loss: 1.1577 - val_acc: 0.6739\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.1337 - acc: 0.6766 - val_loss: 1.2041 - val_acc: 0.6755\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.1311 - acc: 0.6775 - val_loss: 1.1730 - val_acc: 0.6639\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1240 - acc: 0.6797 - val_loss: 1.2661 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1236 - acc: 0.6777 - val_loss: 1.2692 - val_acc: 0.6622\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.1120 - acc: 0.6794 - val_loss: 1.3096 - val_acc: 0.6057\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1197 - acc: 0.6770 - val_loss: 1.2574 - val_acc: 0.6722\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.1079 - acc: 0.6801 - val_loss: 1.1311 - val_acc: 0.6805\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.1124 - acc: 0.6773 - val_loss: 1.3739 - val_acc: 0.5890\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1032 - acc: 0.6733 - val_loss: 1.5265 - val_acc: 0.4825\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1119 - acc: 0.6736 - val_loss: 1.1672 - val_acc: 0.6722\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0969 - acc: 0.6797 - val_loss: 1.1200 - val_acc: 0.6672\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0939 - acc: 0.6807 - val_loss: 1.1026 - val_acc: 0.6855\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0832 - acc: 0.6820 - val_loss: 1.1511 - val_acc: 0.6689\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.0852 - acc: 0.6829 - val_loss: 1.1372 - val_acc: 0.6589\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0873 - acc: 0.6786 - val_loss: 1.1569 - val_acc: 0.6755\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0684 - acc: 0.6803 - val_loss: 1.3824 - val_acc: 0.6572\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.0750 - acc: 0.6797 - val_loss: 1.1393 - val_acc: 0.6606\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0693 - acc: 0.6794 - val_loss: 1.0907 - val_acc: 0.6755\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 213us/step - loss: 1.0704 - acc: 0.6803 - val_loss: 1.1269 - val_acc: 0.6556\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 214us/step - loss: 1.0687 - acc: 0.6808 - val_loss: 1.1000 - val_acc: 0.6689\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0563 - acc: 0.6821 - val_loss: 1.1434 - val_acc: 0.6589\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 224us/step - loss: 1.0660 - acc: 0.6792 - val_loss: 1.6653 - val_acc: 0.6572\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 216us/step - loss: 1.0667 - acc: 0.6821 - val_loss: 1.0608 - val_acc: 0.6839\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0454 - acc: 0.6820 - val_loss: 1.2843 - val_acc: 0.6572\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0589 - acc: 0.6821 - val_loss: 1.0931 - val_acc: 0.6689\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0508 - acc: 0.6825 - val_loss: 1.1154 - val_acc: 0.6789\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 211us/step - loss: 1.0422 - acc: 0.6831 - val_loss: 1.1536 - val_acc: 0.6705\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0390 - acc: 0.6836 - val_loss: 1.0742 - val_acc: 0.6772\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0445 - acc: 0.6795 - val_loss: 1.0511 - val_acc: 0.6822\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0372 - acc: 0.6808 - val_loss: 1.3309 - val_acc: 0.5108\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 208us/step - loss: 1.0418 - acc: 0.6795 - val_loss: 1.0428 - val_acc: 0.6705\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0249 - acc: 0.6803 - val_loss: 1.0559 - val_acc: 0.6855\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.0324 - acc: 0.6790 - val_loss: 1.0453 - val_acc: 0.6672\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.0340 - acc: 0.6797 - val_loss: 1.0743 - val_acc: 0.6772\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.0260 - acc: 0.6836 - val_loss: 1.1824 - val_acc: 0.6473\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0289 - acc: 0.6810 - val_loss: 1.1490 - val_acc: 0.6755\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 205us/step - loss: 1.0326 - acc: 0.6810 - val_loss: 1.0659 - val_acc: 0.6705\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0183 - acc: 0.6812 - val_loss: 1.0407 - val_acc: 0.6839\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0249 - acc: 0.6838 - val_loss: 1.0661 - val_acc: 0.6705\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0188 - acc: 0.6808 - val_loss: 1.2053 - val_acc: 0.6556\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 207us/step - loss: 1.0223 - acc: 0.6810 - val_loss: 1.2410 - val_acc: 0.6423\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.0206 - acc: 0.681 - 1s 207us/step - loss: 1.0201 - acc: 0.6821 - val_loss: 1.0221 - val_acc: 0.6755\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.0064 - acc: 0.6829 - val_loss: 1.1752 - val_acc: 0.6073\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.0188 - acc: 0.6779 - val_loss: 1.0957 - val_acc: 0.6589\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 210us/step - loss: 1.0065 - acc: 0.6827 - val_loss: 1.0812 - val_acc: 0.6705\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 204us/step - loss: 1.0004 - acc: 0.6816 - val_loss: 1.1410 - val_acc: 0.6572\n",
      "5408/5408 [==============================] - 1s 241us/step\n",
      "4006/4006 [==============================] - 1s 245us/step\n",
      "5408/5408 [==============================] - 1s 245us/step\n",
      "4006/4006 [==============================] - 1s 242us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  10\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  40\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: 1.9498 - acc: 0.6293 - val_loss: 1.8401 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 1s 233us/step - loss: 1.8232 - acc: 0.6685 - val_loss: 1.8185 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.8045 - acc: 0.6686 - val_loss: 1.8067 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.7892 - acc: 0.6686 - val_loss: 1.7901 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 1.7748 - acc: 0.6686 - val_loss: 1.7726 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 1.7597 - acc: 0.6686 - val_loss: 1.7638 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.7472 - acc: 0.6686 - val_loss: 1.8400 - val_acc: 0.6439\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.7356 - acc: 0.6685 - val_loss: 1.7226 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.7135 - acc: 0.6686 - val_loss: 1.7054 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 314us/step - loss: 1.6974 - acc: 0.6686 - val_loss: 1.7283 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.6771 - acc: 0.6686 - val_loss: 1.6738 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.6540 - acc: 0.6686 - val_loss: 1.6981 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.6431 - acc: 0.6686 - val_loss: 1.6267 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.6146 - acc: 0.6686 - val_loss: 1.6467 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.5938 - acc: 0.6686 - val_loss: 1.6193 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.5700 - acc: 0.6686 - val_loss: 1.6557 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.5655 - acc: 0.6686 - val_loss: 1.5607 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.5409 - acc: 0.6686 - val_loss: 1.6223 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.5206 - acc: 0.6686 - val_loss: 1.5426 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.5030 - acc: 0.6686 - val_loss: 1.5394 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.4843 - acc: 0.6686 - val_loss: 1.5595 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.4711 - acc: 0.6686 - val_loss: 1.4887 - val_acc: 0.6572\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 1.4561 - acc: 0.6686 - val_loss: 1.5639 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.4541 - acc: 0.6686 - val_loss: 1.5894 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.4330 - acc: 0.6686 - val_loss: 1.4629 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.4222 - acc: 0.6686 - val_loss: 1.4866 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.4040 - acc: 0.6681 - val_loss: 1.4364 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 2s 302us/step - loss: 1.3878 - acc: 0.6686 - val_loss: 1.6148 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.3899 - acc: 0.6686 - val_loss: 1.3853 - val_acc: 0.6572\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.3628 - acc: 0.6686 - val_loss: 1.4151 - val_acc: 0.6572\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.3543 - acc: 0.6686 - val_loss: 1.4377 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.3453 - acc: 0.6688 - val_loss: 1.3691 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.3295 - acc: 0.6694 - val_loss: 1.3424 - val_acc: 0.6589\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.3140 - acc: 0.6696 - val_loss: 1.3727 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3036 - acc: 0.6710 - val_loss: 1.3464 - val_acc: 0.65720s - loss: 1.3076 - a\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2930 - acc: 0.6727 - val_loss: 1.2993 - val_acc: 0.6622\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.2789 - acc: 0.6773 - val_loss: 1.4198 - val_acc: 0.6572\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.3270 - acc: 0.6685 - val_loss: 1.3659 - val_acc: 0.6572\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.2920 - acc: 0.6723 - val_loss: 1.4455 - val_acc: 0.6589\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2722 - acc: 0.6703 - val_loss: 1.2632 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2521 - acc: 0.6685 - val_loss: 1.2603 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.2385 - acc: 0.6722 - val_loss: 1.2886 - val_acc: 0.6572\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2323 - acc: 0.6720 - val_loss: 1.2713 - val_acc: 0.6589\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 1.2175 - acc: 0.6771 - val_loss: 1.2539 - val_acc: 0.6722\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.2142 - acc: 0.6805 - val_loss: 1.4540 - val_acc: 0.6572\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.2101 - acc: 0.6797 - val_loss: 1.3608 - val_acc: 0.6656\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.1987 - acc: 0.6814 - val_loss: 1.3306 - val_acc: 0.6356\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 225us/step - loss: 1.2020 - acc: 0.6783 - val_loss: 1.2685 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.1884 - acc: 0.6829 - val_loss: 1.2723 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 218us/step - loss: 1.1750 - acc: 0.6799 - val_loss: 1.2507 - val_acc: 0.6622\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 1.1857 - acc: 0.6768 - val_loss: 1.2220 - val_acc: 0.6606\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1684 - acc: 0.6770 - val_loss: 1.3646 - val_acc: 0.6622\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1671 - acc: 0.6795 - val_loss: 1.3236 - val_acc: 0.6572\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.1768 - acc: 0.6794 - val_loss: 1.3762 - val_acc: 0.6423\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1541 - acc: 0.6814 - val_loss: 1.2081 - val_acc: 0.6572\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1443 - acc: 0.6825 - val_loss: 1.2261 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1352 - acc: 0.6827 - val_loss: 1.4908 - val_acc: 0.6572\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.1492 - acc: 0.6849 - val_loss: 1.1542 - val_acc: 0.6672\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.1286 - acc: 0.6808 - val_loss: 1.1471 - val_acc: 0.6689\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.1250 - acc: 0.6779 - val_loss: 1.1525 - val_acc: 0.6672\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.1151 - acc: 0.6840 - val_loss: 1.1414 - val_acc: 0.6705\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.1104 - acc: 0.6849 - val_loss: 1.3146 - val_acc: 0.6656\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1121 - acc: 0.6892 - val_loss: 1.1703 - val_acc: 0.6589\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.1065 - acc: 0.6831 - val_loss: 1.1366 - val_acc: 0.6789\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0986 - acc: 0.6871 - val_loss: 1.1912 - val_acc: 0.6389\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0948 - acc: 0.6823 - val_loss: 1.1730 - val_acc: 0.6672\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 217us/step - loss: 1.0916 - acc: 0.6849 - val_loss: 1.2538 - val_acc: 0.6339\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0843 - acc: 0.6884 - val_loss: 1.1094 - val_acc: 0.6589\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0775 - acc: 0.6855 - val_loss: 1.0782 - val_acc: 0.6789\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0727 - acc: 0.6862 - val_loss: 1.1293 - val_acc: 0.6622\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0688 - acc: 0.6893 - val_loss: 1.0710 - val_acc: 0.6805\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.0698 - acc: 0.6858 - val_loss: 1.0898 - val_acc: 0.6689\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.0579 - acc: 0.6906 - val_loss: 1.0593 - val_acc: 0.6789\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.0535 - acc: 0.6912 - val_loss: 1.0667 - val_acc: 0.6705\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0532 - acc: 0.6881 - val_loss: 1.2447 - val_acc: 0.6572\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0500 - acc: 0.6925 - val_loss: 1.1532 - val_acc: 0.6705\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 219us/step - loss: 1.0425 - acc: 0.6914 - val_loss: 1.2438 - val_acc: 0.6639\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0481 - acc: 0.6875 - val_loss: 1.0811 - val_acc: 0.6705\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0388 - acc: 0.6886 - val_loss: 1.0869 - val_acc: 0.6739\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0331 - acc: 0.6916 - val_loss: 1.1891 - val_acc: 0.6572\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0352 - acc: 0.6914 - val_loss: 1.1687 - val_acc: 0.6572\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0354 - acc: 0.6906 - val_loss: 1.1536 - val_acc: 0.6273\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 220us/step - loss: 1.0347 - acc: 0.6855 - val_loss: 1.1171 - val_acc: 0.6656\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0282 - acc: 0.6912 - val_loss: 1.1083 - val_acc: 0.6589\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 222us/step - loss: 1.0185 - acc: 0.6919 - val_loss: 1.3534 - val_acc: 0.5807\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 221us/step - loss: 1.0416 - acc: 0.6849 - val_loss: 1.0176 - val_acc: 0.6822\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 223us/step - loss: 1.0107 - acc: 0.6921 - val_loss: 1.0960 - val_acc: 0.6406\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 1.0086 - acc: 0.6951 - val_loss: 1.0375 - val_acc: 0.6739\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0034 - acc: 0.6914 - val_loss: 1.4082 - val_acc: 0.5025\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0105 - acc: 0.6869 - val_loss: 1.0830 - val_acc: 0.6805\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 237us/step - loss: 1.0082 - acc: 0.6932 - val_loss: 1.0525 - val_acc: 0.6739\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.0035 - acc: 0.6943 - val_loss: 1.0523 - val_acc: 0.6722\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 1.0021 - acc: 0.6893 - val_loss: 1.0876 - val_acc: 0.6656\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.0042 - acc: 0.6890 - val_loss: 1.0330 - val_acc: 0.6639\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 2s 302us/step - loss: 0.9858 - acc: 0.6916 - val_loss: 1.0876 - val_acc: 0.6572\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 0.9925 - acc: 0.6879 - val_loss: 1.2114 - val_acc: 0.6606\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0122 - acc: 0.6851 - val_loss: 1.0556 - val_acc: 0.6755\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.9875 - acc: 0.6943 - val_loss: 1.1159 - val_acc: 0.6572\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 2s 352us/step - loss: 0.9863 - acc: 0.6919 - val_loss: 1.2174 - val_acc: 0.6240\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 2s 370us/step - loss: 0.9935 - acc: 0.6818 - val_loss: 1.2072 - val_acc: 0.6606\n",
      "5408/5408 [==============================] - 2s 368us/step\n",
      "4006/4006 [==============================] - 1s 337us/step\n",
      "5408/5408 [==============================] - 2s 366us/step\n",
      "4006/4006 [==============================] - 2s 381us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  40\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 15s 3ms/step - loss: 1.9648 - acc: 0.6668 - val_loss: 1.9607 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 317us/step - loss: 1.9001 - acc: 0.6686 - val_loss: 1.8748 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.8341 - acc: 0.6686 - val_loss: 1.8161 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.7852 - acc: 0.6686 - val_loss: 1.9246 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.7656 - acc: 0.6686 - val_loss: 1.7650 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.7257 - acc: 0.6686 - val_loss: 1.8059 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.7033 - acc: 0.6686 - val_loss: 1.7261 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.6736 - acc: 0.6685 - val_loss: 1.7052 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.6585 - acc: 0.6686 - val_loss: 1.7720 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.6507 - acc: 0.6686 - val_loss: 1.8174 - val_acc: 0.6556\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.6294 - acc: 0.6685 - val_loss: 1.6151 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 2s 342us/step - loss: 1.6023 - acc: 0.6686 - val_loss: 1.6922 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.5881 - acc: 0.6688 - val_loss: 1.7026 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 1.5691 - acc: 0.6686 - val_loss: 1.6218 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.5475 - acc: 0.6686 - val_loss: 1.5469 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 1.5268 - acc: 0.6686 - val_loss: 1.5715 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.5158 - acc: 0.6686 - val_loss: 1.5986 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.5008 - acc: 0.6686 - val_loss: 1.5248 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.4866 - acc: 0.6703 - val_loss: 1.5062 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.4700 - acc: 0.6736 - val_loss: 1.4755 - val_acc: 0.6622\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.4596 - acc: 0.6757 - val_loss: 1.4773 - val_acc: 0.6672\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 2s 304us/step - loss: 1.4419 - acc: 0.6729 - val_loss: 1.5453 - val_acc: 0.6589\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.4310 - acc: 0.6805 - val_loss: 1.6366 - val_acc: 0.6439\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 1.4217 - acc: 0.6808 - val_loss: 1.4452 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.4026 - acc: 0.6810 - val_loss: 1.4485 - val_acc: 0.6722\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.3949 - acc: 0.6788 - val_loss: 1.3856 - val_acc: 0.6722\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 2s 317us/step - loss: 1.3790 - acc: 0.6816 - val_loss: 1.4234 - val_acc: 0.6639\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 2s 357us/step - loss: 1.3701 - acc: 0.6862 - val_loss: 1.6433 - val_acc: 0.6556\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 2s 312us/step - loss: 1.3586 - acc: 0.6807 - val_loss: 1.4598 - val_acc: 0.6373\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 2s 305us/step - loss: 1.3429 - acc: 0.6855 - val_loss: 1.4019 - val_acc: 0.6639\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.3363 - acc: 0.6820 - val_loss: 1.5220 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 1.3298 - acc: 0.6823 - val_loss: 1.3685 - val_acc: 0.6672\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 1.3119 - acc: 0.6849 - val_loss: 1.4403 - val_acc: 0.6423\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.3113 - acc: 0.6873 - val_loss: 1.4531 - val_acc: 0.6672\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 1.2954 - acc: 0.6844 - val_loss: 1.3575 - val_acc: 0.6589\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2887 - acc: 0.6844 - val_loss: 1.7108 - val_acc: 0.4975\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 2s 314us/step - loss: 1.2918 - acc: 0.6797 - val_loss: 1.3043 - val_acc: 0.6672\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.2672 - acc: 0.6858 - val_loss: 1.3187 - val_acc: 0.6606\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 2s 315us/step - loss: 1.2612 - acc: 0.6888 - val_loss: 1.2865 - val_acc: 0.6772\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 2s 370us/step - loss: 1.2519 - acc: 0.6869 - val_loss: 1.3074 - val_acc: 0.6639\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 2s 364us/step - loss: 1.2500 - acc: 0.6842 - val_loss: 1.2818 - val_acc: 0.6722\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.2423 - acc: 0.6884 - val_loss: 1.4045 - val_acc: 0.6606\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2336 - acc: 0.6875 - val_loss: 1.3002 - val_acc: 0.6589\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2278 - acc: 0.6868 - val_loss: 1.3613 - val_acc: 0.6572\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.2146 - acc: 0.6877 - val_loss: 1.3145 - val_acc: 0.6539\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2167 - acc: 0.6825 - val_loss: 1.2743 - val_acc: 0.6656\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.2020 - acc: 0.6888 - val_loss: 1.2116 - val_acc: 0.6722\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 1.1921 - acc: 0.6849 - val_loss: 1.2898 - val_acc: 0.6389\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 2s 337us/step - loss: 1.1905 - acc: 0.6908 - val_loss: 1.2520 - val_acc: 0.6589\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 2s 316us/step - loss: 1.1847 - acc: 0.6855 - val_loss: 1.5588 - val_acc: 0.5691\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 1.2799 - acc: 0.6725 - val_loss: 1.1933 - val_acc: 0.6755\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 1.1691 - acc: 0.6888 - val_loss: 1.2841 - val_acc: 0.6805\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 2s 313us/step - loss: 1.1611 - acc: 0.6912 - val_loss: 1.1921 - val_acc: 0.6672\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 2s 314us/step - loss: 1.1553 - acc: 0.6895 - val_loss: 1.2678 - val_acc: 0.6606\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 2s 344us/step - loss: 1.1514 - acc: 0.6877 - val_loss: 1.2461 - val_acc: 0.6722\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 1.1498 - acc: 0.6914 - val_loss: 1.1500 - val_acc: 0.6755\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 1.1397 - acc: 0.6905 - val_loss: 1.1629 - val_acc: 0.6739\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.1343 - acc: 0.6899 - val_loss: 1.2051 - val_acc: 0.6539\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.1291 - acc: 0.6893 - val_loss: 1.1656 - val_acc: 0.6622\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.1254 - acc: 0.6912 - val_loss: 1.3229 - val_acc: 0.6572\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.1352 - acc: 0.6853 - val_loss: 1.1861 - val_acc: 0.6705\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.1274 - acc: 0.6823 - val_loss: 1.2715 - val_acc: 0.6556\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.1209 - acc: 0.6864 - val_loss: 1.2467 - val_acc: 0.6572\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1064 - acc: 0.6888 - val_loss: 1.2119 - val_acc: 0.6572\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 2s 308us/step - loss: 1.1006 - acc: 0.6899 - val_loss: 1.1752 - val_acc: 0.6606\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.0949 - acc: 0.6918 - val_loss: 1.3542 - val_acc: 0.6572\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.1128 - acc: 0.6816 - val_loss: 1.1527 - val_acc: 0.6705\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.0872 - acc: 0.6869 - val_loss: 1.1925 - val_acc: 0.6389\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.0894 - acc: 0.6860 - val_loss: 1.2422 - val_acc: 0.6306\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.0752 - acc: 0.6910 - val_loss: 1.4946 - val_acc: 0.4476\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 1.0802 - acc: 0.6873 - val_loss: 1.2820 - val_acc: 0.6539\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 2s 314us/step - loss: 1.0672 - acc: 0.6893 - val_loss: 1.0999 - val_acc: 0.6739\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 2s 333us/step - loss: 1.0660 - acc: 0.6882 - val_loss: 1.1458 - val_acc: 0.6622\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 2s 345us/step - loss: 1.0547 - acc: 0.6895 - val_loss: 1.1312 - val_acc: 0.6722\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 2s 328us/step - loss: 1.0529 - acc: 0.6914 - val_loss: 1.0568 - val_acc: 0.6755\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.0557 - acc: 0.6905 - val_loss: 1.2375 - val_acc: 0.6356\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 2s 330us/step - loss: 1.0580 - acc: 0.6888 - val_loss: 1.1046 - val_acc: 0.6656\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 1.0510 - acc: 0.6849 - val_loss: 1.0781 - val_acc: 0.6755\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 2s 315us/step - loss: 1.0328 - acc: 0.6903 - val_loss: 1.1579 - val_acc: 0.6423\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 2s 341us/step - loss: 1.0354 - acc: 0.6912 - val_loss: 1.0768 - val_acc: 0.6672\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 2s 332us/step - loss: 1.0320 - acc: 0.6901 - val_loss: 1.0653 - val_acc: 0.6755\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 2s 356us/step - loss: 1.0297 - acc: 0.6905 - val_loss: 1.1423 - val_acc: 0.6622\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 2s 340us/step - loss: 1.0262 - acc: 0.6892 - val_loss: 1.1286 - val_acc: 0.6572\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 2s 368us/step - loss: 1.0247 - acc: 0.6871 - val_loss: 1.0572 - val_acc: 0.6772\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 2s 316us/step - loss: 1.0226 - acc: 0.6875 - val_loss: 1.1125 - val_acc: 0.6622\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0160 - acc: 0.6903 - val_loss: 1.3460 - val_acc: 0.5674\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 2s 322us/step - loss: 1.0200 - acc: 0.6882 - val_loss: 1.2902 - val_acc: 0.6622\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 1.0089 - acc: 0.6943 - val_loss: 1.0310 - val_acc: 0.6739\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 2s 344us/step - loss: 0.9974 - acc: 0.6910 - val_loss: 1.1039 - val_acc: 0.6789\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.0145 - acc: 0.691 - 2s 288us/step - loss: 1.0139 - acc: 0.6914 - val_loss: 1.1739 - val_acc: 0.6323\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 2s 326us/step - loss: 1.0019 - acc: 0.6921 - val_loss: 1.0166 - val_acc: 0.6772\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 2s 321us/step - loss: 0.9998 - acc: 0.6908 - val_loss: 1.0445 - val_acc: 0.6772\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.9950 - acc: 0.6901 - val_loss: 1.0604 - val_acc: 0.6689\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 0.9955 - acc: 0.6888 - val_loss: 1.2595 - val_acc: 0.5824\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 2s 318us/step - loss: 0.9936 - acc: 0.6884 - val_loss: 1.1167 - val_acc: 0.6439\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 2s 332us/step - loss: 0.9860 - acc: 0.6893 - val_loss: 1.0876 - val_acc: 0.6656\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 2s 315us/step - loss: 0.9812 - acc: 0.6918 - val_loss: 1.1829 - val_acc: 0.6356\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 2s 305us/step - loss: 0.9920 - acc: 0.6916 - val_loss: 1.6154 - val_acc: 0.4343\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.0584 - acc: 0.6764 - val_loss: 1.0278 - val_acc: 0.6705\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 2s 304us/step - loss: 0.9736 - acc: 0.6962 - val_loss: 1.0103 - val_acc: 0.6689\n",
      "5408/5408 [==============================] - 2s 318us/step\n",
      "4006/4006 [==============================] - 1s 343us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 334us/step\n",
      "4006/4006 [==============================] - 1s 322us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  20\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  40\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 15s 3ms/step - loss: 2.0977 - acc: 0.6568 - val_loss: 1.9904 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.9423 - acc: 0.6686 - val_loss: 1.9800 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.9277 - acc: 0.6686 - val_loss: 1.9218 - val_acc: 0.6572 0s - loss: 1.9354 - acc:\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 2s 302us/step - loss: 1.8860 - acc: 0.6686 - val_loss: 1.8798 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 1.8599 - acc: 0.6686 - val_loss: 1.8579 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.8296 - acc: 0.6686 - val_loss: 1.8759 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.8050 - acc: 0.6686 - val_loss: 1.8458 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.7829 - acc: 0.6686 - val_loss: 1.8127 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.7479 - acc: 0.6686 - val_loss: 1.7532 - val_acc: 0.6572\n",
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.7071 - acc: 0.6686 - val_loss: 1.7606 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.7107 - acc: 0.6686 - val_loss: 1.6958 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.6694 - acc: 0.6686 - val_loss: 1.7401 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 1.6451 - acc: 0.6686 - val_loss: 1.6838 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.6260 - acc: 0.6686 - val_loss: 1.6289 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.6063 - acc: 0.6686 - val_loss: 1.6539 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.5874 - acc: 0.6686 - val_loss: 1.6060 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.5678 - acc: 0.6686 - val_loss: 1.7067 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.5503 - acc: 0.6686 - val_loss: 1.6054 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.5280 - acc: 0.6686 - val_loss: 1.5938 - val_acc: 0.6556\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.5179 - acc: 0.6685 - val_loss: 1.5276 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.5011 - acc: 0.6690 - val_loss: 1.5081 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.4836 - acc: 0.6712 - val_loss: 1.5009 - val_acc: 0.6606\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 1.4707 - acc: 0.6716 - val_loss: 1.5820 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.4668 - acc: 0.6712 - val_loss: 1.4729 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4463 - acc: 0.6734 - val_loss: 1.4717 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.4270 - acc: 0.6757 - val_loss: 1.4892 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.4248 - acc: 0.6736 - val_loss: 1.5562 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4079 - acc: 0.6760 - val_loss: 1.4159 - val_acc: 0.6589\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3903 - acc: 0.6803 - val_loss: 1.4415 - val_acc: 0.6589\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3809 - acc: 0.6792 - val_loss: 1.5811 - val_acc: 0.6389\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 1.3913 - acc: 0.6744 - val_loss: 1.5024 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3717 - acc: 0.6751 - val_loss: 1.4987 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.3566 - acc: 0.6775 - val_loss: 1.3545 - val_acc: 0.6755\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.3404 - acc: 0.6857 - val_loss: 1.3401 - val_acc: 0.6622\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.3209 - acc: 0.6853 - val_loss: 1.5380 - val_acc: 0.6522\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3177 - acc: 0.6829 - val_loss: 1.4167 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 1.3337 - acc: 0.6775 - val_loss: 1.3895 - val_acc: 0.6589\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 2s 324us/step - loss: 1.3124 - acc: 0.6820 - val_loss: 1.3934 - val_acc: 0.6406\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.2868 - acc: 0.6845 - val_loss: 1.2930 - val_acc: 0.6789\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.2730 - acc: 0.683 - 2s 278us/step - loss: 1.2729 - acc: 0.6838 - val_loss: 1.3099 - val_acc: 0.6622\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.2639 - acc: 0.6879 - val_loss: 1.3207 - val_acc: 0.6789\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 1.2609 - acc: 0.6790 - val_loss: 1.4647 - val_acc: 0.5757\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.2584 - acc: 0.6857 - val_loss: 1.3610 - val_acc: 0.6572\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.2504 - acc: 0.6829 - val_loss: 1.3922 - val_acc: 0.6306\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.2342 - acc: 0.6847 - val_loss: 1.2988 - val_acc: 0.6456\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.2223 - acc: 0.6860 - val_loss: 1.2590 - val_acc: 0.6672\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2193 - acc: 0.6827 - val_loss: 1.3243 - val_acc: 0.6572\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.2200 - acc: 0.6832 - val_loss: 1.2523 - val_acc: 0.6755\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.2036 - acc: 0.6836 - val_loss: 1.4514 - val_acc: 0.5674\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2001 - acc: 0.6857 - val_loss: 1.2519 - val_acc: 0.6539\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.1901 - acc: 0.6858 - val_loss: 1.2466 - val_acc: 0.6622\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1838 - acc: 0.6895 - val_loss: 1.3940 - val_acc: 0.6556\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1779 - acc: 0.6855 - val_loss: 1.1995 - val_acc: 0.6689\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.1717 - acc: 0.6873 - val_loss: 1.2252 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1613 - acc: 0.6869 - val_loss: 1.1848 - val_acc: 0.6772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1572 - acc: 0.6906 - val_loss: 1.2522 - val_acc: 0.6572\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 1.1562 - acc: 0.6825 - val_loss: 1.3694 - val_acc: 0.6223\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1618 - acc: 0.6812 - val_loss: 1.1667 - val_acc: 0.6722 - loss: 1.1651 - acc: 0.680\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.1417 - acc: 0.6897 - val_loss: 1.1565 - val_acc: 0.6722\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.1300 - acc: 0.6919 - val_loss: 1.1631 - val_acc: 0.6839\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1287 - acc: 0.6906 - val_loss: 1.2586 - val_acc: 0.6572\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.1358 - acc: 0.6853 - val_loss: 1.2783 - val_acc: 0.6240\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1284 - acc: 0.6851 - val_loss: 1.1719 - val_acc: 0.6606\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.1136 - acc: 0.6869 - val_loss: 1.4484 - val_acc: 0.5524\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.1201 - acc: 0.6836 - val_loss: 1.5838 - val_acc: 0.4559\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.1280 - acc: 0.6855 - val_loss: 1.1405 - val_acc: 0.6855\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.0979 - acc: 0.6910 - val_loss: 1.1485 - val_acc: 0.6622\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.0952 - acc: 0.6899 - val_loss: 1.1004 - val_acc: 0.6772\n",
      "Epoch 69/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.0899 - acc: 0.6903 - val_loss: 1.1310 - val_acc: 0.6772\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0834 - acc: 0.6866 - val_loss: 1.1661 - val_acc: 0.6489\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0811 - acc: 0.6927 - val_loss: 1.2045 - val_acc: 0.6722\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0803 - acc: 0.6888 - val_loss: 1.1626 - val_acc: 0.6705\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.0722 - acc: 0.6918 - val_loss: 1.0965 - val_acc: 0.6839\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0621 - acc: 0.6890 - val_loss: 1.1707 - val_acc: 0.6739\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.0628 - acc: 0.6927 - val_loss: 1.1771 - val_acc: 0.6639\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0800 - acc: 0.6871 - val_loss: 1.1467 - val_acc: 0.6589\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0521 - acc: 0.6929 - val_loss: 1.1313 - val_acc: 0.6622\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0553 - acc: 0.6905 - val_loss: 1.0517 - val_acc: 0.6739\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.0437 - acc: 0.6857 - val_loss: 1.1320 - val_acc: 0.6506\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.0417 - acc: 0.6905 - val_loss: 1.2171 - val_acc: 0.6356\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.0400 - acc: 0.6884 - val_loss: 1.0637 - val_acc: 0.6805\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0416 - acc: 0.6919 - val_loss: 1.1033 - val_acc: 0.6755\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0284 - acc: 0.6908 - val_loss: 1.0417 - val_acc: 0.6822\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 1.0207 - acc: 0.6948- ETA: 0s - loss: 1.0263 - acc: - 1s 247us/step - loss: 1.0205 - acc: 0.6947 - val_loss: 1.0755 - val_acc: 0.6606\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0295 - acc: 0.6875 - val_loss: 1.1576 - val_acc: 0.6639\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0227 - acc: 0.6923 - val_loss: 1.3922 - val_acc: 0.5424\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0402 - acc: 0.6888 - val_loss: 1.3573 - val_acc: 0.5724\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0194 - acc: 0.6925 - val_loss: 1.0577 - val_acc: 0.6755\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 1.0116 - acc: 0.6905 - val_loss: 1.2129 - val_acc: 0.6057\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0058 - acc: 0.6943 - val_loss: 1.0940 - val_acc: 0.6705\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0046 - acc: 0.6929 - val_loss: 1.0664 - val_acc: 0.6622\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9984 - acc: 0.6921 - val_loss: 1.0258 - val_acc: 0.6772\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9936 - acc: 0.6934 - val_loss: 1.1641 - val_acc: 0.6572\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0143 - acc: 0.6881 - val_loss: 1.0323 - val_acc: 0.6789\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9894 - acc: 0.6951 - val_loss: 1.1206 - val_acc: 0.6489\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9970 - acc: 0.6943 - val_loss: 1.0522 - val_acc: 0.6805\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.9876 - acc: 0.6929 - val_loss: 1.0399 - val_acc: 0.6855\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9905 - acc: 0.6905 - val_loss: 1.0683 - val_acc: 0.6689\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9735 - acc: 0.6995 - val_loss: 1.1353 - val_acc: 0.6639\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9792 - acc: 0.6956 - val_loss: 0.9822 - val_acc: 0.6755\n",
      "5408/5408 [==============================] - 1s 262us/step\n",
      "4006/4006 [==============================] - 1s 264us/step\n",
      "5408/5408 [==============================] - 1s 268us/step\n",
      "4006/4006 [==============================] - 1s 264us/step\n",
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  25\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  40\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: 2.1969 - acc: 0.6339 - val_loss: 2.0606 - val_acc: 0.6572\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.9816 - acc: 0.6686 - val_loss: 1.9794 - val_acc: 0.6572\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.9289 - acc: 0.6686 - val_loss: 1.9478 - val_acc: 0.6572\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.9146 - acc: 0.6686 - val_loss: 1.9141 - val_acc: 0.6572\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.8962 - acc: 0.6686 - val_loss: 1.9012 - val_acc: 0.6572\n",
      "Epoch 6/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.8744 - acc: 0.6686 - val_loss: 1.8793 - val_acc: 0.6572\n",
      "Epoch 7/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.8483 - acc: 0.6686 - val_loss: 1.8558 - val_acc: 0.6572\n",
      "Epoch 8/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.8354 - acc: 0.6686 - val_loss: 1.8240 - val_acc: 0.6572\n",
      "Epoch 9/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.8060 - acc: 0.6686 - val_loss: 1.8277 - val_acc: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.8005 - acc: 0.6686 - val_loss: 1.8056 - val_acc: 0.6572\n",
      "Epoch 11/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 1.7798 - acc: 0.6686 - val_loss: 1.7835 - val_acc: 0.6572\n",
      "Epoch 12/100\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.7415 - acc: 0.6686 - val_loss: 1.7297 - val_acc: 0.6572\n",
      "Epoch 13/100\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 1.7065 - acc: 0.6686 - val_loss: 1.7612 - val_acc: 0.6572\n",
      "Epoch 14/100\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 1.6867 - acc: 0.6686 - val_loss: 1.7234 - val_acc: 0.6572\n",
      "Epoch 15/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.6632 - acc: 0.6686 - val_loss: 1.6675 - val_acc: 0.6572\n",
      "Epoch 16/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.6418 - acc: 0.6686 - val_loss: 1.7396 - val_acc: 0.6572\n",
      "Epoch 17/100\n",
      "5408/5408 [==============================] - 2s 304us/step - loss: 1.6271 - acc: 0.6686 - val_loss: 1.6265 - val_acc: 0.6572\n",
      "Epoch 18/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.6031 - acc: 0.6686 - val_loss: 1.6483 - val_acc: 0.6572\n",
      "Epoch 19/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.5898 - acc: 0.6686 - val_loss: 1.6163 - val_acc: 0.6572\n",
      "Epoch 20/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.5675 - acc: 0.6686 - val_loss: 1.5998 - val_acc: 0.6572\n",
      "Epoch 21/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.5555 - acc: 0.6686 - val_loss: 1.6433 - val_acc: 0.6572\n",
      "Epoch 22/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.5355 - acc: 0.6686 - val_loss: 1.5930 - val_acc: 0.6556\n",
      "Epoch 23/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.5158 - acc: 0.6685 - val_loss: 1.5246 - val_acc: 0.6572\n",
      "Epoch 24/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4952 - acc: 0.6685 - val_loss: 1.5301 - val_acc: 0.6572\n",
      "Epoch 25/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.4821 - acc: 0.6686 - val_loss: 1.5258 - val_acc: 0.6572\n",
      "Epoch 26/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4737 - acc: 0.6686 - val_loss: 1.4886 - val_acc: 0.6572\n",
      "Epoch 27/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.4502 - acc: 0.6690 - val_loss: 1.4517 - val_acc: 0.6572\n",
      "Epoch 28/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.4364 - acc: 0.6688 - val_loss: 1.4766 - val_acc: 0.6572\n",
      "Epoch 29/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4237 - acc: 0.6692 - val_loss: 1.4546 - val_acc: 0.6556\n",
      "Epoch 30/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.4036 - acc: 0.6688 - val_loss: 1.4585 - val_acc: 0.6556\n",
      "Epoch 31/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.4006 - acc: 0.6692 - val_loss: 1.4303 - val_acc: 0.6572\n",
      "Epoch 32/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.3865 - acc: 0.6690 - val_loss: 1.4380 - val_acc: 0.6572\n",
      "Epoch 33/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.3721 - acc: 0.6690 - val_loss: 1.6857 - val_acc: 0.6506\n",
      "Epoch 34/100\n",
      "5408/5408 [==============================] - 2s 326us/step - loss: 1.4125 - acc: 0.6688 - val_loss: 1.4939 - val_acc: 0.6572\n",
      "Epoch 35/100\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.3567 - acc: 0.6701 - val_loss: 1.3452 - val_acc: 0.6589\n",
      "Epoch 36/100\n",
      "5408/5408 [==============================] - 2s 334us/step - loss: 1.3379 - acc: 0.6718 - val_loss: 1.3621 - val_acc: 0.6572\n",
      "Epoch 37/100\n",
      "5408/5408 [==============================] - 2s 304us/step - loss: 1.3298 - acc: 0.6694 - val_loss: 1.4614 - val_acc: 0.6656\n",
      "Epoch 38/100\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 1.3328 - acc: 0.6696 - val_loss: 1.5205 - val_acc: 0.6556\n",
      "Epoch 39/100\n",
      "5408/5408 [==============================] - 2s 321us/step - loss: 1.3356 - acc: 0.6718 - val_loss: 1.4137 - val_acc: 0.6572\n",
      "Epoch 40/100\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 1.3072 - acc: 0.6701 - val_loss: 1.4743 - val_acc: 0.6572\n",
      "Epoch 41/100\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 1.2947 - acc: 0.6736 - val_loss: 1.3582 - val_acc: 0.6572\n",
      "Epoch 42/100\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.2868 - acc: 0.6718 - val_loss: 1.3379 - val_acc: 0.6589\n",
      "Epoch 43/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.2748 - acc: 0.6749 - val_loss: 1.3686 - val_acc: 0.6656\n",
      "Epoch 44/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2712 - acc: 0.6744 - val_loss: 1.5172 - val_acc: 0.6439\n",
      "Epoch 45/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2639 - acc: 0.6757 - val_loss: 1.3096 - val_acc: 0.6606\n",
      "Epoch 46/100\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.2548 - acc: 0.6790 - val_loss: 1.3147 - val_acc: 0.6589\n",
      "Epoch 47/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.2397 - acc: 0.6795 - val_loss: 1.2906 - val_acc: 0.6556\n",
      "Epoch 48/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.2304 - acc: 0.6838 - val_loss: 1.3013 - val_acc: 0.6705\n",
      "Epoch 49/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.2252 - acc: 0.6827 - val_loss: 1.5038 - val_acc: 0.6572\n",
      "Epoch 50/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2249 - acc: 0.6799 - val_loss: 1.2640 - val_acc: 0.6556\n",
      "Epoch 51/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2118 - acc: 0.6840 - val_loss: 1.2571 - val_acc: 0.6589\n",
      "Epoch 52/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.1986 - acc: 0.6866 - val_loss: 1.7161 - val_acc: 0.3644\n",
      "Epoch 53/100\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.2162 - acc: 0.6784 - val_loss: 1.2472 - val_acc: 0.6755\n",
      "Epoch 54/100\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1868 - acc: 0.6857 - val_loss: 1.3051 - val_acc: 0.6572\n",
      "Epoch 55/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.1882 - acc: 0.6818 - val_loss: 1.4113 - val_acc: 0.6173\n",
      "Epoch 56/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1861 - acc: 0.6753 - val_loss: 1.2948 - val_acc: 0.6506\n",
      "Epoch 57/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.1731 - acc: 0.6803 - val_loss: 1.2387 - val_acc: 0.6622\n",
      "Epoch 58/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.1696 - acc: 0.6866 - val_loss: 1.1736 - val_acc: 0.6672\n",
      "Epoch 59/100\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.1537 - acc: 0.6864 - val_loss: 1.5153 - val_acc: 0.6439\n",
      "Epoch 60/100\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.1813 - acc: 0.6770 - val_loss: 1.2067 - val_acc: 0.6589\n",
      "Epoch 61/100\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 1.1454 - acc: 0.6844 - val_loss: 1.1689 - val_acc: 0.6739\n",
      "Epoch 62/100\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.1408 - acc: 0.6847 - val_loss: 1.4283 - val_acc: 0.6273\n",
      "Epoch 63/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.1488 - acc: 0.6805 - val_loss: 1.1976 - val_acc: 0.6489\n",
      "Epoch 64/100\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.1326 - acc: 0.6836 - val_loss: 1.2378 - val_acc: 0.6672\n",
      "Epoch 65/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1318 - acc: 0.6825 - val_loss: 1.5984 - val_acc: 0.4260\n",
      "Epoch 66/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.1263 - acc: 0.6832 - val_loss: 1.2176 - val_acc: 0.6589\n",
      "Epoch 67/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1263 - acc: 0.6845 - val_loss: 1.1908 - val_acc: 0.6622\n",
      "Epoch 68/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1058 - acc: 0.6844 - val_loss: 1.3489 - val_acc: 0.6589\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1049 - acc: 0.6901 - val_loss: 1.2172 - val_acc: 0.6622\n",
      "Epoch 70/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0897 - acc: 0.6888 - val_loss: 1.1837 - val_acc: 0.6606\n",
      "Epoch 71/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0952 - acc: 0.6899 - val_loss: 1.2301 - val_acc: 0.6572\n",
      "Epoch 72/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.0916 - acc: 0.6858 - val_loss: 1.1670 - val_acc: 0.6572\n",
      "Epoch 73/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0945 - acc: 0.6860 - val_loss: 1.2028 - val_acc: 0.6522\n",
      "Epoch 74/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.0824 - acc: 0.6869 - val_loss: 1.5286 - val_acc: 0.4925\n",
      "Epoch 75/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0908 - acc: 0.6814 - val_loss: 1.2513 - val_acc: 0.6273\n",
      "Epoch 76/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0812 - acc: 0.6908 - val_loss: 1.0771 - val_acc: 0.6755\n",
      "Epoch 77/100\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.0623 - acc: 0.6879 - val_loss: 1.3205 - val_acc: 0.6639\n",
      "Epoch 78/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0691 - acc: 0.6888 - val_loss: 1.0813 - val_acc: 0.6739\n",
      "Epoch 79/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0601 - acc: 0.6888 - val_loss: 1.0673 - val_acc: 0.6705\n",
      "Epoch 80/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0540 - acc: 0.6903 - val_loss: 1.1020 - val_acc: 0.6772\n",
      "Epoch 81/100\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.0524 - acc: 0.6921 - val_loss: 1.0648 - val_acc: 0.6822\n",
      "Epoch 82/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0482 - acc: 0.6897 - val_loss: 1.0924 - val_acc: 0.6805\n",
      "Epoch 83/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0455 - acc: 0.6906 - val_loss: 1.0743 - val_acc: 0.6755\n",
      "Epoch 84/100\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0404 - acc: 0.6906 - val_loss: 1.0800 - val_acc: 0.6722\n",
      "Epoch 85/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0372 - acc: 0.6910 - val_loss: 1.0535 - val_acc: 0.6755\n",
      "Epoch 86/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0296 - acc: 0.6929 - val_loss: 1.5100 - val_acc: 0.4659\n",
      "Epoch 87/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0428 - acc: 0.6903 - val_loss: 1.0487 - val_acc: 0.6672\n",
      "Epoch 88/100\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 1.0194 - acc: 0.6929 - val_loss: 1.0413 - val_acc: 0.6689\n",
      "Epoch 89/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0265 - acc: 0.6914 - val_loss: 1.0786 - val_acc: 0.6622\n",
      "Epoch 90/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0244 - acc: 0.6918 - val_loss: 1.1076 - val_acc: 0.6522\n",
      "Epoch 91/100\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0159 - acc: 0.6947 - val_loss: 1.2829 - val_acc: 0.6572\n",
      "Epoch 92/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0107 - acc: 0.6979 - val_loss: 1.2544 - val_acc: 0.6572\n",
      "Epoch 93/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0050 - acc: 0.6971 - val_loss: 1.1362 - val_acc: 0.6589\n",
      "Epoch 94/100\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0087 - acc: 0.6984 - val_loss: 1.0855 - val_acc: 0.6622\n",
      "Epoch 95/100\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 1.0051 - acc: 0.6945 - val_loss: 1.2201 - val_acc: 0.6622\n",
      "Epoch 96/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0151 - acc: 0.6943 - val_loss: 1.0809 - val_acc: 0.6622\n",
      "Epoch 97/100\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9940 - acc: 0.6964 - val_loss: 1.0597 - val_acc: 0.6572\n",
      "Epoch 98/100\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.9958 - acc: 0.6943 - val_loss: 1.0649 - val_acc: 0.6722\n",
      "Epoch 99/100\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.9904 - acc: 0.6960 - val_loss: 1.0712 - val_acc: 0.6739\n",
      "Epoch 100/100\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.9860 - acc: 0.6973 - val_loss: 1.0320 - val_acc: 0.6672\n",
      "5408/5408 [==============================] - 1s 275us/step\n",
      "4006/4006 [==============================] - 1s 275us/step\n",
      "5408/5408 [==============================] - 1s 274us/step\n",
      "4006/4006 [==============================] - 1s 281us/step\n"
     ]
    }
   ],
   "source": [
    "# Here we use eta = 0.01 and lambda = 0.01, since they denoted the best results\n",
    "\n",
    "train_accuracy2 = np.zeros((len(n_neuron_values), len(n_filter_values)))\n",
    "test_accuracy2 = np.zeros((len(n_neuron_values), len(n_filter_values)))\n",
    "train_loss = np.zeros((len(n_neuron_values), len(n_filter_values)))\n",
    "test_loss = np.zeros((len(n_neuron_values), len(n_filter_values)))\n",
    "\n",
    "for i, n_neuron in enumerate(n_neuron_values):\n",
    "    for j, n_filter in enumerate(n_filter_values):\n",
    "        # Creating the model\n",
    "        CNN_model = create_convolutional_NN(input_shape, n_neuron, n_categories, eta=0.01, lmbd=0.01, \n",
    "                                            n_filters = n_filter, filter_sizes = receptive_field)\n",
    "        \n",
    "        # Fitting the model with the training data\n",
    "        CNN_model.fit(train, train_labels, epochs = epochs, batch_size = 100, verbose = 1, \n",
    "                      validation_data = (valid, valid_labels))\n",
    "        \n",
    "        # Saving accuracy scores \n",
    "        train_accuracy2[i][j] = CNN_model.evaluate(train, train_labels)[1]\n",
    "        test_accuracy2[i][j] = CNN_model.evaluate(test, test_labels)[1]\n",
    "        \n",
    "        train_loss[i][j] = CNN_model.evaluate(train, train_labels)[0]\n",
    "        test_loss[i][j] = CNN_model.evaluate(test, test_labels)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_neuronsVSfilters(n_neuron_values,n_filter_values,train_accuracy2,test_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_neuronsVSfilters(n_neuron_values,n_filter_values,train_loss,test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Network model with the following parameters:\n",
      "------------------------------------------------------------------\n",
      "Learning rate eta =  0.01\n",
      "regularization strength lambda =  0.01\n",
      "\n",
      "Number of convolutional layers:  1\n",
      "Number of filters in each convolutional layer:  15\n",
      "Filter size in each convolutional layer:  3\n",
      "\n",
      "Number of hidden layers:  1\n",
      "Nunber of neurons in each hidden layer:  30\n",
      "Train on 5408 samples, validate on 601 samples\n",
      "Epoch 1/1000\n",
      "5408/5408 [==============================] - 14s 3ms/step - loss: 2.0022 - acc: 0.5945 - val_loss: 1.8400 - val_acc: 0.6572\n",
      "Epoch 2/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.7916 - acc: 0.6686 - val_loss: 1.7939 - val_acc: 0.6572\n",
      "Epoch 3/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 1.7610 - acc: 0.6686 - val_loss: 1.7646 - val_acc: 0.6572\n",
      "Epoch 4/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.7407 - acc: 0.6686 - val_loss: 1.7441 - val_acc: 0.6572\n",
      "Epoch 5/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.7243 - acc: 0.6686 - val_loss: 1.7300 - val_acc: 0.6572\n",
      "Epoch 6/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.7103 - acc: 0.6686 - val_loss: 1.7152 - val_acc: 0.6572\n",
      "Epoch 7/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.6966 - acc: 0.6686 - val_loss: 1.7022 - val_acc: 0.6572\n",
      "Epoch 8/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.6835 - acc: 0.6686 - val_loss: 1.6884 - val_acc: 0.6572\n",
      "Epoch 9/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.6649 - acc: 0.6686 - val_loss: 1.6757 - val_acc: 0.6572\n",
      "Epoch 10/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 1.6494 - acc: 0.6686 - val_loss: 1.6677 - val_acc: 0.6572\n",
      "Epoch 11/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 1.6492 - acc: 0.6686 - val_loss: 1.6536 - val_acc: 0.6572\n",
      "Epoch 12/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.6377 - acc: 0.6686 - val_loss: 1.6419 - val_acc: 0.6572\n",
      "Epoch 13/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.6263 - acc: 0.6686 - val_loss: 1.6306 - val_acc: 0.6572 - loss: 1.6299 - a\n",
      "Epoch 14/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.6154 - acc: 0.6686 - val_loss: 1.6207 - val_acc: 0.6572 loss: 1.6179 - acc: 0.6\n",
      "Epoch 15/1000\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 1.6048 - acc: 0.6686 - val_loss: 1.6086 - val_acc: 0.6572\n",
      "Epoch 16/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.5950 - acc: 0.6686 - val_loss: 1.5972 - val_acc: 0.6572\n",
      "Epoch 17/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.5846 - acc: 0.6686 - val_loss: 1.5880 - val_acc: 0.6572\n",
      "Epoch 18/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 1.5748 - acc: 0.6686 - val_loss: 1.5784 - val_acc: 0.6572\n",
      "Epoch 19/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.5652 - acc: 0.6686 - val_loss: 1.5690 - val_acc: 0.6572\n",
      "Epoch 20/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.5556 - acc: 0.6686 - val_loss: 1.5603 - val_acc: 0.6572\n",
      "Epoch 21/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.5465 - acc: 0.6686 - val_loss: 1.5513 - val_acc: 0.6572\n",
      "Epoch 22/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 1.5376 - acc: 0.6686 - val_loss: 1.5485 - val_acc: 0.6572\n",
      "Epoch 23/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.5269 - acc: 0.6686 - val_loss: 1.5354 - val_acc: 0.6572\n",
      "Epoch 24/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 1.5203 - acc: 0.6686 - val_loss: 1.5250 - val_acc: 0.6572\n",
      "Epoch 25/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.5037 - acc: 0.6686 - val_loss: 1.5176 - val_acc: 0.6572\n",
      "Epoch 26/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.4992 - acc: 0.6686 - val_loss: 1.5006 - val_acc: 0.6572\n",
      "Epoch 27/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.4812 - acc: 0.6686 - val_loss: 1.4931 - val_acc: 0.6572\n",
      "Epoch 28/1000\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 1.4712 - acc: 0.6686 - val_loss: 1.4786 - val_acc: 0.6572\n",
      "Epoch 29/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.4606 - acc: 0.6686 - val_loss: 1.4840 - val_acc: 0.6572\n",
      "Epoch 30/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 1.4523 - acc: 0.6686 - val_loss: 1.4812 - val_acc: 0.6572\n",
      "Epoch 31/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.4357 - acc: 0.6686 - val_loss: 1.4321 - val_acc: 0.6572\n",
      "Epoch 32/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.4154 - acc: 0.6686 - val_loss: 1.4409 - val_acc: 0.6572\n",
      "Epoch 33/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.4038 - acc: 0.6686 - val_loss: 1.4865 - val_acc: 0.6572\n",
      "Epoch 34/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3884 - acc: 0.6686 - val_loss: 1.3821 - val_acc: 0.6572\n",
      "Epoch 35/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3637 - acc: 0.6686 - val_loss: 1.3748 - val_acc: 0.6572\n",
      "Epoch 36/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.3550 - acc: 0.6686 - val_loss: 1.5043 - val_acc: 0.6572\n",
      "Epoch 37/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 1.3687 - acc: 0.6686 - val_loss: 1.3769 - val_acc: 0.6572\n",
      "Epoch 38/1000\n",
      "5408/5408 [==============================] - 2s 313us/step - loss: 1.3452 - acc: 0.6686 - val_loss: 1.3726 - val_acc: 0.6572\n",
      "Epoch 39/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.3213 - acc: 0.6686 - val_loss: 1.3481 - val_acc: 0.6572\n",
      "Epoch 40/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.3002 - acc: 0.6686 - val_loss: 1.3984 - val_acc: 0.6572\n",
      "Epoch 41/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.2899 - acc: 0.6686 - val_loss: 1.2975 - val_acc: 0.6572\n",
      "Epoch 42/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.2692 - acc: 0.6686 - val_loss: 1.3362 - val_acc: 0.6572\n",
      "Epoch 43/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2552 - acc: 0.6686 - val_loss: 1.2950 - val_acc: 0.6572\n",
      "Epoch 44/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.2498 - acc: 0.6686 - val_loss: 1.2907 - val_acc: 0.6572\n",
      "Epoch 45/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.2453 - acc: 0.6686 - val_loss: 1.4328 - val_acc: 0.6572\n",
      "Epoch 46/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.2353 - acc: 0.6686 - val_loss: 1.2846 - val_acc: 0.6572\n",
      "Epoch 47/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 1.2223 - acc: 0.6685 - val_loss: 1.4422 - val_acc: 0.6572\n",
      "Epoch 48/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.2414 - acc: 0.6686 - val_loss: 1.5748 - val_acc: 0.6572\n",
      "Epoch 49/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.2157 - acc: 0.6686 - val_loss: 1.2945 - val_acc: 0.6572\n",
      "Epoch 50/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1967 - acc: 0.6686 - val_loss: 1.2661 - val_acc: 0.6572\n",
      "Epoch 51/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 1.1842 - acc: 0.6683 - val_loss: 1.2518 - val_acc: 0.6572\n",
      "Epoch 52/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1754 - acc: 0.6681 - val_loss: 1.2231 - val_acc: 0.6572\n",
      "Epoch 53/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 1.1660 - acc: 0.6688 - val_loss: 1.2308 - val_acc: 0.6589\n",
      "Epoch 54/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.1636 - acc: 0.6699 - val_loss: 1.1753 - val_acc: 0.6539\n",
      "Epoch 55/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 1.1507 - acc: 0.6686 - val_loss: 1.2244 - val_acc: 0.6522\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1493 - acc: 0.6712 - val_loss: 1.2799 - val_acc: 0.6572\n",
      "Epoch 57/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1563 - acc: 0.6699 - val_loss: 1.2692 - val_acc: 0.6439\n",
      "Epoch 58/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.1418 - acc: 0.6718 - val_loss: 1.2519 - val_acc: 0.6572\n",
      "Epoch 59/1000\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 1.1352 - acc: 0.6714 - val_loss: 1.1738 - val_acc: 0.6589\n",
      "Epoch 60/1000\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 1.1324 - acc: 0.6733 - val_loss: 1.1419 - val_acc: 0.6656\n",
      "Epoch 61/1000\n",
      "5408/5408 [==============================] - 2s 331us/step - loss: 1.1280 - acc: 0.6712 - val_loss: 1.1765 - val_acc: 0.6572\n",
      "Epoch 62/1000\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 1.1124 - acc: 0.6746 - val_loss: 1.1862 - val_acc: 0.6589\n",
      "Epoch 63/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 1.1197 - acc: 0.6712 - val_loss: 1.3914 - val_acc: 0.6572\n",
      "Epoch 64/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.1092 - acc: 0.6742 - val_loss: 1.1450 - val_acc: 0.6755\n",
      "Epoch 65/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.1028 - acc: 0.6799 - val_loss: 1.2730 - val_acc: 0.6606: 0s - loss: 1.1157 - a\n",
      "Epoch 66/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0974 - acc: 0.6801 - val_loss: 1.1943 - val_acc: 0.6622\n",
      "Epoch 67/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0932 - acc: 0.6812 - val_loss: 1.1376 - val_acc: 0.6639\n",
      "Epoch 68/1000\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 1.0856 - acc: 0.6810 - val_loss: 1.1159 - val_acc: 0.6705 0s - loss: 1.1021 - acc: \n",
      "Epoch 69/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0905 - acc: 0.6788 - val_loss: 1.1754 - val_acc: 0.6556\n",
      "Epoch 70/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.0828 - acc: 0.6820 - val_loss: 1.1078 - val_acc: 0.6656\n",
      "Epoch 71/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0790 - acc: 0.6797 - val_loss: 1.4141 - val_acc: 0.6572\n",
      "Epoch 72/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.0958 - acc: 0.6777 - val_loss: 1.1824 - val_acc: 0.6589\n",
      "Epoch 73/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0751 - acc: 0.6795 - val_loss: 1.1076 - val_acc: 0.6622\n",
      "Epoch 74/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0695 - acc: 0.6816 - val_loss: 1.0910 - val_acc: 0.6705\n",
      "Epoch 75/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 1.0648 - acc: 0.6829 - val_loss: 1.2350 - val_acc: 0.6040\n",
      "Epoch 76/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0670 - acc: 0.6792 - val_loss: 1.2110 - val_acc: 0.6572\n",
      "Epoch 77/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0618 - acc: 0.6814 - val_loss: 1.2172 - val_acc: 0.6423\n",
      "Epoch 78/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 1.0563 - acc: 0.6821 - val_loss: 1.0713 - val_acc: 0.6772\n",
      "Epoch 79/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 1.0459 - acc: 0.6847 - val_loss: 1.0692 - val_acc: 0.6789\n",
      "Epoch 80/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0432 - acc: 0.6866 - val_loss: 1.1441 - val_acc: 0.6506\n",
      "Epoch 81/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0384 - acc: 0.6858 - val_loss: 1.1509 - val_acc: 0.6556\n",
      "Epoch 82/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0442 - acc: 0.6844 - val_loss: 1.0736 - val_acc: 0.6606\n",
      "Epoch 83/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0322 - acc: 0.6881 - val_loss: 1.0857 - val_acc: 0.6489\n",
      "Epoch 84/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0352 - acc: 0.6857 - val_loss: 1.1524 - val_acc: 0.6639\n",
      "Epoch 85/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 1.0342 - acc: 0.6877 - val_loss: 1.0585 - val_acc: 0.6772\n",
      "Epoch 86/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 1.0310 - acc: 0.6855 - val_loss: 1.0538 - val_acc: 0.6789\n",
      "Epoch 87/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0209 - acc: 0.6892 - val_loss: 1.2519 - val_acc: 0.5840\n",
      "Epoch 88/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 1.0322 - acc: 0.6857 - val_loss: 1.0956 - val_acc: 0.6739\n",
      "Epoch 89/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 1.0245 - acc: 0.6831 - val_loss: 1.1142 - val_acc: 0.6439\n",
      "Epoch 90/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.0212 - acc: 0.6873 - val_loss: 1.0272 - val_acc: 0.6755\n",
      "Epoch 91/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 1.0098 - acc: 0.6864 - val_loss: 1.6126 - val_acc: 0.2928\n",
      "Epoch 92/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 1.0527 - acc: 0.6697 - val_loss: 1.1457 - val_acc: 0.6606\n",
      "Epoch 93/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 1.0111 - acc: 0.6857 - val_loss: 1.0501 - val_acc: 0.6772\n",
      "Epoch 94/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 1.0029 - acc: 0.6886 - val_loss: 1.1039 - val_acc: 0.6589\n",
      "Epoch 95/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 1.0038 - acc: 0.6882 - val_loss: 1.1258 - val_acc: 0.6323\n",
      "Epoch 96/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 1.0053 - acc: 0.6895 - val_loss: 1.0773 - val_acc: 0.6672\n",
      "Epoch 97/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 1.0039 - acc: 0.6860 - val_loss: 1.1089 - val_acc: 0.6373\n",
      "Epoch 98/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.9976 - acc: 0.6862 - val_loss: 1.0447 - val_acc: 0.6739\n",
      "Epoch 99/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9923 - acc: 0.6918 - val_loss: 1.0591 - val_acc: 0.6572\n",
      "Epoch 100/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9992 - acc: 0.6869 - val_loss: 1.0219 - val_acc: 0.6722\n",
      "Epoch 101/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9897 - acc: 0.6892 - val_loss: 1.0698 - val_acc: 0.6705\n",
      "Epoch 102/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9938 - acc: 0.6875 - val_loss: 1.0862 - val_acc: 0.6589\n",
      "Epoch 103/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9896 - acc: 0.6905 - val_loss: 1.1037 - val_acc: 0.6589\n",
      "Epoch 104/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9888 - acc: 0.6884 - val_loss: 1.0333 - val_acc: 0.6689\n",
      "Epoch 105/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9807 - acc: 0.6899 - val_loss: 1.0243 - val_acc: 0.6739\n",
      "Epoch 106/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.9826 - acc: 0.6884 - val_loss: 1.0616 - val_acc: 0.6506\n",
      "Epoch 107/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.9843 - acc: 0.6869 - val_loss: 1.0223 - val_acc: 0.6689\n",
      "Epoch 108/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.9825 - acc: 0.6869 - val_loss: 1.1665 - val_acc: 0.6572\n",
      "Epoch 109/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.9853 - acc: 0.6912 - val_loss: 0.9884 - val_acc: 0.6789\n",
      "Epoch 110/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9762 - acc: 0.6910 - val_loss: 1.0356 - val_acc: 0.6622\n",
      "Epoch 111/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.9777 - acc: 0.6842 - val_loss: 1.1379 - val_acc: 0.6223\n",
      "Epoch 112/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.9753 - acc: 0.6893 - val_loss: 1.0543 - val_acc: 0.6606\n",
      "Epoch 113/1000\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.9813 - acc: 0.686 - 1s 268us/step - loss: 0.9814 - acc: 0.6862 - val_loss: 1.1589 - val_acc: 0.6572\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 296us/step - loss: 0.9812 - acc: 0.6882 - val_loss: 1.1072 - val_acc: 0.6622\n",
      "Epoch 115/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9670 - acc: 0.6916 - val_loss: 1.0943 - val_acc: 0.6606\n",
      "Epoch 116/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9635 - acc: 0.6940 - val_loss: 1.0077 - val_acc: 0.6739\n",
      "Epoch 117/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9630 - acc: 0.6897 - val_loss: 1.0029 - val_acc: 0.6739\n",
      "Epoch 118/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9619 - acc: 0.6918 - val_loss: 1.0070 - val_acc: 0.6689\n",
      "Epoch 119/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9609 - acc: 0.6906 - val_loss: 1.0194 - val_acc: 0.6755\n",
      "Epoch 120/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.9653 - acc: 0.6884 - val_loss: 0.9796 - val_acc: 0.6705\n",
      "Epoch 121/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.9632 - acc: 0.6892 - val_loss: 1.0730 - val_acc: 0.6539\n",
      "Epoch 122/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.9625 - acc: 0.6905 - val_loss: 1.0907 - val_acc: 0.6323\n",
      "Epoch 123/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.9597 - acc: 0.6897 - val_loss: 1.0162 - val_acc: 0.6722\n",
      "Epoch 124/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9543 - acc: 0.6903 - val_loss: 1.0320 - val_acc: 0.6589\n",
      "Epoch 125/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9541 - acc: 0.6942 - val_loss: 0.9907 - val_acc: 0.6789\n",
      "Epoch 126/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9494 - acc: 0.6899 - val_loss: 0.9811 - val_acc: 0.6839\n",
      "Epoch 127/1000\n",
      "5408/5408 [==============================] - 2s 311us/step - loss: 0.9456 - acc: 0.6905 - val_loss: 1.0148 - val_acc: 0.6705\n",
      "Epoch 128/1000\n",
      "5408/5408 [==============================] - 2s 321us/step - loss: 0.9515 - acc: 0.6930 - val_loss: 0.9645 - val_acc: 0.6839\n",
      "Epoch 129/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.9481 - acc: 0.6890 - val_loss: 1.1789 - val_acc: 0.6572\n",
      "Epoch 130/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9617 - acc: 0.6895 - val_loss: 1.3041 - val_acc: 0.5275oss: 0.9986 - acc\n",
      "Epoch 131/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9576 - acc: 0.6857 - val_loss: 0.9699 - val_acc: 0.6789\n",
      "Epoch 132/1000\n",
      "5408/5408 [==============================] - 2s 316us/step - loss: 0.9395 - acc: 0.6958 - val_loss: 0.9783 - val_acc: 0.6772\n",
      "Epoch 133/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9456 - acc: 0.6912 - val_loss: 1.0311 - val_acc: 0.6656\n",
      "Epoch 134/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.9386 - acc: 0.6934 - val_loss: 0.9617 - val_acc: 0.6855\n",
      "Epoch 135/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.9387 - acc: 0.6960 - val_loss: 0.9626 - val_acc: 0.6772\n",
      "Epoch 136/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9410 - acc: 0.6919 - val_loss: 1.0514 - val_acc: 0.6606\n",
      "Epoch 137/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9452 - acc: 0.6927 - val_loss: 1.3077 - val_acc: 0.5824\n",
      "Epoch 138/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9493 - acc: 0.6890 - val_loss: 0.9972 - val_acc: 0.6622\n",
      "Epoch 139/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.9463 - acc: 0.6916 - val_loss: 1.0397 - val_acc: 0.6755\n",
      "Epoch 140/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9390 - acc: 0.6890 - val_loss: 1.0162 - val_acc: 0.6522\n",
      "Epoch 141/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.9466 - acc: 0.6908 - val_loss: 1.1869 - val_acc: 0.5990\n",
      "Epoch 142/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.9471 - acc: 0.6866 - val_loss: 1.0012 - val_acc: 0.6589\n",
      "Epoch 143/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.9314 - acc: 0.6945 - val_loss: 0.9767 - val_acc: 0.6689\n",
      "Epoch 144/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.9319 - acc: 0.6929 - val_loss: 0.9813 - val_acc: 0.6705\n",
      "Epoch 145/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9330 - acc: 0.6953 - val_loss: 1.0193 - val_acc: 0.6439\n",
      "Epoch 146/1000\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 0.9266 - acc: 0.6975 - val_loss: 1.0480 - val_acc: 0.6306\n",
      "Epoch 147/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9349 - acc: 0.6921 - val_loss: 0.9921 - val_acc: 0.6755\n",
      "Epoch 148/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9301 - acc: 0.6947 - val_loss: 1.4243 - val_acc: 0.4443\n",
      "Epoch 149/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9400 - acc: 0.6857 - val_loss: 1.0173 - val_acc: 0.6672\n",
      "Epoch 150/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9277 - acc: 0.6930 - val_loss: 1.1107 - val_acc: 0.6306\n",
      "Epoch 151/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.9330 - acc: 0.6940 - val_loss: 1.1288 - val_acc: 0.6356\n",
      "Epoch 152/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9347 - acc: 0.6912 - val_loss: 1.0051 - val_acc: 0.6456\n",
      "Epoch 153/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9205 - acc: 0.6899 - val_loss: 1.1005 - val_acc: 0.6522\n",
      "Epoch 154/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9328 - acc: 0.6930 - val_loss: 0.9432 - val_acc: 0.6855 - loss: 0.9503 - ac\n",
      "Epoch 155/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9240 - acc: 0.6912 - val_loss: 0.9632 - val_acc: 0.6822\n",
      "Epoch 156/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.9203 - acc: 0.6906 - val_loss: 0.9537 - val_acc: 0.6772\n",
      "Epoch 157/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.9258 - acc: 0.6927 - val_loss: 0.9709 - val_acc: 0.6755\n",
      "Epoch 158/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9214 - acc: 0.6932 - val_loss: 1.4438 - val_acc: 0.4193\n",
      "Epoch 159/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.9399 - acc: 0.6807 - val_loss: 1.0037 - val_acc: 0.6606\n",
      "Epoch 160/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9194 - acc: 0.6986 - val_loss: 0.9875 - val_acc: 0.6705\n",
      "Epoch 161/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9188 - acc: 0.6971 - val_loss: 1.1886 - val_acc: 0.5574\n",
      "Epoch 162/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9396 - acc: 0.6884 - val_loss: 1.0072 - val_acc: 0.6689\n",
      "Epoch 163/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9190 - acc: 0.6967 - val_loss: 0.9415 - val_acc: 0.6789\n",
      "Epoch 164/1000\n",
      "5408/5408 [==============================] - 2s 318us/step - loss: 0.9076 - acc: 0.6966 - val_loss: 1.0069 - val_acc: 0.6639\n",
      "Epoch 165/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9103 - acc: 0.6979 - val_loss: 0.9898 - val_acc: 0.6423\n",
      "Epoch 166/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9138 - acc: 0.6947 - val_loss: 1.0703 - val_acc: 0.6656\n",
      "Epoch 167/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9185 - acc: 0.6958 - val_loss: 0.9223 - val_acc: 0.6872\n",
      "Epoch 168/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9059 - acc: 0.6988 - val_loss: 1.0462 - val_acc: 0.6656\n",
      "Epoch 169/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.9128 - acc: 0.6966 - val_loss: 0.9966 - val_acc: 0.6689\n",
      "Epoch 170/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.9103 - acc: 0.6956 - val_loss: 0.9541 - val_acc: 0.6772\n",
      "Epoch 171/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9052 - acc: 0.6986 - val_loss: 1.0408 - val_acc: 0.6389\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.9095 - acc: 0.6958 - val_loss: 0.9943 - val_acc: 0.6822\n",
      "Epoch 173/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9120 - acc: 0.6958 - val_loss: 1.0287 - val_acc: 0.6423\n",
      "Epoch 174/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9101 - acc: 0.6960 - val_loss: 0.9880 - val_acc: 0.6606\n",
      "Epoch 175/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.9072 - acc: 0.6966 - val_loss: 0.9270 - val_acc: 0.6855\n",
      "Epoch 176/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8980 - acc: 0.6990 - val_loss: 1.1399 - val_acc: 0.6589\n",
      "Epoch 177/1000\n",
      "5408/5408 [==============================] - 2s 305us/step - loss: 0.9121 - acc: 0.6967 - val_loss: 1.0138 - val_acc: 0.6656\n",
      "Epoch 178/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.9049 - acc: 0.6979 - val_loss: 0.9610 - val_acc: 0.6656\n",
      "Epoch 179/1000\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 0.8987 - acc: 0.6999 - val_loss: 0.9703 - val_acc: 0.6373\n",
      "Epoch 180/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.9002 - acc: 0.6969 - val_loss: 1.0446 - val_acc: 0.6156\n",
      "Epoch 181/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9095 - acc: 0.6945 - val_loss: 1.0646 - val_acc: 0.6489\n",
      "Epoch 182/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8967 - acc: 0.7021 - val_loss: 1.0572 - val_acc: 0.6373\n",
      "Epoch 183/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.9014 - acc: 0.6977 - val_loss: 1.0754 - val_acc: 0.6040\n",
      "Epoch 184/1000\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 0.9004 - acc: 0.7030 - val_loss: 0.9636 - val_acc: 0.6722\n",
      "Epoch 185/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.8901 - acc: 0.7023 - val_loss: 1.0497 - val_acc: 0.6672\n",
      "Epoch 186/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8942 - acc: 0.7008 - val_loss: 1.0681 - val_acc: 0.6622\n",
      "Epoch 187/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8927 - acc: 0.7025 - val_loss: 1.0705 - val_acc: 0.6572\n",
      "Epoch 188/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.9050 - acc: 0.6982 - val_loss: 0.9030 - val_acc: 0.6855\n",
      "Epoch 189/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9019 - acc: 0.6995 - val_loss: 1.0436 - val_acc: 0.6639\n",
      "Epoch 190/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.9001 - acc: 0.7006 - val_loss: 1.0726 - val_acc: 0.6606\n",
      "Epoch 191/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8991 - acc: 0.7012 - val_loss: 1.2268 - val_acc: 0.6622\n",
      "Epoch 192/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9074 - acc: 0.6990 - val_loss: 0.9257 - val_acc: 0.6972\n",
      "Epoch 193/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8955 - acc: 0.7028 - val_loss: 1.0134 - val_acc: 0.6772\n",
      "Epoch 194/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8880 - acc: 0.7054 - val_loss: 0.9803 - val_acc: 0.6522\n",
      "Epoch 195/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8827 - acc: 0.7049 - val_loss: 1.6784 - val_acc: 0.4260\n",
      "Epoch 196/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.9159 - acc: 0.6993 - val_loss: 1.0074 - val_acc: 0.6656\n",
      "Epoch 197/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8852 - acc: 0.7036 - val_loss: 1.0800 - val_acc: 0.6739\n",
      "Epoch 198/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.9000 - acc: 0.7054 - val_loss: 1.1361 - val_acc: 0.6339\n",
      "Epoch 199/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8983 - acc: 0.7012 - val_loss: 0.9530 - val_acc: 0.6772\n",
      "Epoch 200/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8839 - acc: 0.7077 - val_loss: 1.0506 - val_acc: 0.6306\n",
      "Epoch 201/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.9004 - acc: 0.7049 - val_loss: 0.9635 - val_acc: 0.6755\n",
      "Epoch 202/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8861 - acc: 0.7053 - val_loss: 0.9331 - val_acc: 0.6872\n",
      "Epoch 203/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8780 - acc: 0.7089 - val_loss: 1.0636 - val_acc: 0.6106\n",
      "Epoch 204/1000\n",
      "5408/5408 [==============================] - 2s 329us/step - loss: 0.8891 - acc: 0.7056 - val_loss: 1.0978 - val_acc: 0.6589\n",
      "Epoch 205/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8825 - acc: 0.7089 - val_loss: 0.9964 - val_acc: 0.6988\n",
      "Epoch 206/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8769 - acc: 0.7112 - val_loss: 1.0098 - val_acc: 0.6822\n",
      "Epoch 207/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8757 - acc: 0.7108 - val_loss: 1.1482 - val_acc: 0.6656\n",
      "Epoch 208/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8784 - acc: 0.7102 - val_loss: 1.2264 - val_acc: 0.6556\n",
      "Epoch 209/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.9002 - acc: 0.7056 - val_loss: 0.8965 - val_acc: 0.7005\n",
      "Epoch 210/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8781 - acc: 0.7126 - val_loss: 1.4625 - val_acc: 0.4093\n",
      "Epoch 211/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.9020 - acc: 0.7036 - val_loss: 0.9388 - val_acc: 0.6855\n",
      "Epoch 212/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8688 - acc: 0.7138 - val_loss: 0.9850 - val_acc: 0.6922\n",
      "Epoch 213/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8777 - acc: 0.7114 - val_loss: 0.9645 - val_acc: 0.6789\n",
      "Epoch 214/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8714 - acc: 0.7149 - val_loss: 0.9745 - val_acc: 0.6705\n",
      "Epoch 215/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8677 - acc: 0.7173 - val_loss: 0.9143 - val_acc: 0.6905\n",
      "Epoch 216/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8648 - acc: 0.7184 - val_loss: 1.1088 - val_acc: 0.6656\n",
      "Epoch 217/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8756 - acc: 0.7121 - val_loss: 0.9310 - val_acc: 0.6739\n",
      "Epoch 218/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8693 - acc: 0.7093 - val_loss: 0.9873 - val_acc: 0.6639\n",
      "Epoch 219/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8718 - acc: 0.7136 - val_loss: 1.0264 - val_acc: 0.6656\n",
      "Epoch 220/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8723 - acc: 0.7102 - val_loss: 1.0502 - val_acc: 0.6689\n",
      "Epoch 221/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8689 - acc: 0.7138 - val_loss: 1.0461 - val_acc: 0.6639\n",
      "Epoch 222/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8738 - acc: 0.7145 - val_loss: 0.9538 - val_acc: 0.6772\n",
      "Epoch 223/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8782 - acc: 0.7095 - val_loss: 0.9185 - val_acc: 0.7171\n",
      "Epoch 224/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8691 - acc: 0.7176 - val_loss: 0.8944 - val_acc: 0.6839\n",
      "Epoch 225/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8669 - acc: 0.7169 - val_loss: 1.0560 - val_acc: 0.6656\n",
      "Epoch 226/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8682 - acc: 0.7151 - val_loss: 1.7344 - val_acc: 0.3910\n",
      "Epoch 227/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8997 - acc: 0.7091 - val_loss: 0.9456 - val_acc: 0.6805\n",
      "Epoch 228/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8690 - acc: 0.7132 - val_loss: 0.9957 - val_acc: 0.6755\n",
      "Epoch 229/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8757 - acc: 0.7121 - val_loss: 0.9777 - val_acc: 0.6639\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8715 - acc: 0.7182 - val_loss: 0.9106 - val_acc: 0.7155\n",
      "Epoch 231/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8633 - acc: 0.7165 - val_loss: 0.9801 - val_acc: 0.6705\n",
      "Epoch 232/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8636 - acc: 0.7200 - val_loss: 0.9311 - val_acc: 0.6955\n",
      "Epoch 233/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8539 - acc: 0.7260 - val_loss: 1.0828 - val_acc: 0.6240\n",
      "Epoch 234/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.9001 - acc: 0.7051 - val_loss: 0.9660 - val_acc: 0.6872\n",
      "Epoch 235/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8573 - acc: 0.7163 - val_loss: 0.9401 - val_acc: 0.6755\n",
      "Epoch 236/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8598 - acc: 0.7219 - val_loss: 1.0036 - val_acc: 0.6606\n",
      "Epoch 237/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8639 - acc: 0.7163 - val_loss: 0.9734 - val_acc: 0.6872\n",
      "Epoch 238/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8583 - acc: 0.7147 - val_loss: 0.9033 - val_acc: 0.7038\n",
      "Epoch 239/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8576 - acc: 0.7228 - val_loss: 1.2961 - val_acc: 0.5158\n",
      "Epoch 240/1000\n",
      "5408/5408 [==============================] - 2s 298us/step - loss: 0.8824 - acc: 0.7084 - val_loss: 1.0678 - val_acc: 0.6839\n",
      "Epoch 241/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8801 - acc: 0.7152 - val_loss: 0.9552 - val_acc: 0.6789\n",
      "Epoch 242/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8592 - acc: 0.7151 - val_loss: 1.0703 - val_acc: 0.6772\n",
      "Epoch 243/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8685 - acc: 0.7173 - val_loss: 1.0606 - val_acc: 0.6672\n",
      "Epoch 244/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8560 - acc: 0.7202 - val_loss: 0.9692 - val_acc: 0.6805\n",
      "Epoch 245/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8599 - acc: 0.7204 - val_loss: 0.9617 - val_acc: 0.7022\n",
      "Epoch 246/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8590 - acc: 0.7186 - val_loss: 0.9822 - val_acc: 0.6522\n",
      "Epoch 247/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8581 - acc: 0.7200 - val_loss: 0.9624 - val_acc: 0.7055\n",
      "Epoch 248/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8599 - acc: 0.7195 - val_loss: 0.9788 - val_acc: 0.6772\n",
      "Epoch 249/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8600 - acc: 0.7221 - val_loss: 0.9123 - val_acc: 0.7022\n",
      "Epoch 250/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8563 - acc: 0.7239 - val_loss: 0.9535 - val_acc: 0.6822\n",
      "Epoch 251/1000\n",
      "5408/5408 [==============================] - 2s 310us/step - loss: 0.8527 - acc: 0.7223 - val_loss: 0.9279 - val_acc: 0.6839\n",
      "Epoch 252/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8555 - acc: 0.7212 - val_loss: 0.9432 - val_acc: 0.6889\n",
      "Epoch 253/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8589 - acc: 0.7178 - val_loss: 0.9072 - val_acc: 0.6955\n",
      "Epoch 254/1000\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 0.8567 - acc: 0.7224 - val_loss: 0.8940 - val_acc: 0.7022\n",
      "Epoch 255/1000\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 0.8590 - acc: 0.7199 - val_loss: 0.9035 - val_acc: 0.6988\n",
      "Epoch 256/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.8562 - acc: 0.7204 - val_loss: 0.9575 - val_acc: 0.6822\n",
      "Epoch 257/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8558 - acc: 0.7241 - val_loss: 0.8979 - val_acc: 0.6972\n",
      "Epoch 258/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8558 - acc: 0.7241 - val_loss: 0.9118 - val_acc: 0.7138\n",
      "Epoch 259/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8444 - acc: 0.7282 - val_loss: 1.2141 - val_acc: 0.5824\n",
      "Epoch 260/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8712 - acc: 0.7182 - val_loss: 1.0535 - val_acc: 0.6889\n",
      "Epoch 261/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8561 - acc: 0.7206 - val_loss: 1.1715 - val_acc: 0.4859\n",
      "Epoch 262/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8621 - acc: 0.7176 - val_loss: 0.9216 - val_acc: 0.6922\n",
      "Epoch 263/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8546 - acc: 0.7241 - val_loss: 0.9330 - val_acc: 0.7072\n",
      "Epoch 264/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8502 - acc: 0.7213 - val_loss: 1.0090 - val_acc: 0.6656\n",
      "Epoch 265/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8490 - acc: 0.7232 - val_loss: 0.9465 - val_acc: 0.6672\n",
      "Epoch 266/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8479 - acc: 0.7226 - val_loss: 0.9563 - val_acc: 0.6955\n",
      "Epoch 267/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8525 - acc: 0.7232 - val_loss: 0.9238 - val_acc: 0.6889\n",
      "Epoch 268/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8464 - acc: 0.7237 - val_loss: 1.1445 - val_acc: 0.6290\n",
      "Epoch 269/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8790 - acc: 0.7163 - val_loss: 0.8944 - val_acc: 0.7088\n",
      "Epoch 270/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8409 - acc: 0.7310 - val_loss: 0.9171 - val_acc: 0.7005\n",
      "Epoch 271/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8503 - acc: 0.7260 - val_loss: 0.9133 - val_acc: 0.7038\n",
      "Epoch 272/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8415 - acc: 0.7286 - val_loss: 0.9660 - val_acc: 0.6855\n",
      "Epoch 273/1000\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 0.8703 - acc: 0.7243 - val_loss: 1.1134 - val_acc: 0.6572\n",
      "Epoch 274/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8663 - acc: 0.7239 - val_loss: 1.0969 - val_acc: 0.6705\n",
      "Epoch 275/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8617 - acc: 0.7226 - val_loss: 0.8949 - val_acc: 0.7038\n",
      "Epoch 276/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8509 - acc: 0.7236 - val_loss: 1.0445 - val_acc: 0.6589\n",
      "Epoch 277/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8547 - acc: 0.7215 - val_loss: 0.9623 - val_acc: 0.6739\n",
      "Epoch 278/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8529 - acc: 0.7212 - val_loss: 0.9345 - val_acc: 0.7005\n",
      "Epoch 279/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8728 - acc: 0.7189 - val_loss: 0.9715 - val_acc: 0.6689\n",
      "Epoch 280/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8548 - acc: 0.7236 - val_loss: 1.2217 - val_acc: 0.4792\n",
      "Epoch 281/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8608 - acc: 0.7193 - val_loss: 0.8879 - val_acc: 0.7055\n",
      "Epoch 282/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8505 - acc: 0.7258 - val_loss: 0.9165 - val_acc: 0.7155 0s - loss: 0.8480 - acc: 0\n",
      "Epoch 283/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8477 - acc: 0.7224 - val_loss: 0.8787 - val_acc: 0.7205\n",
      "Epoch 284/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8397 - acc: 0.7295 - val_loss: 1.0660 - val_acc: 0.6156\n",
      "Epoch 285/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8475 - acc: 0.7263 - val_loss: 0.8850 - val_acc: 0.7121\n",
      "Epoch 286/1000\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 0.8459 - acc: 0.7223 - val_loss: 1.1087 - val_acc: 0.6406\n",
      "Epoch 287/1000\n",
      "5408/5408 [==============================] - 2s 312us/step - loss: 0.8511 - acc: 0.7256 - val_loss: 0.9489 - val_acc: 0.6839oss: 0.8529 - acc: 0.72\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8490 - acc: 0.7269 - val_loss: 0.9289 - val_acc: 0.6955\n",
      "Epoch 289/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8402 - acc: 0.7319 - val_loss: 0.9490 - val_acc: 0.6722\n",
      "Epoch 290/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8494 - acc: 0.7261 - val_loss: 1.2776 - val_acc: 0.6622\n",
      "Epoch 291/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8548 - acc: 0.7224 - val_loss: 1.0430 - val_acc: 0.6173\n",
      "Epoch 292/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8490 - acc: 0.7254 - val_loss: 1.0133 - val_acc: 0.6373\n",
      "Epoch 293/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8415 - acc: 0.7249 - val_loss: 0.9450 - val_acc: 0.6872\n",
      "Epoch 294/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8447 - acc: 0.7276 - val_loss: 0.9808 - val_acc: 0.6905\n",
      "Epoch 295/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8427 - acc: 0.7245 - val_loss: 1.0523 - val_acc: 0.6889\n",
      "Epoch 296/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8497 - acc: 0.7258 - val_loss: 0.9190 - val_acc: 0.6988\n",
      "Epoch 297/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8539 - acc: 0.7232 - val_loss: 0.8795 - val_acc: 0.7138\n",
      "Epoch 298/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8441 - acc: 0.7276 - val_loss: 1.1395 - val_acc: 0.6572\n",
      "Epoch 299/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8623 - acc: 0.7167 - val_loss: 1.0829 - val_acc: 0.6672\n",
      "Epoch 300/1000\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 0.8498 - acc: 0.7241 - val_loss: 1.0761 - val_acc: 0.6639\n",
      "Epoch 301/1000\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 0.8520 - acc: 0.7247 - val_loss: 0.9550 - val_acc: 0.6972\n",
      "Epoch 302/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8392 - acc: 0.7300 - val_loss: 1.1459 - val_acc: 0.6057\n",
      "Epoch 303/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8598 - acc: 0.7265 - val_loss: 0.9274 - val_acc: 0.7005\n",
      "Epoch 304/1000\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 0.8474 - acc: 0.7271 - val_loss: 0.9773 - val_acc: 0.6872\n",
      "Epoch 305/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8440 - acc: 0.7232 - val_loss: 0.9703 - val_acc: 0.7072\n",
      "Epoch 306/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8458 - acc: 0.7276 - val_loss: 1.0127 - val_acc: 0.6539\n",
      "Epoch 307/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8435 - acc: 0.7260 - val_loss: 1.0800 - val_acc: 0.5890\n",
      "Epoch 308/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8451 - acc: 0.7273 - val_loss: 0.9796 - val_acc: 0.6839\n",
      "Epoch 309/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8426 - acc: 0.7252 - val_loss: 0.8896 - val_acc: 0.7088\n",
      "Epoch 310/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8405 - acc: 0.7317 - val_loss: 0.9586 - val_acc: 0.6972\n",
      "Epoch 311/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8392 - acc: 0.7328 - val_loss: 1.0003 - val_acc: 0.6972\n",
      "Epoch 312/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8417 - acc: 0.7271 - val_loss: 0.9972 - val_acc: 0.6755\n",
      "Epoch 313/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8397 - acc: 0.7300 - val_loss: 0.9179 - val_acc: 0.6988\n",
      "Epoch 314/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8356 - acc: 0.7332 - val_loss: 0.9117 - val_acc: 0.7221\n",
      "Epoch 315/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8289 - acc: 0.7343 - val_loss: 0.9662 - val_acc: 0.6473\n",
      "Epoch 316/1000\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 0.8488 - acc: 0.7243 - val_loss: 1.3560 - val_acc: 0.5374\n",
      "Epoch 317/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8588 - acc: 0.7208 - val_loss: 0.9159 - val_acc: 0.6988\n",
      "Epoch 318/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8437 - acc: 0.7311 - val_loss: 0.9729 - val_acc: 0.7205\n",
      "Epoch 319/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8437 - acc: 0.7306 - val_loss: 0.8832 - val_acc: 0.7321\n",
      "Epoch 320/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8419 - acc: 0.7260 - val_loss: 0.9371 - val_acc: 0.6789\n",
      "Epoch 321/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8475 - acc: 0.7328 - val_loss: 0.9381 - val_acc: 0.7038\n",
      "Epoch 322/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8348 - acc: 0.7289 - val_loss: 1.0461 - val_acc: 0.6356\n",
      "Epoch 323/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8556 - acc: 0.7223 - val_loss: 0.8974 - val_acc: 0.6955\n",
      "Epoch 324/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8308 - acc: 0.7341 - val_loss: 0.9358 - val_acc: 0.6938\n",
      "Epoch 325/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8436 - acc: 0.7276 - val_loss: 0.9586 - val_acc: 0.6705\n",
      "Epoch 326/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8430 - acc: 0.7286 - val_loss: 0.9209 - val_acc: 0.7055\n",
      "Epoch 327/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8465 - acc: 0.7298 - val_loss: 1.3779 - val_acc: 0.6606\n",
      "Epoch 328/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8439 - acc: 0.7304 - val_loss: 0.9282 - val_acc: 0.7038\n",
      "Epoch 329/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8369 - acc: 0.7315 - val_loss: 0.8871 - val_acc: 0.7121\n",
      "Epoch 330/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8354 - acc: 0.7306 - val_loss: 1.1872 - val_acc: 0.4925\n",
      "Epoch 331/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8507 - acc: 0.7282 - val_loss: 0.9077 - val_acc: 0.7138\n",
      "Epoch 332/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8363 - acc: 0.7335 - val_loss: 0.9691 - val_acc: 0.6839\n",
      "Epoch 333/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8409 - acc: 0.7302 - val_loss: 1.4300 - val_acc: 0.5374\n",
      "Epoch 334/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8661 - acc: 0.7199 - val_loss: 1.0065 - val_acc: 0.6589\n",
      "Epoch 335/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8378 - acc: 0.7337 - val_loss: 0.9730 - val_acc: 0.6855\n",
      "Epoch 336/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8481 - acc: 0.7321 - val_loss: 1.0176 - val_acc: 0.6722\n",
      "Epoch 337/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8351 - acc: 0.7321 - val_loss: 0.9402 - val_acc: 0.6955\n",
      "Epoch 338/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8436 - acc: 0.7276 - val_loss: 1.4230 - val_acc: 0.4493\n",
      "Epoch 339/1000\n",
      "5408/5408 [==============================] - 2s 321us/step - loss: 0.8946 - acc: 0.7121 - val_loss: 1.0142 - val_acc: 0.6506\n",
      "Epoch 340/1000\n",
      "5408/5408 [==============================] - 2s 328us/step - loss: 0.8353 - acc: 0.7350 - val_loss: 1.0581 - val_acc: 0.6373\n",
      "Epoch 341/1000\n",
      "5408/5408 [==============================] - 2s 316us/step - loss: 0.8425 - acc: 0.7324 - val_loss: 0.9558 - val_acc: 0.7088\n",
      "Epoch 342/1000\n",
      "5408/5408 [==============================] - 2s 320us/step - loss: 0.8473 - acc: 0.7265 - val_loss: 0.9479 - val_acc: 0.7022\n",
      "Epoch 343/1000\n",
      "5408/5408 [==============================] - 2s 327us/step - loss: 0.8362 - acc: 0.7365 - val_loss: 0.9736 - val_acc: 0.6972\n",
      "Epoch 344/1000\n",
      "5408/5408 [==============================] - 2s 325us/step - loss: 0.8419 - acc: 0.7273 - val_loss: 1.1189 - val_acc: 0.6489\n",
      "Epoch 345/1000\n",
      "5408/5408 [==============================] - 2s 318us/step - loss: 0.8517 - acc: 0.7295 - val_loss: 0.8914 - val_acc: 0.7304\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8355 - acc: 0.7322 - val_loss: 0.9304 - val_acc: 0.7138\n",
      "Epoch 347/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8336 - acc: 0.7376 - val_loss: 1.1341 - val_acc: 0.6689\n",
      "Epoch 348/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8557 - acc: 0.7271 - val_loss: 0.8870 - val_acc: 0.7171\n",
      "Epoch 349/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8367 - acc: 0.7306 - val_loss: 1.0921 - val_acc: 0.6656\n",
      "Epoch 350/1000\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 0.8450 - acc: 0.7289 - val_loss: 0.8711 - val_acc: 0.7338\n",
      "Epoch 351/1000\n",
      "5408/5408 [==============================] - 2s 299us/step - loss: 0.8374 - acc: 0.7322 - val_loss: 0.9079 - val_acc: 0.7038\n",
      "Epoch 352/1000\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 0.8433 - acc: 0.7306 - val_loss: 1.0325 - val_acc: 0.6839\n",
      "Epoch 353/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8435 - acc: 0.7337 - val_loss: 0.9890 - val_acc: 0.6822\n",
      "Epoch 354/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8371 - acc: 0.7341 - val_loss: 0.9845 - val_acc: 0.6839\n",
      "Epoch 355/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8366 - acc: 0.7356 - val_loss: 0.9154 - val_acc: 0.6955\n",
      "Epoch 356/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8329 - acc: 0.7324 - val_loss: 0.9572 - val_acc: 0.6689\n",
      "Epoch 357/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8396 - acc: 0.7378 - val_loss: 0.9857 - val_acc: 0.6905\n",
      "Epoch 358/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8270 - acc: 0.7359 - val_loss: 1.0620 - val_acc: 0.6722\n",
      "Epoch 359/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8418 - acc: 0.7317 - val_loss: 1.0379 - val_acc: 0.6839\n",
      "Epoch 360/1000\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 0.8462 - acc: 0.7260 - val_loss: 0.9594 - val_acc: 0.6805\n",
      "Epoch 361/1000\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 0.8394 - acc: 0.7324 - val_loss: 1.3834 - val_acc: 0.4043\n",
      "Epoch 362/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8615 - acc: 0.7202 - val_loss: 0.9798 - val_acc: 0.6789\n",
      "Epoch 363/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8504 - acc: 0.7287 - val_loss: 0.9148 - val_acc: 0.7138\n",
      "Epoch 364/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8330 - acc: 0.7339 - val_loss: 0.9126 - val_acc: 0.7105\n",
      "Epoch 365/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8350 - acc: 0.7315 - val_loss: 1.1766 - val_acc: 0.6656\n",
      "Epoch 366/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8489 - acc: 0.7271 - val_loss: 1.0035 - val_acc: 0.6839\n",
      "Epoch 367/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8394 - acc: 0.7350 - val_loss: 0.9215 - val_acc: 0.7271\n",
      "Epoch 368/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8299 - acc: 0.7335 - val_loss: 0.9199 - val_acc: 0.7171\n",
      "Epoch 369/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8403 - acc: 0.7339 - val_loss: 0.9127 - val_acc: 0.7271\n",
      "Epoch 370/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8422 - acc: 0.7300 - val_loss: 0.8886 - val_acc: 0.7388\n",
      "Epoch 371/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8335 - acc: 0.7363 - val_loss: 0.9276 - val_acc: 0.7221\n",
      "Epoch 372/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8333 - acc: 0.7363 - val_loss: 0.9535 - val_acc: 0.6889\n",
      "Epoch 373/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8398 - acc: 0.7332 - val_loss: 0.9003 - val_acc: 0.7188\n",
      "Epoch 374/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8399 - acc: 0.7354 - val_loss: 0.9215 - val_acc: 0.6955\n",
      "Epoch 375/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8280 - acc: 0.7384 - val_loss: 0.9156 - val_acc: 0.7371\n",
      "Epoch 376/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8357 - acc: 0.7311 - val_loss: 1.0247 - val_acc: 0.6689\n",
      "Epoch 377/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8399 - acc: 0.7278 - val_loss: 0.9771 - val_acc: 0.6606\n",
      "Epoch 378/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8370 - acc: 0.7324 - val_loss: 0.9336 - val_acc: 0.6889\n",
      "Epoch 379/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8347 - acc: 0.7343 - val_loss: 0.8769 - val_acc: 0.7404\n",
      "Epoch 380/1000\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.8340 - acc: 0.736 - 2s 294us/step - loss: 0.8334 - acc: 0.7365 - val_loss: 0.8985 - val_acc: 0.7138\n",
      "Epoch 381/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8331 - acc: 0.7389 - val_loss: 0.9390 - val_acc: 0.7038\n",
      "Epoch 382/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8337 - acc: 0.7324 - val_loss: 0.9168 - val_acc: 0.7121\n",
      "Epoch 383/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8295 - acc: 0.7369 - val_loss: 1.0737 - val_acc: 0.6206\n",
      "Epoch 384/1000\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.8448 - acc: 0.7295 - val_loss: 0.8915 - val_acc: 0.7205\n",
      "Epoch 385/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8355 - acc: 0.7324 - val_loss: 0.9606 - val_acc: 0.7005\n",
      "Epoch 386/1000\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.8343 - acc: 0.7347 - val_loss: 0.9862 - val_acc: 0.6822\n",
      "Epoch 387/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8379 - acc: 0.7311 - val_loss: 0.9044 - val_acc: 0.7055\n",
      "Epoch 388/1000\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 0.8310 - acc: 0.7385 - val_loss: 1.0063 - val_acc: 0.6755\n",
      "Epoch 389/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8391 - acc: 0.7332 - val_loss: 0.9701 - val_acc: 0.6855\n",
      "Epoch 390/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8368 - acc: 0.7335 - val_loss: 1.1064 - val_acc: 0.6622\n",
      "Epoch 391/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8317 - acc: 0.7387 - val_loss: 0.9428 - val_acc: 0.7022\n",
      "Epoch 392/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8361 - acc: 0.7356 - val_loss: 0.9737 - val_acc: 0.6839\n",
      "Epoch 393/1000\n",
      "5408/5408 [==============================] - 1s 258us/step - loss: 0.8433 - acc: 0.7324 - val_loss: 0.9022 - val_acc: 0.7088\n",
      "Epoch 394/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8297 - acc: 0.7371 - val_loss: 1.3386 - val_acc: 0.3577\n",
      "Epoch 395/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8558 - acc: 0.7241 - val_loss: 0.9805 - val_acc: 0.6839\n",
      "Epoch 396/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8334 - acc: 0.7356 - val_loss: 0.9421 - val_acc: 0.7038\n",
      "Epoch 397/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8313 - acc: 0.7393 - val_loss: 0.9188 - val_acc: 0.7138\n",
      "Epoch 398/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8373 - acc: 0.7328 - val_loss: 0.9150 - val_acc: 0.7205\n",
      "Epoch 399/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8274 - acc: 0.7350 - val_loss: 1.0962 - val_acc: 0.6789\n",
      "Epoch 400/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8519 - acc: 0.7276 - val_loss: 0.8849 - val_acc: 0.7171\n",
      "Epoch 401/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8313 - acc: 0.7374 - val_loss: 0.8902 - val_acc: 0.7238\n",
      "Epoch 402/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8330 - acc: 0.7367 - val_loss: 1.2300 - val_acc: 0.6722\n",
      "Epoch 403/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8318 - acc: 0.7352 - val_loss: 0.9296 - val_acc: 0.7255\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8380 - acc: 0.7400 - val_loss: 0.9416 - val_acc: 0.7022\n",
      "Epoch 405/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8347 - acc: 0.7335 - val_loss: 1.1686 - val_acc: 0.6639\n",
      "Epoch 406/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8529 - acc: 0.7308 - val_loss: 1.0776 - val_acc: 0.6473\n",
      "Epoch 407/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8406 - acc: 0.7330 - val_loss: 0.9311 - val_acc: 0.6938\n",
      "Epoch 408/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8342 - acc: 0.7363 - val_loss: 0.9444 - val_acc: 0.7038\n",
      "Epoch 409/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8449 - acc: 0.7322 - val_loss: 0.9599 - val_acc: 0.6889\n",
      "Epoch 410/1000\n",
      "5408/5408 [==============================] - 2s 295us/step - loss: 0.8331 - acc: 0.7369 - val_loss: 0.9994 - val_acc: 0.6789\n",
      "Epoch 411/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8401 - acc: 0.7321 - val_loss: 1.0176 - val_acc: 0.6739\n",
      "Epoch 412/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8291 - acc: 0.7365 - val_loss: 0.9894 - val_acc: 0.6955\n",
      "Epoch 413/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8519 - acc: 0.7267 - val_loss: 1.0829 - val_acc: 0.5923\n",
      "Epoch 414/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8402 - acc: 0.7345 - val_loss: 0.9204 - val_acc: 0.7055\n",
      "Epoch 415/1000\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.8334 - acc: 0.7354 - val_loss: 0.9156 - val_acc: 0.7072\n",
      "Epoch 416/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8381 - acc: 0.7298 - val_loss: 1.0780 - val_acc: 0.6689\n",
      "Epoch 417/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8406 - acc: 0.7321 - val_loss: 0.9920 - val_acc: 0.6822\n",
      "Epoch 418/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8306 - acc: 0.7385 - val_loss: 0.9850 - val_acc: 0.6855\n",
      "Epoch 419/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8449 - acc: 0.7347 - val_loss: 0.9569 - val_acc: 0.6955\n",
      "Epoch 420/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8343 - acc: 0.7354 - val_loss: 1.0060 - val_acc: 0.6473\n",
      "Epoch 421/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8500 - acc: 0.7354 - val_loss: 0.9515 - val_acc: 0.6955\n",
      "Epoch 422/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8387 - acc: 0.7345 - val_loss: 0.8958 - val_acc: 0.7171\n",
      "Epoch 423/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8352 - acc: 0.7371 - val_loss: 0.9183 - val_acc: 0.7205\n",
      "Epoch 424/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8360 - acc: 0.7319 - val_loss: 1.0252 - val_acc: 0.6556\n",
      "Epoch 425/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8423 - acc: 0.7315 - val_loss: 0.9642 - val_acc: 0.6755\n",
      "Epoch 426/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8338 - acc: 0.7391 - val_loss: 1.2156 - val_acc: 0.6572\n",
      "Epoch 427/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8704 - acc: 0.7226 - val_loss: 0.9521 - val_acc: 0.7105\n",
      "Epoch 428/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8368 - acc: 0.7358 - val_loss: 0.9829 - val_acc: 0.6855\n",
      "Epoch 429/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8413 - acc: 0.7359 - val_loss: 0.8955 - val_acc: 0.7354\n",
      "Epoch 430/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8242 - acc: 0.7443 - val_loss: 0.9374 - val_acc: 0.7038\n",
      "Epoch 431/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8365 - acc: 0.7371 - val_loss: 0.9322 - val_acc: 0.6922\n",
      "Epoch 432/1000\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 0.8269 - acc: 0.7372 - val_loss: 0.9262 - val_acc: 0.6905\n",
      "Epoch 433/1000\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.8368 - acc: 0.7365 - val_loss: 1.2464 - val_acc: 0.4759\n",
      "Epoch 434/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8538 - acc: 0.7276 - val_loss: 0.8847 - val_acc: 0.7205\n",
      "Epoch 435/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8339 - acc: 0.7347 - val_loss: 0.9413 - val_acc: 0.7005\n",
      "Epoch 436/1000\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.8231 - acc: 0.737 - 2s 292us/step - loss: 0.8281 - acc: 0.7350 - val_loss: 1.5575 - val_acc: 0.4975\n",
      "Epoch 437/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8694 - acc: 0.7223 - val_loss: 0.9736 - val_acc: 0.6988\n",
      "Epoch 438/1000\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 0.8327 - acc: 0.7361 - val_loss: 0.9939 - val_acc: 0.6905\n",
      "Epoch 439/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8316 - acc: 0.7391 - val_loss: 0.9663 - val_acc: 0.7105\n",
      "Epoch 440/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8366 - acc: 0.7371 - val_loss: 1.2141 - val_acc: 0.5674\n",
      "Epoch 441/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8424 - acc: 0.7332 - val_loss: 1.0021 - val_acc: 0.6739\n",
      "Epoch 442/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8357 - acc: 0.7337 - val_loss: 0.9654 - val_acc: 0.6822\n",
      "Epoch 443/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8339 - acc: 0.7378 - val_loss: 1.1118 - val_acc: 0.6273\n",
      "Epoch 444/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8385 - acc: 0.7408 - val_loss: 0.9316 - val_acc: 0.7055\n",
      "Epoch 445/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8349 - acc: 0.7348 - val_loss: 1.0026 - val_acc: 0.6839\n",
      "Epoch 446/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8313 - acc: 0.7385 - val_loss: 0.8817 - val_acc: 0.7238\n",
      "Epoch 447/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8314 - acc: 0.7389 - val_loss: 1.7537 - val_acc: 0.2363\n",
      "Epoch 448/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8867 - acc: 0.7200 - val_loss: 1.2331 - val_acc: 0.6656\n",
      "Epoch 449/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8483 - acc: 0.7326 - val_loss: 0.9795 - val_acc: 0.7038\n",
      "Epoch 450/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8334 - acc: 0.7402 - val_loss: 0.9568 - val_acc: 0.7038\n",
      "Epoch 451/1000\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 0.8312 - acc: 0.7365 - val_loss: 1.0658 - val_acc: 0.6689\n",
      "Epoch 452/1000\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 0.8391 - acc: 0.7356 - val_loss: 0.9326 - val_acc: 0.6955\n",
      "Epoch 453/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8311 - acc: 0.7396 - val_loss: 0.9679 - val_acc: 0.7038\n",
      "Epoch 454/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8321 - acc: 0.7380 - val_loss: 1.0580 - val_acc: 0.6456\n",
      "Epoch 455/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8416 - acc: 0.7358 - val_loss: 0.9481 - val_acc: 0.7205\n",
      "Epoch 456/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8349 - acc: 0.7363 - val_loss: 0.8915 - val_acc: 0.7271\n",
      "Epoch 457/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8320 - acc: 0.7396 - val_loss: 0.9025 - val_acc: 0.7255\n",
      "Epoch 458/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8283 - acc: 0.7376 - val_loss: 1.0237 - val_acc: 0.7055\n",
      "Epoch 459/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8341 - acc: 0.7389 - val_loss: 1.1336 - val_acc: 0.6672\n",
      "Epoch 460/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8461 - acc: 0.7369 - val_loss: 0.9076 - val_acc: 0.7121\n",
      "Epoch 461/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8256 - acc: 0.7450 - val_loss: 0.9849 - val_acc: 0.6722\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8482 - acc: 0.7380 - val_loss: 0.9703 - val_acc: 0.6905\n",
      "Epoch 463/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8262 - acc: 0.7409 - val_loss: 1.4797 - val_acc: 0.4992\n",
      "Epoch 464/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8687 - acc: 0.7228 - val_loss: 1.0270 - val_acc: 0.6223\n",
      "Epoch 465/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8427 - acc: 0.7347 - val_loss: 1.3968 - val_acc: 0.5458\n",
      "Epoch 466/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8646 - acc: 0.7271 - val_loss: 0.9819 - val_acc: 0.6872\n",
      "Epoch 467/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8301 - acc: 0.7409 - val_loss: 0.9531 - val_acc: 0.6922\n",
      "Epoch 468/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8366 - acc: 0.7376 - val_loss: 0.9096 - val_acc: 0.7138\n",
      "Epoch 469/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8340 - acc: 0.7396 - val_loss: 0.9084 - val_acc: 0.7038\n",
      "Epoch 470/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8246 - acc: 0.7432 - val_loss: 0.9551 - val_acc: 0.7055\n",
      "Epoch 471/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8332 - acc: 0.7367 - val_loss: 0.8962 - val_acc: 0.7205\n",
      "Epoch 472/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8233 - acc: 0.7456 - val_loss: 0.9401 - val_acc: 0.7055\n",
      "Epoch 473/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8283 - acc: 0.7400 - val_loss: 1.4516 - val_acc: 0.4875\n",
      "Epoch 474/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.9210 - acc: 0.7125 - val_loss: 0.9925 - val_acc: 0.6872\n",
      "Epoch 475/1000\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 0.8394 - acc: 0.7387 - val_loss: 0.9393 - val_acc: 0.7088\n",
      "Epoch 476/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8297 - acc: 0.7428 - val_loss: 0.9767 - val_acc: 0.6955\n",
      "Epoch 477/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8220 - acc: 0.7443 - val_loss: 1.0812 - val_acc: 0.6306\n",
      "Epoch 478/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8366 - acc: 0.7395 - val_loss: 0.9414 - val_acc: 0.7238\n",
      "Epoch 479/1000\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 0.8295 - acc: 0.7398 - val_loss: 0.9816 - val_acc: 0.7138\n",
      "Epoch 480/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8367 - acc: 0.7363 - val_loss: 0.9394 - val_acc: 0.7072\n",
      "Epoch 481/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8330 - acc: 0.7400 - val_loss: 0.9077 - val_acc: 0.7288\n",
      "Epoch 482/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8328 - acc: 0.7382 - val_loss: 0.9499 - val_acc: 0.6905\n",
      "Epoch 483/1000\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 0.8309 - acc: 0.7398 - val_loss: 0.9548 - val_acc: 0.7238\n",
      "Epoch 484/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8344 - acc: 0.7408 - val_loss: 1.0291 - val_acc: 0.6955\n",
      "Epoch 485/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8469 - acc: 0.7354 - val_loss: 0.8926 - val_acc: 0.7271\n",
      "Epoch 486/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8339 - acc: 0.7359 - val_loss: 1.1118 - val_acc: 0.5674: 0s - loss: 0.8332 - acc: 0.7\n",
      "Epoch 487/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8419 - acc: 0.7341 - val_loss: 0.9232 - val_acc: 0.6938\n",
      "Epoch 488/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8264 - acc: 0.7432 - val_loss: 1.0565 - val_acc: 0.6755\n",
      "Epoch 489/1000\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 0.8352 - acc: 0.7395 - val_loss: 1.0127 - val_acc: 0.6839\n",
      "Epoch 490/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8360 - acc: 0.7384 - val_loss: 1.0565 - val_acc: 0.6007\n",
      "Epoch 491/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8507 - acc: 0.7313 - val_loss: 1.0467 - val_acc: 0.6722\n",
      "Epoch 492/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8289 - acc: 0.7428 - val_loss: 1.1797 - val_acc: 0.6639\n",
      "Epoch 493/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8451 - acc: 0.7356 - val_loss: 1.0227 - val_acc: 0.6789\n",
      "Epoch 494/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8376 - acc: 0.7382 - val_loss: 1.1186 - val_acc: 0.6755\n",
      "Epoch 495/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8343 - acc: 0.7433 - val_loss: 0.9966 - val_acc: 0.6772\n",
      "Epoch 496/1000\n",
      "5408/5408 [==============================] - 2s 292us/step - loss: 0.8382 - acc: 0.7339 - val_loss: 0.9618 - val_acc: 0.7038\n",
      "Epoch 497/1000\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 0.8384 - acc: 0.7384 - val_loss: 0.9427 - val_acc: 0.7055\n",
      "Epoch 498/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8301 - acc: 0.7369 - val_loss: 1.2218 - val_acc: 0.6572\n",
      "Epoch 499/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8408 - acc: 0.7378 - val_loss: 0.9598 - val_acc: 0.7005\n",
      "Epoch 500/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8332 - acc: 0.7406 - val_loss: 0.9785 - val_acc: 0.6988\n",
      "Epoch 501/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8395 - acc: 0.7387 - val_loss: 0.9416 - val_acc: 0.7088\n",
      "Epoch 502/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8378 - acc: 0.7359 - val_loss: 0.9409 - val_acc: 0.7038\n",
      "Epoch 503/1000\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 0.8263 - acc: 0.7422 - val_loss: 1.6401 - val_acc: 0.4060\n",
      "Epoch 504/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.9050 - acc: 0.7184 - val_loss: 0.9235 - val_acc: 0.7038\n",
      "Epoch 505/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8322 - acc: 0.7396 - val_loss: 1.1550 - val_acc: 0.6389\n",
      "Epoch 506/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8397 - acc: 0.7361 - val_loss: 0.9483 - val_acc: 0.7138\n",
      "Epoch 507/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8470 - acc: 0.7350 - val_loss: 0.9246 - val_acc: 0.7138\n",
      "Epoch 508/1000\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.8309 - acc: 0.740 - 1s 275us/step - loss: 0.8303 - acc: 0.7406 - val_loss: 0.9428 - val_acc: 0.7055\n",
      "Epoch 509/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8327 - acc: 0.7400 - val_loss: 1.0377 - val_acc: 0.6805\n",
      "Epoch 510/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8275 - acc: 0.7395 - val_loss: 0.9569 - val_acc: 0.6988\n",
      "Epoch 511/1000\n",
      "5408/5408 [==============================] - 2s 299us/step - loss: 0.8417 - acc: 0.7343 - val_loss: 0.9850 - val_acc: 0.7155\n",
      "Epoch 512/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8337 - acc: 0.7408 - val_loss: 1.0396 - val_acc: 0.6656\n",
      "Epoch 513/1000\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.8341 - acc: 0.7389 - val_loss: 0.9920 - val_acc: 0.6805\n",
      "Epoch 514/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8287 - acc: 0.7422 - val_loss: 1.1214 - val_acc: 0.5707\n",
      "Epoch 515/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.9127 - acc: 0.7060 - val_loss: 1.1440 - val_acc: 0.6073\n",
      "Epoch 516/1000\n",
      "5408/5408 [==============================] - 2s 303us/step - loss: 0.8759 - acc: 0.7210 - val_loss: 1.2063 - val_acc: 0.6256\n",
      "Epoch 517/1000\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 0.8776 - acc: 0.7234 - val_loss: 0.9651 - val_acc: 0.6772\n",
      "Epoch 518/1000\n",
      "5408/5408 [==============================] - 2s 318us/step - loss: 0.8573 - acc: 0.7287 - val_loss: 0.9578 - val_acc: 0.7005\n",
      "Epoch 519/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8485 - acc: 0.7330 - val_loss: 0.9163 - val_acc: 0.7105\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8417 - acc: 0.7367 - val_loss: 0.9022 - val_acc: 0.7088\n",
      "Epoch 521/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8405 - acc: 0.7326 - val_loss: 0.9105 - val_acc: 0.7088\n",
      "Epoch 522/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8538 - acc: 0.7284 - val_loss: 1.0949 - val_acc: 0.6805\n",
      "Epoch 523/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8483 - acc: 0.7343 - val_loss: 0.9629 - val_acc: 0.6972\n",
      "Epoch 524/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8467 - acc: 0.7306 - val_loss: 0.9282 - val_acc: 0.7072\n",
      "Epoch 525/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8524 - acc: 0.7319 - val_loss: 1.0711 - val_acc: 0.6639\n",
      "Epoch 526/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8543 - acc: 0.7284 - val_loss: 0.9042 - val_acc: 0.7105\n",
      "Epoch 527/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8394 - acc: 0.7348 - val_loss: 1.0165 - val_acc: 0.6855\n",
      "Epoch 528/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8399 - acc: 0.7354 - val_loss: 0.8880 - val_acc: 0.7221\n",
      "Epoch 529/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8364 - acc: 0.7341 - val_loss: 1.0138 - val_acc: 0.6955\n",
      "Epoch 530/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8597 - acc: 0.7311 - val_loss: 1.0908 - val_acc: 0.5607\n",
      "Epoch 531/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8623 - acc: 0.7243 - val_loss: 1.0426 - val_acc: 0.6306\n",
      "Epoch 532/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8521 - acc: 0.7271 - val_loss: 1.0774 - val_acc: 0.6722\n",
      "Epoch 533/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8418 - acc: 0.7315 - val_loss: 0.9861 - val_acc: 0.7005\n",
      "Epoch 534/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8477 - acc: 0.7278 - val_loss: 0.9990 - val_acc: 0.6905\n",
      "Epoch 535/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8478 - acc: 0.7385 - val_loss: 0.9229 - val_acc: 0.7055\n",
      "Epoch 536/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8430 - acc: 0.7359 - val_loss: 0.9362 - val_acc: 0.7238\n",
      "Epoch 537/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8561 - acc: 0.7289 - val_loss: 1.2782 - val_acc: 0.5541: 0s - loss: 0.8540 - ac\n",
      "Epoch 538/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8596 - acc: 0.7258 - val_loss: 1.3292 - val_acc: 0.4676\n",
      "Epoch 539/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8478 - acc: 0.7265 - val_loss: 1.2631 - val_acc: 0.4443\n",
      "Epoch 540/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8587 - acc: 0.7249 - val_loss: 0.9554 - val_acc: 0.6988\n",
      "Epoch 541/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8355 - acc: 0.7347 - val_loss: 0.9335 - val_acc: 0.7121\n",
      "Epoch 542/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8450 - acc: 0.7330 - val_loss: 0.9935 - val_acc: 0.6922\n",
      "Epoch 543/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8425 - acc: 0.7324 - val_loss: 0.9731 - val_acc: 0.6955\n",
      "Epoch 544/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8455 - acc: 0.7378 - val_loss: 0.8894 - val_acc: 0.7205\n",
      "Epoch 545/1000\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 0.8386 - acc: 0.7345 - val_loss: 0.9472 - val_acc: 0.7005\n",
      "Epoch 546/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8382 - acc: 0.7326 - val_loss: 1.0041 - val_acc: 0.6606\n",
      "Epoch 547/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8466 - acc: 0.7319 - val_loss: 1.7816 - val_acc: 0.2546\n",
      "Epoch 548/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.9149 - acc: 0.7023 - val_loss: 1.0584 - val_acc: 0.6755\n",
      "Epoch 549/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8494 - acc: 0.7317 - val_loss: 0.9602 - val_acc: 0.7055\n",
      "Epoch 550/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8472 - acc: 0.7335 - val_loss: 0.9082 - val_acc: 0.7205\n",
      "Epoch 551/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8363 - acc: 0.7322 - val_loss: 1.0994 - val_acc: 0.6290\n",
      "Epoch 552/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8487 - acc: 0.7291 - val_loss: 0.9479 - val_acc: 0.6855\n",
      "Epoch 553/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8424 - acc: 0.7326 - val_loss: 0.8758 - val_acc: 0.7304\n",
      "Epoch 554/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8438 - acc: 0.7358 - val_loss: 0.9520 - val_acc: 0.71218411 - acc: 0.737 - ETA: 0s - loss: 0.8439 - acc: 0.735\n",
      "Epoch 555/1000\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.8370 - acc: 0.7369 - val_loss: 0.9473 - val_acc: 0.7022\n",
      "Epoch 556/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8410 - acc: 0.7345 - val_loss: 0.9312 - val_acc: 0.7255\n",
      "Epoch 557/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8350 - acc: 0.7378 - val_loss: 1.0933 - val_acc: 0.6572\n",
      "Epoch 558/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8536 - acc: 0.7287 - val_loss: 0.9902 - val_acc: 0.6922\n",
      "Epoch 559/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8614 - acc: 0.7317 - val_loss: 0.9349 - val_acc: 0.7155\n",
      "Epoch 560/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8378 - acc: 0.7345 - val_loss: 0.9260 - val_acc: 0.6988\n",
      "Epoch 561/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8392 - acc: 0.7345 - val_loss: 0.9937 - val_acc: 0.6855\n",
      "Epoch 562/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8429 - acc: 0.7341 - val_loss: 1.0036 - val_acc: 0.6805\n",
      "Epoch 563/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8380 - acc: 0.7384 - val_loss: 0.9990 - val_acc: 0.6639\n",
      "Epoch 564/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8356 - acc: 0.7354 - val_loss: 1.0458 - val_acc: 0.6739\n",
      "Epoch 565/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8399 - acc: 0.7378 - val_loss: 1.0563 - val_acc: 0.6805\n",
      "Epoch 566/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8418 - acc: 0.7337 - val_loss: 0.9700 - val_acc: 0.6972\n",
      "Epoch 567/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8418 - acc: 0.7398 - val_loss: 0.9552 - val_acc: 0.7072\n",
      "Epoch 568/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8423 - acc: 0.7358 - val_loss: 0.8974 - val_acc: 0.7171\n",
      "Epoch 569/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8351 - acc: 0.7400 - val_loss: 0.9011 - val_acc: 0.7255\n",
      "Epoch 570/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8371 - acc: 0.7376 - val_loss: 1.0149 - val_acc: 0.6589\n",
      "Epoch 571/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8464 - acc: 0.7359 - val_loss: 0.9511 - val_acc: 0.7238\n",
      "Epoch 572/1000\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 0.8339 - acc: 0.7385 - val_loss: 0.9294 - val_acc: 0.7105\n",
      "Epoch 573/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8367 - acc: 0.7358 - val_loss: 0.8955 - val_acc: 0.7321\n",
      "Epoch 574/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8327 - acc: 0.7380 - val_loss: 1.0379 - val_acc: 0.6423\n",
      "Epoch 575/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8415 - acc: 0.7343 - val_loss: 0.9216 - val_acc: 0.7221\n",
      "Epoch 576/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8349 - acc: 0.7311 - val_loss: 0.9830 - val_acc: 0.6789 0s - loss: 0.8336 - acc\n",
      "Epoch 577/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8390 - acc: 0.7404 - val_loss: 0.9403 - val_acc: 0.7121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8277 - acc: 0.7415 - val_loss: 0.9331 - val_acc: 0.7138\n",
      "Epoch 579/1000\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 0.8393 - acc: 0.7352 - val_loss: 1.0184 - val_acc: 0.6772\n",
      "Epoch 580/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8452 - acc: 0.7322 - val_loss: 0.9046 - val_acc: 0.7105\n",
      "Epoch 581/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8328 - acc: 0.7404 - val_loss: 0.9386 - val_acc: 0.6905\n",
      "Epoch 582/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8378 - acc: 0.7354 - val_loss: 0.9819 - val_acc: 0.6955\n",
      "Epoch 583/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8336 - acc: 0.7367 - val_loss: 0.9729 - val_acc: 0.6889\n",
      "Epoch 584/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8340 - acc: 0.7393 - val_loss: 1.0876 - val_acc: 0.6290\n",
      "Epoch 585/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8461 - acc: 0.7321 - val_loss: 0.9530 - val_acc: 0.7304\n",
      "Epoch 586/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8444 - acc: 0.7334 - val_loss: 0.9488 - val_acc: 0.7038\n",
      "Epoch 587/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8354 - acc: 0.7367 - val_loss: 1.0126 - val_acc: 0.6722\n",
      "Epoch 588/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8460 - acc: 0.7361 - val_loss: 1.0022 - val_acc: 0.6789\n",
      "Epoch 589/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8372 - acc: 0.7384 - val_loss: 0.8924 - val_acc: 0.7171\n",
      "Epoch 590/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8289 - acc: 0.7395 - val_loss: 0.9267 - val_acc: 0.7171\n",
      "Epoch 591/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8441 - acc: 0.7324 - val_loss: 1.0496 - val_acc: 0.6689\n",
      "Epoch 592/1000\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 0.8303 - acc: 0.7376 - val_loss: 1.0034 - val_acc: 0.6622 0s - loss: 0.82\n",
      "Epoch 593/1000\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 0.8503 - acc: 0.7352 - val_loss: 0.9207 - val_acc: 0.7121\n",
      "Epoch 594/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8370 - acc: 0.7361 - val_loss: 1.0346 - val_acc: 0.6522\n",
      "Epoch 595/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8371 - acc: 0.7378 - val_loss: 1.0750 - val_acc: 0.6456\n",
      "Epoch 596/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8467 - acc: 0.7385 - val_loss: 0.9365 - val_acc: 0.7005\n",
      "Epoch 597/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8297 - acc: 0.7406 - val_loss: 1.0871 - val_acc: 0.6755\n",
      "Epoch 598/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8376 - acc: 0.7376 - val_loss: 0.9466 - val_acc: 0.6955\n",
      "Epoch 599/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8363 - acc: 0.7385 - val_loss: 0.9176 - val_acc: 0.7171\n",
      "Epoch 600/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8316 - acc: 0.7347 - val_loss: 0.9052 - val_acc: 0.7171\n",
      "Epoch 601/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8327 - acc: 0.7347 - val_loss: 1.0748 - val_acc: 0.6522\n",
      "Epoch 602/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8464 - acc: 0.7367 - val_loss: 0.9038 - val_acc: 0.7121\n",
      "Epoch 603/1000\n",
      "5408/5408 [==============================] - 1s 264us/step - loss: 0.8325 - acc: 0.7361 - val_loss: 0.8854 - val_acc: 0.7255\n",
      "Epoch 604/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8250 - acc: 0.7389 - val_loss: 0.9721 - val_acc: 0.6705\n",
      "Epoch 605/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8406 - acc: 0.7354 - val_loss: 1.0805 - val_acc: 0.5691\n",
      "Epoch 606/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8375 - acc: 0.7402 - val_loss: 0.9220 - val_acc: 0.6972\n",
      "Epoch 607/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8401 - acc: 0.7393 - val_loss: 0.8985 - val_acc: 0.7171\n",
      "Epoch 608/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8230 - acc: 0.7420 - val_loss: 0.9597 - val_acc: 0.6889\n",
      "Epoch 609/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8257 - acc: 0.7406 - val_loss: 0.9649 - val_acc: 0.6988\n",
      "Epoch 610/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8251 - acc: 0.7422 - val_loss: 0.9648 - val_acc: 0.6789\n",
      "Epoch 611/1000\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.8305 - acc: 0.7411 - val_loss: 0.9753 - val_acc: 0.7022\n",
      "Epoch 612/1000\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.8245 - acc: 0.7428 - val_loss: 1.0359 - val_acc: 0.6206\n",
      "Epoch 613/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8401 - acc: 0.7284 - val_loss: 0.9033 - val_acc: 0.7238\n",
      "Epoch 614/1000\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 0.8307 - acc: 0.7371 - val_loss: 0.9906 - val_acc: 0.6839\n",
      "Epoch 615/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8393 - acc: 0.7374 - val_loss: 0.9752 - val_acc: 0.6805\n",
      "Epoch 616/1000\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.8402 - acc: 0.7313 - val_loss: 0.9345 - val_acc: 0.7121\n",
      "Epoch 617/1000\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 0.8275 - acc: 0.7409 - val_loss: 0.9879 - val_acc: 0.6839\n",
      "Epoch 618/1000\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 0.8279 - acc: 0.7432 - val_loss: 1.0910 - val_acc: 0.5657\n",
      "Epoch 619/1000\n",
      "5408/5408 [==============================] - 2s 290us/step - loss: 0.8374 - acc: 0.7335 - val_loss: 0.9984 - val_acc: 0.6689\n",
      "Epoch 620/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8314 - acc: 0.7406 - val_loss: 0.9406 - val_acc: 0.6972\n",
      "Epoch 621/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8195 - acc: 0.7456 - val_loss: 0.8915 - val_acc: 0.7371\n",
      "Epoch 622/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8374 - acc: 0.7417 - val_loss: 0.9165 - val_acc: 0.7022\n",
      "Epoch 623/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8268 - acc: 0.7419 - val_loss: 2.0774 - val_acc: 0.1997\n",
      "Epoch 624/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 1.0456 - acc: 0.6624 - val_loss: 1.0559 - val_acc: 0.6972\n",
      "Epoch 625/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8585 - acc: 0.7278 - val_loss: 1.3360 - val_acc: 0.4309\n",
      "Epoch 626/1000\n",
      "5408/5408 [==============================] - 2s 299us/step - loss: 0.8721 - acc: 0.7219 - val_loss: 1.0281 - val_acc: 0.6755\n",
      "Epoch 627/1000\n",
      "5408/5408 [==============================] - 2s 347us/step - loss: 0.8412 - acc: 0.7417 - val_loss: 1.0998 - val_acc: 0.6805\n",
      "Epoch 628/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8377 - acc: 0.7365 - val_loss: 1.1994 - val_acc: 0.6589\n",
      "Epoch 629/1000\n",
      "5408/5408 [==============================] - 2s 309us/step - loss: 0.8469 - acc: 0.7348 - val_loss: 0.9357 - val_acc: 0.7055\n",
      "Epoch 630/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8363 - acc: 0.7387 - val_loss: 0.9622 - val_acc: 0.6822\n",
      "Epoch 631/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8330 - acc: 0.7406 - val_loss: 1.0275 - val_acc: 0.7055\n",
      "Epoch 632/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8397 - acc: 0.7371 - val_loss: 0.9511 - val_acc: 0.7055\n",
      "Epoch 633/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8376 - acc: 0.7321 - val_loss: 1.0309 - val_acc: 0.6739\n",
      "Epoch 634/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8368 - acc: 0.7413 - val_loss: 0.9458 - val_acc: 0.7155\n",
      "Epoch 635/1000\n",
      "5408/5408 [==============================] - 2s 306us/step - loss: 0.8366 - acc: 0.7365 - val_loss: 1.0270 - val_acc: 0.6872\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8245 - acc: 0.7426 - val_loss: 1.0806 - val_acc: 0.6240\n",
      "Epoch 637/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8358 - acc: 0.7384 - val_loss: 0.9313 - val_acc: 0.7138\n",
      "Epoch 638/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8360 - acc: 0.7406 - val_loss: 1.0056 - val_acc: 0.6839\n",
      "Epoch 639/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8252 - acc: 0.7420 - val_loss: 0.9826 - val_acc: 0.6739\n",
      "Epoch 640/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8335 - acc: 0.7398 - val_loss: 0.9295 - val_acc: 0.7055\n",
      "Epoch 641/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8232 - acc: 0.7411 - val_loss: 1.1298 - val_acc: 0.6639\n",
      "Epoch 642/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8307 - acc: 0.7382 - val_loss: 0.9059 - val_acc: 0.7205\n",
      "Epoch 643/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8379 - acc: 0.7372 - val_loss: 1.3321 - val_acc: 0.5591\n",
      "Epoch 644/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8579 - acc: 0.7293 - val_loss: 0.9374 - val_acc: 0.7105\n",
      "Epoch 645/1000\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.8329 - acc: 0.742 - 1s 235us/step - loss: 0.8313 - acc: 0.7430 - val_loss: 1.1264 - val_acc: 0.5607\n",
      "Epoch 646/1000\n",
      "5408/5408 [==============================] - 2s 302us/step - loss: 0.8328 - acc: 0.7385 - val_loss: 0.8808 - val_acc: 0.7205\n",
      "Epoch 647/1000\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 0.8262 - acc: 0.7389 - val_loss: 0.8826 - val_acc: 0.7255\n",
      "Epoch 648/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8194 - acc: 0.7433 - val_loss: 0.9016 - val_acc: 0.7105\n",
      "Epoch 649/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8283 - acc: 0.7424 - val_loss: 0.9080 - val_acc: 0.7288\n",
      "Epoch 650/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8228 - acc: 0.7420 - val_loss: 1.0588 - val_acc: 0.6473\n",
      "Epoch 651/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8383 - acc: 0.7415 - val_loss: 0.9837 - val_acc: 0.6855\n",
      "Epoch 652/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8345 - acc: 0.7354 - val_loss: 1.3316 - val_acc: 0.5740\n",
      "Epoch 653/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8395 - acc: 0.7350 - val_loss: 0.9699 - val_acc: 0.7022\n",
      "Epoch 654/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8364 - acc: 0.7382 - val_loss: 1.1897 - val_acc: 0.6589\n",
      "Epoch 655/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.8377 - acc: 0.7406 - val_loss: 0.9947 - val_acc: 0.6705\n",
      "Epoch 656/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8236 - acc: 0.7459 - val_loss: 0.9360 - val_acc: 0.6955\n",
      "Epoch 657/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8353 - acc: 0.7419 - val_loss: 1.5004 - val_acc: 0.5092\n",
      "Epoch 658/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.8659 - acc: 0.7263 - val_loss: 0.9358 - val_acc: 0.7105\n",
      "Epoch 659/1000\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 0.8187 - acc: 0.7504 - val_loss: 1.4627 - val_acc: 0.3295\n",
      "Epoch 660/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.9091 - acc: 0.7093 - val_loss: 0.9344 - val_acc: 0.7238\n",
      "Epoch 661/1000\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.8248 - acc: 0.7457 - val_loss: 0.9972 - val_acc: 0.6755\n",
      "Epoch 662/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8322 - acc: 0.7391 - val_loss: 0.9724 - val_acc: 0.6905\n",
      "Epoch 663/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8317 - acc: 0.7428 - val_loss: 0.9561 - val_acc: 0.7072\n",
      "Epoch 664/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8336 - acc: 0.7382 - val_loss: 0.9182 - val_acc: 0.7221\n",
      "Epoch 665/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8294 - acc: 0.7439 - val_loss: 0.9749 - val_acc: 0.6972\n",
      "Epoch 666/1000\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 0.8320 - acc: 0.7428 - val_loss: 0.9938 - val_acc: 0.6722\n",
      "Epoch 667/1000\n",
      "5408/5408 [==============================] - 1s 227us/step - loss: 0.8379 - acc: 0.7393 - val_loss: 0.9413 - val_acc: 0.7121\n",
      "Epoch 668/1000\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.8256 - acc: 0.7474 - val_loss: 0.9578 - val_acc: 0.6872\n",
      "Epoch 669/1000\n",
      "5408/5408 [==============================] - 1s 230us/step - loss: 0.8168 - acc: 0.7482 - val_loss: 0.9269 - val_acc: 0.7188\n",
      "Epoch 670/1000\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.8290 - acc: 0.7426 - val_loss: 0.9179 - val_acc: 0.7055\n",
      "Epoch 671/1000\n",
      "5408/5408 [==============================] - 1s 229us/step - loss: 0.8168 - acc: 0.7439 - val_loss: 0.9435 - val_acc: 0.7221\n",
      "Epoch 672/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8319 - acc: 0.7406 - val_loss: 1.0557 - val_acc: 0.5957\n",
      "Epoch 673/1000\n",
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8368 - acc: 0.7409 - val_loss: 1.1797 - val_acc: 0.6656\n",
      "Epoch 674/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8439 - acc: 0.7396 - val_loss: 0.9320 - val_acc: 0.7055\n",
      "Epoch 675/1000\n",
      "5408/5408 [==============================] - 2s 313us/step - loss: 0.8196 - acc: 0.7472 - val_loss: 1.0764 - val_acc: 0.6822\n",
      "Epoch 676/1000\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.8367 - acc: 0.7398 - val_loss: 1.0559 - val_acc: 0.6057\n",
      "Epoch 677/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8339 - acc: 0.7408 - val_loss: 0.9761 - val_acc: 0.6855\n",
      "Epoch 678/1000\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.8282 - acc: 0.7457 - val_loss: 1.0632 - val_acc: 0.6988\n",
      "Epoch 679/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8253 - acc: 0.7426 - val_loss: 1.0774 - val_acc: 0.6755\n",
      "Epoch 680/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8298 - acc: 0.7445 - val_loss: 0.9270 - val_acc: 0.7255\n",
      "Epoch 681/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8265 - acc: 0.7398 - val_loss: 0.9141 - val_acc: 0.7088\n",
      "Epoch 682/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8208 - acc: 0.7472 - val_loss: 0.9992 - val_acc: 0.6705\n",
      "Epoch 683/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8284 - acc: 0.7393 - val_loss: 1.0318 - val_acc: 0.6323\n",
      "Epoch 684/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8327 - acc: 0.7426 - val_loss: 0.9891 - val_acc: 0.6589\n",
      "Epoch 685/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8243 - acc: 0.7467 - val_loss: 1.9505 - val_acc: 0.1930\n",
      "Epoch 686/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.9422 - acc: 0.6999 - val_loss: 0.9311 - val_acc: 0.7138\n",
      "Epoch 687/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8297 - acc: 0.7435 - val_loss: 1.1013 - val_acc: 0.6090\n",
      "Epoch 688/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8323 - acc: 0.7437 - val_loss: 0.9398 - val_acc: 0.6955\n",
      "Epoch 689/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8347 - acc: 0.7426 - val_loss: 1.0240 - val_acc: 0.6839\n",
      "Epoch 690/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8353 - acc: 0.7408 - val_loss: 1.0989 - val_acc: 0.6606\n",
      "Epoch 691/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8563 - acc: 0.7393 - val_loss: 1.1319 - val_acc: 0.5840\n",
      "Epoch 692/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8637 - acc: 0.7293 - val_loss: 0.9093 - val_acc: 0.7105\n",
      "Epoch 693/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8435 - acc: 0.7393 - val_loss: 0.9057 - val_acc: 0.7171\n",
      "Epoch 694/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8314 - acc: 0.7430 - val_loss: 1.3011 - val_acc: 0.5607\n",
      "Epoch 695/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8529 - acc: 0.7311 - val_loss: 0.9378 - val_acc: 0.7105\n",
      "Epoch 696/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8339 - acc: 0.7395 - val_loss: 0.9421 - val_acc: 0.7121\n",
      "Epoch 697/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8315 - acc: 0.7387 - val_loss: 1.0791 - val_acc: 0.6156\n",
      "Epoch 698/1000\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.8476 - acc: 0.7295 - val_loss: 1.1721 - val_acc: 0.6839\n",
      "Epoch 699/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8494 - acc: 0.7358 - val_loss: 0.9828 - val_acc: 0.6889\n",
      "Epoch 700/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8473 - acc: 0.7382 - val_loss: 1.1298 - val_acc: 0.5840\n",
      "Epoch 701/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8475 - acc: 0.7334 - val_loss: 0.9577 - val_acc: 0.7155\n",
      "Epoch 702/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8422 - acc: 0.7367 - val_loss: 0.9175 - val_acc: 0.7155\n",
      "Epoch 703/1000\n",
      "5408/5408 [==============================] - 1s 238us/step - loss: 0.8334 - acc: 0.7389 - val_loss: 0.9293 - val_acc: 0.7055\n",
      "Epoch 704/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8355 - acc: 0.7417 - val_loss: 0.9532 - val_acc: 0.6972\n",
      "Epoch 705/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8359 - acc: 0.7406 - val_loss: 0.9590 - val_acc: 0.6972\n",
      "Epoch 706/1000\n",
      "5408/5408 [==============================] - 1s 277us/step - loss: 0.8350 - acc: 0.7387 - val_loss: 1.0275 - val_acc: 0.6855\n",
      "Epoch 707/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8391 - acc: 0.7393 - val_loss: 1.0268 - val_acc: 0.6938\n",
      "Epoch 708/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8377 - acc: 0.7371 - val_loss: 0.9314 - val_acc: 0.6905 - loss: 0.8630 - acc: 0 - ETA: 0s - loss: 0.8340 - acc:\n",
      "Epoch 709/1000\n",
      "5408/5408 [==============================] - 1s 259us/step - loss: 0.8435 - acc: 0.7382 - val_loss: 1.1443 - val_acc: 0.6606\n",
      "Epoch 710/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8350 - acc: 0.7409 - val_loss: 0.9892 - val_acc: 0.6972\n",
      "Epoch 711/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8237 - acc: 0.7446 - val_loss: 1.0701 - val_acc: 0.6922\n",
      "Epoch 712/1000\n",
      "5408/5408 [==============================] - 2s 293us/step - loss: 0.8369 - acc: 0.7378 - val_loss: 0.9689 - val_acc: 0.7055\n",
      "Epoch 713/1000\n",
      "5408/5408 [==============================] - 2s 344us/step - loss: 0.8267 - acc: 0.7445 - val_loss: 0.9833 - val_acc: 0.6938\n",
      "Epoch 714/1000\n",
      "5408/5408 [==============================] - 2s 380us/step - loss: 0.8341 - acc: 0.7369 - val_loss: 0.8991 - val_acc: 0.7421\n",
      "Epoch 715/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8265 - acc: 0.7443 - val_loss: 0.8984 - val_acc: 0.7171\n",
      "Epoch 716/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8179 - acc: 0.7483 - val_loss: 1.2338 - val_acc: 0.6539\n",
      "Epoch 717/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8507 - acc: 0.7374 - val_loss: 0.9900 - val_acc: 0.6905\n",
      "Epoch 718/1000\n",
      "5408/5408 [==============================] - 2s 320us/step - loss: 0.8376 - acc: 0.7391 - val_loss: 1.8880 - val_acc: 0.3278\n",
      "Epoch 719/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8755 - acc: 0.7224 - val_loss: 1.1529 - val_acc: 0.5358\n",
      "Epoch 720/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8473 - acc: 0.7334 - val_loss: 0.9864 - val_acc: 0.6889\n",
      "Epoch 721/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8259 - acc: 0.7395 - val_loss: 0.9822 - val_acc: 0.6922\n",
      "Epoch 722/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8351 - acc: 0.7378 - val_loss: 0.9532 - val_acc: 0.7105\n",
      "Epoch 723/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8286 - acc: 0.7446 - val_loss: 1.3547 - val_acc: 0.5141\n",
      "Epoch 724/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8474 - acc: 0.7409 - val_loss: 1.0648 - val_acc: 0.6023\n",
      "Epoch 725/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8443 - acc: 0.7339 - val_loss: 0.9970 - val_acc: 0.6905\n",
      "Epoch 726/1000\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.8326 - acc: 0.7411 - val_loss: 1.0029 - val_acc: 0.7072\n",
      "Epoch 727/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8307 - acc: 0.7413 - val_loss: 1.1513 - val_acc: 0.6606\n",
      "Epoch 728/1000\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.8395 - acc: 0.7382 - val_loss: 0.9121 - val_acc: 0.7138\n",
      "Epoch 729/1000\n",
      "5408/5408 [==============================] - 1s 232us/step - loss: 0.8280 - acc: 0.7432 - val_loss: 0.9683 - val_acc: 0.6839\n",
      "Epoch 730/1000\n",
      "5408/5408 [==============================] - 1s 231us/step - loss: 0.8303 - acc: 0.7441 - val_loss: 0.9141 - val_acc: 0.7188\n",
      "Epoch 731/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8286 - acc: 0.7426 - val_loss: 1.0744 - val_acc: 0.6606\n",
      "Epoch 732/1000\n",
      "5408/5408 [==============================] - 1s 234us/step - loss: 0.8325 - acc: 0.7419 - val_loss: 0.9420 - val_acc: 0.7055\n",
      "Epoch 733/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8271 - acc: 0.7441 - val_loss: 1.0526 - val_acc: 0.6972\n",
      "Epoch 734/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8326 - acc: 0.7417 - val_loss: 1.0897 - val_acc: 0.6822\n",
      "Epoch 735/1000\n",
      "5408/5408 [==============================] - 1s 228us/step - loss: 0.8295 - acc: 0.7435 - val_loss: 1.0070 - val_acc: 0.6306\n",
      "Epoch 736/1000\n",
      "5408/5408 [==============================] - 1s 235us/step - loss: 0.8320 - acc: 0.7400 - val_loss: 0.9425 - val_acc: 0.7088\n",
      "Epoch 737/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8246 - acc: 0.7428 - val_loss: 1.1119 - val_acc: 0.6606\n",
      "Epoch 738/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8341 - acc: 0.7378 - val_loss: 1.2245 - val_acc: 0.5774\n",
      "Epoch 739/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8501 - acc: 0.7352 - val_loss: 0.9626 - val_acc: 0.7105\n",
      "Epoch 740/1000\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 0.8256 - acc: 0.7454 - val_loss: 0.9226 - val_acc: 0.7238\n",
      "Epoch 741/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8273 - acc: 0.7406 - val_loss: 0.9557 - val_acc: 0.6988\n",
      "Epoch 742/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8387 - acc: 0.7409 - val_loss: 1.0400 - val_acc: 0.6972\n",
      "Epoch 743/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8352 - acc: 0.7432 - val_loss: 0.9142 - val_acc: 0.7155\n",
      "Epoch 744/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8333 - acc: 0.7422 - val_loss: 0.8985 - val_acc: 0.7404\n",
      "Epoch 745/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8241 - acc: 0.7472 - val_loss: 1.3935 - val_acc: 0.4459\n",
      "Epoch 746/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8435 - acc: 0.7391 - val_loss: 0.9508 - val_acc: 0.7072\n",
      "Epoch 747/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8279 - acc: 0.7428 - val_loss: 1.1076 - val_acc: 0.5857\n",
      "Epoch 748/1000\n",
      "5408/5408 [==============================] - 1s 275us/step - loss: 0.8493 - acc: 0.7313 - val_loss: 0.9210 - val_acc: 0.7138\n",
      "Epoch 749/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8226 - acc: 0.7469 - val_loss: 0.9358 - val_acc: 0.7138\n",
      "Epoch 750/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8260 - acc: 0.7413 - val_loss: 0.8962 - val_acc: 0.7321\n",
      "Epoch 751/1000\n",
      "5408/5408 [==============================] - 1s 276us/step - loss: 0.8201 - acc: 0.7445 - val_loss: 1.1161 - val_acc: 0.6805\n",
      "Epoch 752/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8301 - acc: 0.7428 - val_loss: 2.2236 - val_acc: 0.1614\n",
      "Epoch 753/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.9017 - acc: 0.7139 - val_loss: 0.9647 - val_acc: 0.7121\n",
      "Epoch 754/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8466 - acc: 0.7330 - val_loss: 0.9548 - val_acc: 0.6988\n",
      "Epoch 755/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8346 - acc: 0.7430 - val_loss: 0.9586 - val_acc: 0.7171\n",
      "Epoch 756/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8282 - acc: 0.7432 - val_loss: 0.9771 - val_acc: 0.6922\n",
      "Epoch 757/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8295 - acc: 0.7433 - val_loss: 0.9879 - val_acc: 0.7055\n",
      "Epoch 758/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8339 - acc: 0.7395 - val_loss: 0.9062 - val_acc: 0.7255\n",
      "Epoch 759/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8310 - acc: 0.7430 - val_loss: 0.9859 - val_acc: 0.6972\n",
      "Epoch 760/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8301 - acc: 0.7469 - val_loss: 0.9568 - val_acc: 0.7088\n",
      "Epoch 761/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8292 - acc: 0.7448 - val_loss: 0.9181 - val_acc: 0.7072\n",
      "Epoch 762/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8312 - acc: 0.7406 - val_loss: 0.9283 - val_acc: 0.7005\n",
      "Epoch 763/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8348 - acc: 0.7432 - val_loss: 1.1323 - val_acc: 0.6306\n",
      "Epoch 764/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8407 - acc: 0.7382 - val_loss: 1.0484 - val_acc: 0.6739\n",
      "Epoch 765/1000\n",
      "5408/5408 [==============================] - 1s 249us/step - loss: 0.8429 - acc: 0.7367 - val_loss: 1.0054 - val_acc: 0.7022\n",
      "Epoch 766/1000\n",
      "5408/5408 [==============================] - ETA: 0s - loss: 0.8254 - acc: 0.745 - 1s 248us/step - loss: 0.8245 - acc: 0.7461 - val_loss: 0.9988 - val_acc: 0.7005\n",
      "Epoch 767/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8352 - acc: 0.7408 - val_loss: 0.8998 - val_acc: 0.7255\n",
      "Epoch 768/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8327 - acc: 0.7420 - val_loss: 0.9391 - val_acc: 0.7072\n",
      "Epoch 769/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8254 - acc: 0.7433 - val_loss: 1.2474 - val_acc: 0.6572\n",
      "Epoch 770/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8788 - acc: 0.7280 - val_loss: 1.0192 - val_acc: 0.6539\n",
      "Epoch 771/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8286 - acc: 0.7448 - val_loss: 0.9830 - val_acc: 0.6922\n",
      "Epoch 772/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8237 - acc: 0.7482 - val_loss: 1.0893 - val_acc: 0.6739\n",
      "Epoch 773/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8359 - acc: 0.7457 - val_loss: 0.9331 - val_acc: 0.6905\n",
      "Epoch 774/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8272 - acc: 0.7459 - val_loss: 0.9433 - val_acc: 0.7221\n",
      "Epoch 775/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8290 - acc: 0.7459 - val_loss: 1.1209 - val_acc: 0.6622s - loss: 0.8322 - acc: 0.7\n",
      "Epoch 776/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8338 - acc: 0.7404 - val_loss: 1.0138 - val_acc: 0.6922\n",
      "Epoch 777/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8291 - acc: 0.7419 - val_loss: 1.0421 - val_acc: 0.7088\n",
      "Epoch 778/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8406 - acc: 0.7441 - val_loss: 0.9722 - val_acc: 0.7072\n",
      "Epoch 779/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8200 - acc: 0.7470 - val_loss: 1.0088 - val_acc: 0.6972\n",
      "Epoch 780/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8346 - acc: 0.7426 - val_loss: 1.1431 - val_acc: 0.5840\n",
      "Epoch 781/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8346 - acc: 0.7387 - val_loss: 0.9282 - val_acc: 0.7155\n",
      "Epoch 782/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8271 - acc: 0.7411 - val_loss: 0.9553 - val_acc: 0.7155\n",
      "Epoch 783/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8307 - acc: 0.7422 - val_loss: 1.0136 - val_acc: 0.6955\n",
      "Epoch 784/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8323 - acc: 0.7441 - val_loss: 1.1289 - val_acc: 0.6656\n",
      "Epoch 785/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8365 - acc: 0.7428 - val_loss: 1.0228 - val_acc: 0.6306\n",
      "Epoch 786/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8269 - acc: 0.7443 - val_loss: 0.9252 - val_acc: 0.7155\n",
      "Epoch 787/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8233 - acc: 0.7469 - val_loss: 0.9798 - val_acc: 0.6639\n",
      "Epoch 788/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8249 - acc: 0.7433 - val_loss: 0.9639 - val_acc: 0.7005\n",
      "Epoch 789/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8319 - acc: 0.7470 - val_loss: 1.0029 - val_acc: 0.6938\n",
      "Epoch 790/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8308 - acc: 0.7454 - val_loss: 0.9643 - val_acc: 0.6955\n",
      "Epoch 791/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8324 - acc: 0.7389 - val_loss: 1.0559 - val_acc: 0.7022\n",
      "Epoch 792/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8398 - acc: 0.7409 - val_loss: 1.0881 - val_acc: 0.6656\n",
      "Epoch 793/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8407 - acc: 0.7435 - val_loss: 1.0792 - val_acc: 0.6755\n",
      "Epoch 794/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8290 - acc: 0.7408 - val_loss: 0.9498 - val_acc: 0.7205\n",
      "Epoch 795/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8221 - acc: 0.7467 - val_loss: 0.9363 - val_acc: 0.7138\n",
      "Epoch 796/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8292 - acc: 0.7480 - val_loss: 0.9261 - val_acc: 0.7338\n",
      "Epoch 797/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8254 - acc: 0.7485 - val_loss: 0.9060 - val_acc: 0.7255\n",
      "Epoch 798/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8289 - acc: 0.7408 - val_loss: 0.9639 - val_acc: 0.6789\n",
      "Epoch 799/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8273 - acc: 0.7417 - val_loss: 1.2008 - val_acc: 0.5824\n",
      "Epoch 800/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8496 - acc: 0.7378 - val_loss: 0.9272 - val_acc: 0.7155\n",
      "Epoch 801/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8255 - acc: 0.7459 - val_loss: 0.9094 - val_acc: 0.7205\n",
      "Epoch 802/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8271 - acc: 0.7408 - val_loss: 0.9277 - val_acc: 0.7188\n",
      "Epoch 803/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8289 - acc: 0.7461 - val_loss: 1.0278 - val_acc: 0.6855\n",
      "Epoch 804/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8264 - acc: 0.7480 - val_loss: 1.1728 - val_acc: 0.5923\n",
      "Epoch 805/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8361 - acc: 0.7409 - val_loss: 0.9426 - val_acc: 0.7005\n",
      "Epoch 806/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8228 - acc: 0.7437 - val_loss: 0.9842 - val_acc: 0.6905\n",
      "Epoch 807/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8321 - acc: 0.7465 - val_loss: 1.0173 - val_acc: 0.7022\n",
      "Epoch 808/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8244 - acc: 0.7469 - val_loss: 0.9693 - val_acc: 0.6705\n",
      "Epoch 809/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8420 - acc: 0.7408 - val_loss: 1.0192 - val_acc: 0.6938\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8314 - acc: 0.7424 - val_loss: 0.9482 - val_acc: 0.7105\n",
      "Epoch 811/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8287 - acc: 0.7443 - val_loss: 1.0043 - val_acc: 0.6922\n",
      "Epoch 812/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8360 - acc: 0.7413 - val_loss: 0.9308 - val_acc: 0.7155\n",
      "Epoch 813/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8240 - acc: 0.7445 - val_loss: 0.9903 - val_acc: 0.7155\n",
      "Epoch 814/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8307 - acc: 0.7426 - val_loss: 1.0174 - val_acc: 0.6822\n",
      "Epoch 815/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8268 - acc: 0.7474 - val_loss: 0.9515 - val_acc: 0.7005\n",
      "Epoch 816/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8329 - acc: 0.7435 - val_loss: 1.0196 - val_acc: 0.7005\n",
      "Epoch 817/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8233 - acc: 0.7457 - val_loss: 1.2836 - val_acc: 0.5923\n",
      "Epoch 818/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8389 - acc: 0.7385 - val_loss: 0.9140 - val_acc: 0.7288\n",
      "Epoch 819/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8275 - acc: 0.7456 - val_loss: 0.9498 - val_acc: 0.6955\n",
      "Epoch 820/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8285 - acc: 0.7470 - val_loss: 0.9096 - val_acc: 0.7171\n",
      "Epoch 821/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8250 - acc: 0.7430 - val_loss: 1.1598 - val_acc: 0.6456\n",
      "Epoch 822/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8304 - acc: 0.7415 - val_loss: 0.9265 - val_acc: 0.7055\n",
      "Epoch 823/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8272 - acc: 0.7456 - val_loss: 1.0237 - val_acc: 0.6755\n",
      "Epoch 824/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8187 - acc: 0.7470 - val_loss: 0.9349 - val_acc: 0.6972\n",
      "Epoch 825/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8260 - acc: 0.7469 - val_loss: 0.9680 - val_acc: 0.7005\n",
      "Epoch 826/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8318 - acc: 0.7454 - val_loss: 1.1921 - val_acc: 0.5241\n",
      "Epoch 827/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8267 - acc: 0.7424 - val_loss: 1.0134 - val_acc: 0.6805\n",
      "Epoch 828/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8249 - acc: 0.7441 - val_loss: 1.1775 - val_acc: 0.6606\n",
      "Epoch 829/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8393 - acc: 0.7389 - val_loss: 0.9470 - val_acc: 0.6889\n",
      "Epoch 830/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8216 - acc: 0.7459 - val_loss: 1.0411 - val_acc: 0.6805\n",
      "Epoch 831/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8328 - acc: 0.7439 - val_loss: 1.0590 - val_acc: 0.6839\n",
      "Epoch 832/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8462 - acc: 0.7376 - val_loss: 0.9987 - val_acc: 0.6789\n",
      "Epoch 833/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8318 - acc: 0.7469 - val_loss: 0.9452 - val_acc: 0.7205\n",
      "Epoch 834/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8235 - acc: 0.7498 - val_loss: 1.0629 - val_acc: 0.6822\n",
      "Epoch 835/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8297 - acc: 0.7424 - val_loss: 0.9409 - val_acc: 0.7121\n",
      "Epoch 836/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8324 - acc: 0.7443 - val_loss: 0.9157 - val_acc: 0.7221\n",
      "Epoch 837/1000\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 0.8302 - acc: 0.7467 - val_loss: 1.0199 - val_acc: 0.6889\n",
      "Epoch 838/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8181 - acc: 0.7457 - val_loss: 0.9492 - val_acc: 0.7055\n",
      "Epoch 839/1000\n",
      "5408/5408 [==============================] - 1s 246us/step - loss: 0.8240 - acc: 0.7487 - val_loss: 0.9516 - val_acc: 0.7121\n",
      "Epoch 840/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8343 - acc: 0.7446 - val_loss: 0.9343 - val_acc: 0.7138\n",
      "Epoch 841/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8408 - acc: 0.7424 - val_loss: 0.9706 - val_acc: 0.7105\n",
      "Epoch 842/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8294 - acc: 0.7469 - val_loss: 0.9672 - val_acc: 0.6855\n",
      "Epoch 843/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8374 - acc: 0.7389 - val_loss: 1.0388 - val_acc: 0.6705\n",
      "Epoch 844/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8270 - acc: 0.7459 - val_loss: 1.0034 - val_acc: 0.7155\n",
      "Epoch 845/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8242 - acc: 0.7474 - val_loss: 0.9623 - val_acc: 0.7088\n",
      "Epoch 846/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8282 - acc: 0.7459 - val_loss: 1.0167 - val_acc: 0.6522\n",
      "Epoch 847/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8244 - acc: 0.7454 - val_loss: 1.1545 - val_acc: 0.6273\n",
      "Epoch 848/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8377 - acc: 0.7430 - val_loss: 1.2643 - val_acc: 0.5890\n",
      "Epoch 849/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8670 - acc: 0.7332 - val_loss: 0.9750 - val_acc: 0.7121\n",
      "Epoch 850/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8252 - acc: 0.7502 - val_loss: 1.0609 - val_acc: 0.6256\n",
      "Epoch 851/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8330 - acc: 0.7413 - val_loss: 0.9890 - val_acc: 0.6622\n",
      "Epoch 852/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8310 - acc: 0.7424 - val_loss: 1.0466 - val_acc: 0.6772\n",
      "Epoch 853/1000\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.8310 - acc: 0.7448 - val_loss: 0.9057 - val_acc: 0.7205\n",
      "Epoch 854/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8180 - acc: 0.7507 - val_loss: 0.9894 - val_acc: 0.6988\n",
      "Epoch 855/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8254 - acc: 0.7467 - val_loss: 0.9207 - val_acc: 0.7155\n",
      "Epoch 856/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8339 - acc: 0.7422 - val_loss: 1.1140 - val_acc: 0.6722\n",
      "Epoch 857/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8360 - acc: 0.7387 - val_loss: 0.9526 - val_acc: 0.7188\n",
      "Epoch 858/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8300 - acc: 0.7485 - val_loss: 0.9655 - val_acc: 0.7072\n",
      "Epoch 859/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8198 - acc: 0.7487 - val_loss: 0.9202 - val_acc: 0.7038\n",
      "Epoch 860/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8209 - acc: 0.7463 - val_loss: 0.9563 - val_acc: 0.6955\n",
      "Epoch 861/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8276 - acc: 0.7476 - val_loss: 1.0075 - val_acc: 0.7238\n",
      "Epoch 862/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8419 - acc: 0.7428 - val_loss: 1.3727 - val_acc: 0.5674\n",
      "Epoch 863/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8481 - acc: 0.7358 - val_loss: 1.0588 - val_acc: 0.6755\n",
      "Epoch 864/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8221 - acc: 0.7472 - val_loss: 1.1075 - val_acc: 0.6589\n",
      "Epoch 865/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8581 - acc: 0.7361 - val_loss: 1.0708 - val_acc: 0.6839\n",
      "Epoch 866/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8353 - acc: 0.7422 - val_loss: 0.9501 - val_acc: 0.7055\n",
      "Epoch 867/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8248 - acc: 0.7446 - val_loss: 0.9967 - val_acc: 0.6822\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - ETA: 0s - loss: 0.8434 - acc: 0.740 - 1s 245us/step - loss: 0.8411 - acc: 0.7415 - val_loss: 1.1011 - val_acc: 0.5874\n",
      "Epoch 869/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8242 - acc: 0.7465 - val_loss: 1.2120 - val_acc: 0.6306\n",
      "Epoch 870/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8414 - acc: 0.7384 - val_loss: 0.9377 - val_acc: 0.7155\n",
      "Epoch 871/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8245 - acc: 0.7452 - val_loss: 1.0890 - val_acc: 0.6672\n",
      "Epoch 872/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8239 - acc: 0.7478 - val_loss: 0.9253 - val_acc: 0.7171\n",
      "Epoch 873/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8237 - acc: 0.7480 - val_loss: 0.9781 - val_acc: 0.6955\n",
      "Epoch 874/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8268 - acc: 0.7489 - val_loss: 1.1490 - val_acc: 0.6672\n",
      "Epoch 875/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8397 - acc: 0.7395 - val_loss: 1.1485 - val_acc: 0.5707\n",
      "Epoch 876/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8355 - acc: 0.7422 - val_loss: 0.9542 - val_acc: 0.6972\n",
      "Epoch 877/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8173 - acc: 0.7507 - val_loss: 0.9789 - val_acc: 0.6556\n",
      "Epoch 878/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8311 - acc: 0.7435 - val_loss: 0.9118 - val_acc: 0.7238\n",
      "Epoch 879/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8275 - acc: 0.7457 - val_loss: 1.0162 - val_acc: 0.6772\n",
      "Epoch 880/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8309 - acc: 0.7437 - val_loss: 0.9673 - val_acc: 0.6889\n",
      "Epoch 881/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8215 - acc: 0.7487 - val_loss: 0.9689 - val_acc: 0.6889\n",
      "Epoch 882/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8275 - acc: 0.7439 - val_loss: 0.9886 - val_acc: 0.6755\n",
      "Epoch 883/1000\n",
      "5408/5408 [==============================] - 1s 242us/step - loss: 0.8255 - acc: 0.7465 - val_loss: 1.0754 - val_acc: 0.5857\n",
      "Epoch 884/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8302 - acc: 0.7457 - val_loss: 0.9721 - val_acc: 0.7038\n",
      "Epoch 885/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8251 - acc: 0.7428 - val_loss: 0.9312 - val_acc: 0.7005\n",
      "Epoch 886/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8279 - acc: 0.7454 - val_loss: 0.9663 - val_acc: 0.6938\n",
      "Epoch 887/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8251 - acc: 0.7480 - val_loss: 0.9833 - val_acc: 0.7072\n",
      "Epoch 888/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8237 - acc: 0.7463 - val_loss: 0.9815 - val_acc: 0.6839\n",
      "Epoch 889/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8227 - acc: 0.7480 - val_loss: 1.1166 - val_acc: 0.6639\n",
      "Epoch 890/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8370 - acc: 0.7400 - val_loss: 0.9462 - val_acc: 0.6889\n",
      "Epoch 891/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8240 - acc: 0.7478 - val_loss: 0.9896 - val_acc: 0.6972\n",
      "Epoch 892/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8233 - acc: 0.7507 - val_loss: 0.9682 - val_acc: 0.7238\n",
      "Epoch 893/1000\n",
      "5408/5408 [==============================] - 1s 245us/step - loss: 0.8192 - acc: 0.7478 - val_loss: 1.0117 - val_acc: 0.6872\n",
      "Epoch 894/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8233 - acc: 0.7461 - val_loss: 0.9580 - val_acc: 0.7121\n",
      "Epoch 895/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8279 - acc: 0.7452 - val_loss: 1.1068 - val_acc: 0.6689\n",
      "Epoch 896/1000\n",
      "5408/5408 [==============================] - 1s 241us/step - loss: 0.8263 - acc: 0.7502 - val_loss: 0.9150 - val_acc: 0.7171\n",
      "Epoch 897/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8277 - acc: 0.7450 - val_loss: 0.9844 - val_acc: 0.7022\n",
      "Epoch 898/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8196 - acc: 0.7522 - val_loss: 1.0115 - val_acc: 0.6339\n",
      "Epoch 899/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8335 - acc: 0.7452 - val_loss: 0.9975 - val_acc: 0.6972\n",
      "Epoch 900/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8314 - acc: 0.7448 - val_loss: 1.2276 - val_acc: 0.6606\n",
      "Epoch 901/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8378 - acc: 0.7404 - val_loss: 1.3224 - val_acc: 0.4942\n",
      "Epoch 902/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8357 - acc: 0.7411 - val_loss: 0.9323 - val_acc: 0.7188\n",
      "Epoch 903/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8265 - acc: 0.7454 - val_loss: 1.4841 - val_acc: 0.5125\n",
      "Epoch 904/1000\n",
      "5408/5408 [==============================] - 2s 279us/step - loss: 0.8545 - acc: 0.7365 - val_loss: 0.9734 - val_acc: 0.6922\n",
      "Epoch 905/1000\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 0.8299 - acc: 0.7439 - val_loss: 0.9897 - val_acc: 0.6755\n",
      "Epoch 906/1000\n",
      "5408/5408 [==============================] - 2s 291us/step - loss: 0.8303 - acc: 0.7419 - val_loss: 1.1302 - val_acc: 0.6007\n",
      "Epoch 907/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8393 - acc: 0.7369 - val_loss: 1.1797 - val_acc: 0.5874\n",
      "Epoch 908/1000\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 0.8537 - acc: 0.7345 - val_loss: 1.0024 - val_acc: 0.6922\n",
      "Epoch 909/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8301 - acc: 0.7463 - val_loss: 1.0305 - val_acc: 0.7105\n",
      "Epoch 910/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8287 - acc: 0.7448 - val_loss: 0.9490 - val_acc: 0.7138\n",
      "Epoch 911/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8263 - acc: 0.7511 - val_loss: 1.0969 - val_acc: 0.6406\n",
      "Epoch 912/1000\n",
      "5408/5408 [==============================] - 1s 256us/step - loss: 0.8322 - acc: 0.7465 - val_loss: 0.9074 - val_acc: 0.7221\n",
      "Epoch 913/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8367 - acc: 0.7382 - val_loss: 1.0254 - val_acc: 0.6988\n",
      "Epoch 914/1000\n",
      "5408/5408 [==============================] - 1s 269us/step - loss: 0.8224 - acc: 0.7474 - val_loss: 1.0208 - val_acc: 0.6722\n",
      "Epoch 915/1000\n",
      "5408/5408 [==============================] - 1s 265us/step - loss: 0.8342 - acc: 0.7419 - val_loss: 1.0688 - val_acc: 0.6772\n",
      "Epoch 916/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8276 - acc: 0.7446 - val_loss: 1.1598 - val_acc: 0.5341\n",
      "Epoch 917/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8308 - acc: 0.7435 - val_loss: 1.0056 - val_acc: 0.6805\n",
      "Epoch 918/1000\n",
      "5408/5408 [==============================] - 2s 286us/step - loss: 0.8273 - acc: 0.7457 - val_loss: 1.3907 - val_acc: 0.4409\n",
      "Epoch 919/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8436 - acc: 0.7361 - val_loss: 0.9281 - val_acc: 0.7155\n",
      "Epoch 920/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8199 - acc: 0.7504 - val_loss: 1.1550 - val_acc: 0.6639\n",
      "Epoch 921/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8324 - acc: 0.7478 - val_loss: 0.9530 - val_acc: 0.7121\n",
      "Epoch 922/1000\n",
      "5408/5408 [==============================] - 1s 261us/step - loss: 0.8279 - acc: 0.7443 - val_loss: 0.9557 - val_acc: 0.6988\n",
      "Epoch 923/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8171 - acc: 0.7504 - val_loss: 1.0064 - val_acc: 0.6805\n",
      "Epoch 924/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8361 - acc: 0.7450 - val_loss: 1.0986 - val_acc: 0.6639\n",
      "Epoch 925/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8443 - acc: 0.7404 - val_loss: 0.9539 - val_acc: 0.7221\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 1s 267us/step - loss: 0.8264 - acc: 0.7483 - val_loss: 0.9848 - val_acc: 0.7105\n",
      "Epoch 927/1000\n",
      "5408/5408 [==============================] - 2s 296us/step - loss: 0.8204 - acc: 0.7504 - val_loss: 0.9943 - val_acc: 0.6988\n",
      "Epoch 928/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8327 - acc: 0.7404 - val_loss: 1.2819 - val_acc: 0.5874\n",
      "Epoch 929/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8418 - acc: 0.7389 - val_loss: 0.9411 - val_acc: 0.6988\n",
      "Epoch 930/1000\n",
      "5408/5408 [==============================] - 2s 281us/step - loss: 0.8258 - acc: 0.7493 - val_loss: 0.9237 - val_acc: 0.7205\n",
      "Epoch 931/1000\n",
      "5408/5408 [==============================] - 2s 289us/step - loss: 0.8240 - acc: 0.7476 - val_loss: 0.9436 - val_acc: 0.7155\n",
      "Epoch 932/1000\n",
      "5408/5408 [==============================] - 1s 271us/step - loss: 0.8216 - acc: 0.7513 - val_loss: 0.9278 - val_acc: 0.7221\n",
      "Epoch 933/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8185 - acc: 0.7511 - val_loss: 1.1398 - val_acc: 0.6672\n",
      "Epoch 934/1000\n",
      "5408/5408 [==============================] - 2s 280us/step - loss: 0.8499 - acc: 0.7378 - val_loss: 1.4277 - val_acc: 0.4692\n",
      "Epoch 935/1000\n",
      "5408/5408 [==============================] - 1s 270us/step - loss: 0.8637 - acc: 0.7341 - val_loss: 1.0157 - val_acc: 0.6789\n",
      "Epoch 936/1000\n",
      "5408/5408 [==============================] - 1s 262us/step - loss: 0.8329 - acc: 0.7420 - val_loss: 0.9776 - val_acc: 0.7072\n",
      "Epoch 937/1000\n",
      "5408/5408 [==============================] - 1s 273us/step - loss: 0.8272 - acc: 0.7450 - val_loss: 0.9123 - val_acc: 0.7271\n",
      "Epoch 938/1000\n",
      "5408/5408 [==============================] - 1s 268us/step - loss: 0.8260 - acc: 0.7424 - val_loss: 1.1919 - val_acc: 0.5757\n",
      "Epoch 939/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8459 - acc: 0.7361 - val_loss: 1.0056 - val_acc: 0.7005\n",
      "Epoch 940/1000\n",
      "5408/5408 [==============================] - 1s 274us/step - loss: 0.8402 - acc: 0.7439 - val_loss: 0.9738 - val_acc: 0.7171\n",
      "Epoch 941/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8320 - acc: 0.7439 - val_loss: 1.1091 - val_acc: 0.6822\n",
      "Epoch 942/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8259 - acc: 0.7443 - val_loss: 1.9748 - val_acc: 0.2696\n",
      "Epoch 943/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8733 - acc: 0.7278 - val_loss: 1.0061 - val_acc: 0.6938\n",
      "Epoch 944/1000\n",
      "5408/5408 [==============================] - 1s 266us/step - loss: 0.8312 - acc: 0.7463 - val_loss: 1.0593 - val_acc: 0.6689\n",
      "Epoch 945/1000\n",
      "5408/5408 [==============================] - 1s 260us/step - loss: 0.8342 - acc: 0.7400 - val_loss: 1.0257 - val_acc: 0.6556\n",
      "Epoch 946/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8306 - acc: 0.7507 - val_loss: 1.1816 - val_acc: 0.5424\n",
      "Epoch 947/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8407 - acc: 0.7402 - val_loss: 0.9726 - val_acc: 0.6889\n",
      "Epoch 948/1000\n",
      "5408/5408 [==============================] - 1s 257us/step - loss: 0.8238 - acc: 0.7463 - val_loss: 0.9460 - val_acc: 0.7188\n",
      "Epoch 949/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8275 - acc: 0.7472 - val_loss: 1.4261 - val_acc: 0.4343\n",
      "Epoch 950/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8598 - acc: 0.7308 - val_loss: 0.9070 - val_acc: 0.7221\n",
      "Epoch 951/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8280 - acc: 0.7465 - val_loss: 0.9307 - val_acc: 0.7038\n",
      "Epoch 952/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8252 - acc: 0.7483 - val_loss: 0.9104 - val_acc: 0.7255\n",
      "Epoch 953/1000\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.8310 - acc: 0.7457 - val_loss: 1.0010 - val_acc: 0.7072\n",
      "Epoch 954/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8291 - acc: 0.7465 - val_loss: 1.3338 - val_acc: 0.4759\n",
      "Epoch 955/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8378 - acc: 0.7406 - val_loss: 0.9946 - val_acc: 0.6622\n",
      "Epoch 956/1000\n",
      "5408/5408 [==============================] - 1s 254us/step - loss: 0.8224 - acc: 0.7483 - val_loss: 0.9095 - val_acc: 0.7371\n",
      "Epoch 957/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8196 - acc: 0.7493 - val_loss: 0.9225 - val_acc: 0.7188\n",
      "Epoch 958/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8191 - acc: 0.7476 - val_loss: 1.2563 - val_acc: 0.6722\n",
      "Epoch 959/1000\n",
      "5408/5408 [==============================] - 1s 253us/step - loss: 0.8343 - acc: 0.7482 - val_loss: 0.9516 - val_acc: 0.7022\n",
      "Epoch 960/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8383 - acc: 0.7430 - val_loss: 0.9648 - val_acc: 0.7288\n",
      "Epoch 961/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8211 - acc: 0.7485 - val_loss: 0.9905 - val_acc: 0.7221\n",
      "Epoch 962/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8233 - acc: 0.7467 - val_loss: 0.9583 - val_acc: 0.6839\n",
      "Epoch 963/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8267 - acc: 0.7476 - val_loss: 0.9488 - val_acc: 0.7072\n",
      "Epoch 964/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8195 - acc: 0.7517 - val_loss: 0.9442 - val_acc: 0.7138\n",
      "Epoch 965/1000\n",
      "5408/5408 [==============================] - 2s 300us/step - loss: 0.8208 - acc: 0.7480 - val_loss: 0.9539 - val_acc: 0.7088\n",
      "Epoch 966/1000\n",
      "5408/5408 [==============================] - 2s 337us/step - loss: 0.8239 - acc: 0.7439 - val_loss: 1.2956 - val_acc: 0.5241\n",
      "Epoch 967/1000\n",
      "5408/5408 [==============================] - 2s 349us/step - loss: 0.8596 - acc: 0.7352 - val_loss: 0.9059 - val_acc: 0.7121 0.8608 - acc: 0.7\n",
      "Epoch 968/1000\n",
      "5408/5408 [==============================] - 2s 331us/step - loss: 0.8301 - acc: 0.7446 - val_loss: 0.9175 - val_acc: 0.7155\n",
      "Epoch 969/1000\n",
      "5408/5408 [==============================] - 2s 350us/step - loss: 0.8145 - acc: 0.7504 - val_loss: 0.9920 - val_acc: 0.6589\n",
      "Epoch 970/1000\n",
      "5408/5408 [==============================] - 2s 348us/step - loss: 0.8466 - acc: 0.7404 - val_loss: 1.0065 - val_acc: 0.6556\n",
      "Epoch 971/1000\n",
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.8307 - acc: 0.7482 - val_loss: 1.0743 - val_acc: 0.6456\n",
      "Epoch 972/1000\n",
      "5408/5408 [==============================] - 2s 284us/step - loss: 0.8398 - acc: 0.7433 - val_loss: 0.9822 - val_acc: 0.6972\n",
      "Epoch 973/1000\n",
      "5408/5408 [==============================] - 2s 307us/step - loss: 0.8212 - acc: 0.7496 - val_loss: 0.9345 - val_acc: 0.6972\n",
      "Epoch 974/1000\n",
      "5408/5408 [==============================] - 2s 282us/step - loss: 0.8225 - acc: 0.7493 - val_loss: 0.9259 - val_acc: 0.7088\n",
      "Epoch 975/1000\n",
      "5408/5408 [==============================] - 1s 263us/step - loss: 0.8349 - acc: 0.7430 - val_loss: 0.9127 - val_acc: 0.7205\n",
      "Epoch 976/1000\n",
      "5408/5408 [==============================] - 1s 252us/step - loss: 0.8156 - acc: 0.7515 - val_loss: 1.0493 - val_acc: 0.6755\n",
      "Epoch 977/1000\n",
      "5408/5408 [==============================] - 1s 248us/step - loss: 0.8348 - acc: 0.7441 - val_loss: 0.9886 - val_acc: 0.6855\n",
      "Epoch 978/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8280 - acc: 0.7457 - val_loss: 0.9752 - val_acc: 0.7072\n",
      "Epoch 979/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8366 - acc: 0.7441 - val_loss: 1.3349 - val_acc: 0.5507\n",
      "Epoch 980/1000\n",
      "5408/5408 [==============================] - 1s 272us/step - loss: 0.8357 - acc: 0.7402 - val_loss: 1.0097 - val_acc: 0.6905\n",
      "Epoch 981/1000\n",
      "5408/5408 [==============================] - 2s 299us/step - loss: 0.8257 - acc: 0.7504 - val_loss: 0.9438 - val_acc: 0.7138\n",
      "Epoch 982/1000\n",
      "5408/5408 [==============================] - 2s 301us/step - loss: 0.8177 - acc: 0.7496 - val_loss: 1.1191 - val_acc: 0.6156\n",
      "Epoch 983/1000\n",
      "5408/5408 [==============================] - 2s 297us/step - loss: 0.8341 - acc: 0.7433 - val_loss: 0.9779 - val_acc: 0.7304: 1s - loss: 0\n",
      "Epoch 984/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 2s 288us/step - loss: 0.8335 - acc: 0.7424 - val_loss: 0.9488 - val_acc: 0.7072\n",
      "Epoch 985/1000\n",
      "5408/5408 [==============================] - 2s 294us/step - loss: 0.8322 - acc: 0.7469 - val_loss: 0.9802 - val_acc: 0.7138\n",
      "Epoch 986/1000\n",
      "5408/5408 [==============================] - 2s 283us/step - loss: 0.8275 - acc: 0.7469 - val_loss: 1.0001 - val_acc: 0.6656\n",
      "Epoch 987/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8285 - acc: 0.7483 - val_loss: 0.9368 - val_acc: 0.7088s - loss: 0.8343 - acc:\n",
      "Epoch 988/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8220 - acc: 0.7480 - val_loss: 0.9504 - val_acc: 0.6938\n",
      "Epoch 989/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8209 - acc: 0.7491 - val_loss: 1.0608 - val_acc: 0.6855\n",
      "Epoch 990/1000\n",
      "5408/5408 [==============================] - 2s 285us/step - loss: 0.8330 - acc: 0.7461 - val_loss: 0.9427 - val_acc: 0.7022\n",
      "Epoch 991/1000\n",
      "5408/5408 [==============================] - 2s 287us/step - loss: 0.8185 - acc: 0.7502 - val_loss: 0.9496 - val_acc: 0.7138\n",
      "Epoch 992/1000\n",
      "5408/5408 [==============================] - 2s 278us/step - loss: 0.8348 - acc: 0.7435 - val_loss: 0.9713 - val_acc: 0.7005\n",
      "Epoch 993/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8263 - acc: 0.7500 - val_loss: 1.0461 - val_acc: 0.6273\n",
      "Epoch 994/1000\n",
      "5408/5408 [==============================] - 1s 250us/step - loss: 0.8353 - acc: 0.7441 - val_loss: 1.0416 - val_acc: 0.6739\n",
      "Epoch 995/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8340 - acc: 0.7430 - val_loss: 0.9639 - val_acc: 0.6938\n",
      "Epoch 996/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8179 - acc: 0.7513 - val_loss: 0.9413 - val_acc: 0.7155\n",
      "Epoch 997/1000\n",
      "5408/5408 [==============================] - 1s 255us/step - loss: 0.8222 - acc: 0.7482 - val_loss: 0.9544 - val_acc: 0.6955\n",
      "Epoch 998/1000\n",
      "5408/5408 [==============================] - 1s 244us/step - loss: 0.8240 - acc: 0.7467 - val_loss: 0.9604 - val_acc: 0.7088\n",
      "Epoch 999/1000\n",
      "5408/5408 [==============================] - 1s 247us/step - loss: 0.8206 - acc: 0.7494 - val_loss: 1.0222 - val_acc: 0.6972\n",
      "Epoch 1000/1000\n",
      "5408/5408 [==============================] - 1s 251us/step - loss: 0.8237 - acc: 0.7494 - val_loss: 0.9604 - val_acc: 0.7038\n",
      "5408/5408 [==============================] - 2s 287us/step\n",
      "[0.8740989738667505, 0.7176405325443787]\n"
     ]
    }
   ],
   "source": [
    "# Now we pick the best model and run it for a 1000 epochs\n",
    "CNN_model = create_convolutional_NN(input_shape, 30, n_categories, eta=0.01, lmbd=0.01, \n",
    "                                    n_filters = 15, filter_sizes = receptive_field)\n",
    "CNN_model.fit(train, train_labels, epochs = 1000, batch_size = batch_size, verbose =1, validation_data = \n",
    "              (valid, valid_labels))\n",
    "print(CNN_model.evaluate(train, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "pred_train = CNN_model.predict(train)\n",
    "pred_test = CNN_model.predict(test)\n",
    "\n",
    "# Convert predicted classes to one hot vectors \n",
    "pred_train = np.argmax(pred_train,axis = 1)\n",
    "pred_test = np.argmax(pred_test,axis = 1)\n",
    "\n",
    "# Convert train and test observations to one hot vectors\n",
    "converted_train_values = np.argmax(train_labels, axis = 1)\n",
    "converted_test_values = np.argmax(test_labels, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 3, 6, 5, 1, 0]\n",
      "[1 1 1 ... 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Rearranging values, in order to correctly correspond to the confusion matrix axis\n",
    "print(legend)\n",
    "print(pred_train)\n",
    "for i in range(len(pred_train)):\n",
    "    pred_train[i] = legend[pred_train[i]]\n",
    "    converted_train_values[i] = legend[converted_train_values[i]]\n",
    "\n",
    "for i in range(len(pred_test)):\n",
    "    pred_test[i] = legend[pred_test[i]]\n",
    "    converted_test_values[i] = legend[converted_test_values[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(63.7, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAJ+CAYAAAAOi1y1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xt8znUfx/HXZmxzPp/P5IuQJHJXKlQOKXfdlVKRQkQh3VE6iUqRUsghqRzLqXPu0lHJIXIIX2fVnOYUZjPb3H/8rs3Mtdl12Xb9tuv9fDz22Hb9Dtfn+u53/a7PvseQ06dPIyIiIiLuFRroAEREREQkY0rYRERERFxOCZuIiIiIyylhExEREXE5JWwiIiIiLqeETURERMTlwgIdgEheZYx5DnjWj0NrWGt3Zm00DmNMN+Bd4DdrbdPseA4vz5kfuBO4A2gKlAbigK3Al8A4a+3unIglI8aY1sBwoCGQCPxgrb05h557J1AN6Git/SwnnjM3MsbUtdZu8mH/6sAOz69FrLXHsyUwkRyghE0k+/wJ/Ozl8aZAOLAF2O9le1x2BpWTjDF1gbnAxZ6HjgDrgVLAJcClQD9jzAPW2o8CEyUYY2oBXwAFgGhgF2c+6CXAjDEXARNwrp//BDgckYBQwiaSTay1U4GpaR9PVZvyorV2Ws5GxQLgVyA2u5/IGNMMWAwUBr4Dhlhrl6XaXg14GegMzDbGnLDWfp7dcaWjE06ytg1oYK3N6aS5NZAf+CuHnze36IJTRvN8PC4KqOf5OSZLIxLJYUrYRIKItfYf4J/sfh5jTCFgOk6yNg/obK1NSBPLLuAuY0wScDcwyRhzkbX2RHbH50UZz/cVAUjWsNZuy+nnDAbW2lNApptQRdxMgw5EJDsMAi4CDgPd0yZrXvY9BVQkcM1dyf+8ngzQ84uIZEg1bCIularptDYwAugIxAOfWmvv8+xTFOjj2VYXKAocA9YBHwBTrbVJqc7ZDS+DDowxp3GajIoADwAP4TQlJQDLgVestV/7EH53z/fJ1tqjGe1ord1jjLkbp8/fqrTbjTG3Ar2Ay4FCwF7gG2CktXZzmn2TX9844DnP181AOZz+gp8Bw6y1e9Lsn6yrMaarJ66Q8w3SMMb0Bd7EGaBwbarHQzxlcA9ggJKe518CjLHWrkhznp2kM+jAGHMd8AjwL6AEcAD4ERhlrV2ZZt9rcZqfP8cZ6PEUzmCPyjj9v77xvP6zyi09qc73MXAv8LTnfOWB3cD7wHBrbYIx5nZgINAIJwH/HnjCWmu9nLcR0A9oCVTC+SzaD/wEjLbWrkq1b+oFr2/z/P6DtfbaNK/3ZZx+bnVwrpGBwG+kGXRgjHkRGAKcwGn+Tumr6Pm7/Q9og/O3uib1+0ckkFTDJuJ+03FqnjbjJFC7AIwxVYHVwEvAZTgfUuuBfDgfhJOB8T4+1yTPcTVxmpJCcT68FnkSp/PydOCv6vl1cWaOsdbOtdYuT10TZ4wJNcZMx2lSvQE4DqzFSVq6A2syiKkiTvLXB6fMtuAkLQ8BS40xxT377cMZGBLl+X2/53dvg0V8MQGYAlyDk0Cvx2kevsvz/Ldk5iTGmJeAb3H62J0Gfsfpa3cnsMyTMHpTBCfhGIIzwGUjzujcLsCvxpiaPr6eEjh9HwfhJPa7gRo4o6Df9IyI/hDnnwsLFARuAX4wxpRK85q64vxtHsRJZDfh9N2riNM0vtQY0zLVIT9zpm/fQc/v69LEVwNn0Eglz2stD6xJ57U8h/P3KMi574++ONf7UeBeJWviJkrYRNzvUuBqa+2lOB9qr3oeH4OTWP0IVLHWXuzZpywwyrNPT2NM+Uw+TyHgfpyaj9LW2stwPgB/AEKAFzJ5nrqpfl6fyWO8GYqTYPyDU/NU1Vp7OU5t2RggAphhjGng5dh/4wysaGqtrWmtbQBciVOrUg3oAWCt/dJaexUw23Pcl9baqzyP+cUYczFOjWA00NBaazy1cxVwEoR8wGuZOM99wGCcWtUHgArW2mY4r/8JnL/JWGPM9V4Ob4mTtLSx1lbxXBcNcJL6EsBjPr6slp7jLvdcZzWBZzzbenp+HgCUtdY2wRkVfMgTa5dUr6kcZ8pgEFDeWtvUWnsRTs3YGpyEdHDyMZ6/RfLgne89f59+aeKrj5PEVbXWNgYqWWu3ensh1tp4oCtOIt/WGNPZE1sdnFo6gH7ZNbWOiL+UsIm433xr7VJwOlFba48aYyKA5ji1Lr2stdHJO1trT+J84J3E+VCv6+Wc6ZlsrX0ruWbB05w51LOtvqcJ9nyKp/r5oA/PncIzaGGQ59deqZsJrbWx1tqBOM10ETjNdN7cl7ppzVr7CzDL82sLf+LKpIae779Ya/9I9fwngceBr4FvjTGFz3Oe5Dn8nrHWTrXWnvacJ9Fa+wowFufvOzyd4/tba1NqOD3zl43z/OrP63/cWvtbqt9H4cxXFwp8aK19PVWMW3BGJAM0TnXMtZ7vv1prR1trE1PFt50z/2jU9yO+55PnWbPWHshoR8918ZLn1zHGmJLANJxat7nW2vf9eH6RbKWETcT9lqZ9wFobZ62tDBRKZyLRCJwO/+B8CGXWF14eS90HKTMJW+pRnv72k70ap1kvGkhvfraxnu/tjDH50mw7lHoKkVSSX0tmXoe/kkd8djDGPG6MqZjy5NaesNbeYK3tkdEkrp7562oCScDEdHZLfv3NjDFl02w7jTMpcVoX8vrPOp+1NpYz8wj+z8v++zzfi6Q6Zo61thBwXTrPkXzt+HLNJjvnfXIeL+DU6JUHfsFJYnfj1I6KuI4GHYi43570NlhrYz2zuf8LZ1RmDZzmqEY4TUvg2z9mUV4eSz1nW9rEyJu9qX4ujX/zX9XxfF+bQT+i5NqzIjgfuqlj9/Y64Mxryczr8Iu1doUxZgFOs+wrwCvGmLXAIpxBD0sy0Tcq+fXvsNYeSed5thtj/gGK4fztU0/CfDydwR7+vv44a+0hL4/He75He9l2yvM9xNtxxpgrcWoja+H0fbsE5/oF3ysTYqy1x3w5wFp7ytOfbgXOwJDTQLd0XqdIwClhE3E/r/OCeQYdvIHTuTv1h+JenNUF2uH0O/JF/Hm2e/vwTWsrzodfCE7yuOt8B3gm0T1urU1uQk2ulcnoQzh1DVWRNNuy4nVciNuB3jgd6y/BSaAb4TSJ7jLGPGqt/TiD4zPz+sEpg2Jk/+s/X9J9+jzbU3gGirzEmaQUnJrE9cB8IFODW9Lwd+68DcB2nIQtDmdwiogrqUlUJBcyxhTEGYHZCdgJ/BdohdMxvYK1tgsBWuLK059uuefX1pk87CUg2hgzxfN7cjKWUdNdsVQ/Z/cakeklOF6b7jz9zN7ydICvijOYYxbO6MNqwDxjzGUZPF9mXj+cKYNcsUamMeYGnH8m6gCfAt2AJjhTblxC+s2/2eUpnGQtCYgEpnqm9hBxHdWwieROnXCakQ7ijNw7q3O/Z1BCKW8H5pB5OIMi7jfGDLfWHk5vR2NMGZzXE8KZqRiS+1o1MsaEptOEmJzwnMDpe5QdkqcZCU9ne4W0D3gGZtQF9llrd1lr/8Lp0D7NGFMMZ7qNBjhLcv2W9niP5Ndf3RhT3FuzqGdUY/LABa8jIl1oEM7feZq19n4v2yvnVCDGmEuBJ3FqBzvhTGdzHfAw8FZOxSGSWaphE8mdqnu+/5k2WfO4lzN92ALxj9lEnD5VJYDxxhivMRhjQoG3cWo39nFm+oYlOLVRpXGaF7152PN9cTbOl5WcaFbzJMEpPK+pvZdjXgGW4cyBdhbrLA2WPGluuv3IPANJtuHco9PrBJ/8+tdZa/ems4/bVPd8X512g6dmq5vn17TXS/LfN0tqv4wxBYD3cNZvfdta+ynQ37N5pGcuQRFXUcImkjslz1TfyBjTMflBY0x+Y8yDwOup9j0r0cgJng7v3XCmfegMfOVZDD6Fp4boE5w+S4k4S1jFeI4/Doz27DrRGNMh1XERxpjXcFYwiOfM9BfZYbkntsLAiOTRqJ6asnc4ux9Wspme7w8aY+5J3cRmjLmGMwmot1GcqQ1L/m6MuT/5PMaYfMaYx3HmywOnlii3SL5uH/TMyQaAMaYCTrld7Xko7TWb3ORblazxLM6Ah9145nyz1s4GvsJp5n7X88+EiGvoghTJnRbiNKflAz4xxmwzxqzEqdWajDMacK1n34reT5G9rLVf4qzQcBSnL9syY8w+Y8wKY8xWnGa/DjgT495hrU07pcgInAltiwGfGWN2GWOW47zGAThNod2stefU1mTha4jGGdgBzlJHfxtjfsMZhdoFL3OgWWt/xJkYNx/O8mB7Pa95B85yTYWBSfY8S3155gJ7FaemdCqw2/P69+HU4iUBj9k0S1m53HCcJLshsNMY87sx5g+cZck640zSnAiEe+ZGS5Z8LTc1xmw2xsz1NwBjzOU4Ew8DPJxmNG1vnOvqauBRf59DJDsoYRPJhTxLOF2LUwvzB860FvVwpgAZjfOBmLzsTkcvp8gR1tqFONM2DMVZUigMZ+WGsjgJ5wtAXWvtfC/HJuIsVXQnzhqYRXBGWu7HeW2XWmtnpT0uGwzCGe25Eid5rImTeF2J01cvvWO6efYLw5k8tjBODc5/rLWZmuvLWvtf4HqcDvphOCNOj+Os4dncWnveFRPcxFr7K84gg/k4f8eLOTMP2gM4A2eSm4w7pjruG5yaxL9xBm008acGzBgTjtMUmg9nQuqFaeLbibN0FTg1qt5qUEUCIuT06UyPxhYRERGRAFANm4iIiIjLKWETERERcTklbCIiIiIup4RNRERExOWUsImIiIi4XNAvTRVWoJKGyYqIiEiOSYiP8nnVDtWwiYiIiLicEjYRERERl1PCJiIiIuJySthEREREXE4Jm4iIiIjLKWETERERcTklbCIiIiIup4RNRERExOWUsImIiIi4nBI2EREREZdTwiYiIiLickrYRERERFxOCZuIiIiIyylhExEREXE5JWwiIiIiLqeETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcTgmbiIiIiMspYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwiYiIiLicEjYRERERl1PCJiIiIuJySthcpGTJEiTER2X4Nez5/wY6TFcpXrwYo0c9z7Yty4g5tp2d21cyaeIoqlatFOjQcpWQkBB+WfIpe3evC3QorqbrzXcqM/+o3PyTl8st5PTp04GOIaDCClRyTQFc07IFi7+Zy4EDh7B2q9d93v/gI96ZOjOHI3On4sWL8eMPC6lfrw5Hjx5j85bt1KxRlZIlS3D48BFatfkP69ZtDHSYucLwFwYz+Il+HDhwiPIVGwY6HFfS9eY7lZl/VG7+yU3llhAfFeLrMaphc5GGDesBMHvOQq657t9ev5SsnTHx7VepX68OX3yxmKrVL+OKFu2pUu0ypr03hxIlijNj+nhCQ3WJn8/TQwcw+Il+gQ7D9XS9+U5l5h+Vm3/yermphs1FNWxvT3iFBx/oQp+HBzNp8geBDsfVjKnFujXfExNzgpq1m3P48JGUbaGhofy+ejH169Xhjs49mT//8wBG6l7lypVh/LiXueXmtimPqYbNO11vvlOZ+Ufl5p/cVm55sobNGFPYGFPeGFPBGFM00PFkp4YNnBq2DRtsgCNxvy5330ZoaCifff71WW9MgKSkJN57bw4Ad9x+cyDCc73r27Rk4x8/ccvNbdmzZx9PPvVioENyNV1vvlOZ+Ufl5p9gKLewQAeQljGmAtATaAdcDBRMsz0OWAd8Dkyw1h7I8SCzSf36dQD4Y8PmAEfifs0uvxSApUtXet2+bNkqAK66slmOxZSb1KtXh8KFC/HB9Lk8Nug5GjaoG+iQXE3Xm+9UZv5RufknGMrNVQmbMeZB4A0gAggBkoBoINbzewRQGmjm+XrCGNPDWjsrMBFnnZo1q1GkSGH27NlH2bKleHxQby5pdDEAa9dt4J2ps9i6dUeAo3SPWrWqA7Bz519et+/6828AypcvS6FCBYmJOZFToeUKK1b8zuXN27JmzR+BDiVX0PXmO5WZf1Ru/gmGcnNNwmaMuQGYBBwFRgALgM3W2sQ0++UDDPBv4HHgA2PMHmvt9zkbcdZq4KnhKFasKGtWf0tY2Jk/zY03Xsejj/Tg0f5PM3nK9ECF6CplypQC4ODBw163Hzp0pkq8dOmSufLNmZ2W/ur9v1DxTteb71Rm/lG5+ScYys1NfdgGA/FAa2vti9bajWmTNQBrbaK1doO1dgTQBkgEnsrhWLNcI88I0YIFI5nyzkzqN2hJZKHq1K1/FRMnfUCBAgUY99ZLdGjfJsCRukNkZAQAsXFxXrfHxsads6+Iv3S9+U5l5h+Vm3+CodzclLBdBnxnrf0tswdYa1cC3wKNsy2qHLJ69XomTvqARx59ir79hrB58zZOnTrF1q07eLjvYN4aN5XQ0FBGjnw60KG6QmLiObn8WVIP3Q72kdBy4XS9+U5l5h+Vm3+CodzclLDF49SW+eo0EJ7FseS4z7/4hof7Dmb8hGlet7888k0A6pra1K5dIwcjc6fk6uyIcO9/+vDwAik/p/7PSsQfut58pzLzj8rNP8FQbm5K2NYBrYwx9TJ7gDGmCdAaWJVtUbnE3r372bcvGoBqVSsHOJrAS+6nULJkca/bS5UqkfJzdPTBHIlJ8i5db75TmflH5eafYCg3NyVsL+KMAv3ZGDPUGNPQGHPOoAhjTKgxpq4xZjCwGGfgxCs5HGu2CAsLy3AW5pAQZ569+Pj4nArJtazdBkC1alW8bk9Oanfv3ptr/5sS99D15juVmX9Ubv4JhnJzTcJmrf0G6A5EAs8DvwOxxpi9xpjtxphtxpjdQBzwB06CFw70tdZ+Eai4s8qObSuIO7GL22/v6HV7hQrlKFu2NACb0llnNJj8tmoNAM2bN/G6Pfnx5StW51hMknfpevOdysw/Kjf/BEO5uSZhA7DWTgNqACNxErYEoCxQ3fN4eZyEbQUwDKhnrZ0QiFizWvLqBvd2+Y/X7QP79wLghx9+ybXVuVlpwcIvAeh0S1tKlDi7Cjw0NJT77rsDgBkz5+d4bJL36HrzncrMPyo3/wRDubkqYQOw1u611j5prb3MWhsJlAKqApWB4tbaotbaK6y1z1lrdwU22qzz2piJALRt24oRwweTP39+wLnQBg7oxaOP9iAhIYEhT2oJIYB16zbyxReLKVq0CB/OnkTJkk7/hPDwcCZNHEX9enXYZLey0PMmFrkQut58pzLzj8rNP8FQblr83UWLvw9+oh/DXxgMwJEj/7B1206qVa1MmTKlOHXqFD16DWL69LkBjtI9KlWqwA/fLaB69SrExJxg46Yt1KxRlZIlS3DkyD9cfc0tbNy4JdBh5grXtGzB4m/mavH3DOh6853KzD8qN//kpnLLk4u/B5OXR75Jm+tv55NPF3HqVAKNGtYjPj6embPm07xFeyVraURF7aHZFe0Y++YUoqMP0qhhPRISEpk1ewFX/KuDa96YkjfoevOdysw/Kjf/5PVyUw2bi2rYREREJO9TDZuIiIhIHqSETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcTgmbiIiIiMspYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwiYiIiLicEjYRERERl1PCJiIiIuJySthEREREXE4Jm4iIiIjLKWETERERcTklbCIiIiIup4RNRERExOWUsImIiIi4nBI2EREREZdTwiYiIiLickrYRERERFxOCZuIiIiIyylhExEREXE5JWwiIiIiLqeETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcLizQAQRaaEhIoEPIdfKF5gt0CLlSQmJCoEOQIHE60AHkQvok8I+utZyjGjYRERERl1PCJiIiIuJySthEREREXE4Jm4iIiIjLKWETERERcTklbCIiIiIup4RNRERExOWUsImIiIi4nBI2EREREZdTwiYiIiLickrYRERERFxOCZuIiIiIyylhExEREXE5JWwiIiIiLqeETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcTgmbiIiIiMspYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwiYiIiLicEjYRERERl1PCJiIiIuJySthEREREXE4JWw5r0qQRc2ZP4u+/fufoP1vZuHEJo0c/T4UK5TJ1fJ8+9xN/8m/at2+dzZG6S6VK5Rk7dgTW/sw//2zhr79W89FHU2jRommmz9G7dzdiY3fRrl2rbIzUXYypxeRJo9my+VeOH9tO9P4NLP5mLl263OZ1/wULpnEqPirdrx3bV+bwKwi8kJAQfl7yKXt2r8twvyaXNmTGjAn8uWsVMcd3sG3rcsa99TLly5fNoUjdIyQkhF+WfMre85RZao8+0oOE+ChuvOHa7AvM5XSt+W/r5l9JiI/K1Nc1LVsEOly/hAU6gGDSoUMbPvpwCmFhYRw8eJiNG7dQs2Y1+vV9gC5330b7DnezatXadI9v3LgBLwx7Igcjdod69S5i0aI5lClTitjYODZt2krFiuW56abradeuFX36DOb99z/M8ByNGzfg+ecfz6GI3aFDh+uZNXMCkZGRxMbGYu02ypYtTcuWLWjZsgU33nAt93Xtd9YxDS6uC8Cvv/5GYmLiOefcH30gR2J3k2HDnqBZsyYcOHAo3X3u79aZ8eNHEhYWxp49+7B2K8bUpmfPe+nY8QauubYTO3b8mYNRB9YLmSiz1JpedgnPPxdc709vdK35b+Vva4iK2pPu9mrVqlC5cgXi4uKI2r03ByPLOkrYckilShWY9u5YwsLCGDHidYaPGENiYiKRkRGMfWMEXbveycyZE7j44pZePyibNm3MwgXTKFKkcACiD6wpU8ZQpkwpvv/+F+6992EOHDhEaGgoTz89kMGD+zF27HB++GEpu3b95fX4pk0vYd68qUFVdmXLlub9994kMjKSKVOmM/CxZ4mNjQPg5ptv5N2pb3DXXbeyfPlq3ho3FYAiRQpTvXoVjh49xtUtbw5k+K4xdOgABj/RL8N9mlzakAkTXiEkJITHHnuWN996h9OnT1OhQjnmzJ5EixZNmTD+Fdq265xDUQfW05kos9SaN2vCxwvfo3DhQtkYlfvpWrswne/qle62kiVL8PuqbwAYMPBZtm7dkVNhZSk1ieaQuzr/m2LFivL997/w/LBRKUlZbGwcD/cdwsGDh6lZoxrXXvuvs44LDQ2lT5/7+XbxXMqWLR2I0AOqbt2LaNKkIUlJSXTv/mjKf55JSUk8//woVq78nfDwcO6449wEIzQ0lN69u/H11x8GXdl17343RYsWYdWqtfR5eHBKsgbwySeLGDr0JQAeeaRHyuMNGzi1axs3bsnZYF2oXLkyzJ37Ds8+M+i8+44c+Qz58uXj1VHjGPvmFE6fPg3Anj376NqtH0lJSbRufTVVq1bK7rADqly5MszLZJmB8/7s1/cBvl08l9KlS2ZzdO6lay37TZ40iooVy/PFF4uZPGV6oMPxmxK2HLJnzz7mzfuMd96Zcc62+Ph4tm3bCUDlyhVTHg8PD2fZr1/y+pgXKFCgAMOHj2HnTu+1SHlVxYpO376DBw+zZ8/+c7avXr0egCpVKp71eHh4OL/88hmvvfY8BQoUYMSI19OtgcuLkvtoLFj4ZcpNPbXPv3D+26xRoyrFixcDoEGDegBs2GBzKEp3atOmJRv++Ilbbm7Lnj37ePKpF9Pdt1KlCrRseQVHjx7j5ZffPGf7jh1/MmjQc/TvP5RTpxKyM+yAur5NSzZmsswAIiMjWLliEWNeG0ZYWBjPPf8qf/+dfnNWXqVrLft16tSOW25uS0zMCfo+MiTQ4VwQJWw5ZMbMedx190PM+fDjc7YVLBjJRRfVAEhJ3AAiIsK55JKL2bDB0ub62xn2wuicCtc1oqKcvgZlypRKSd5Sq1+/DgB//bX7rMfPlN1mbrjhToYPH5P9wbrIc8+9SvcH+vPJJ1953V6oUMGUn8PC8gHQsGFywrY5+wN0sfr16lC4cCGmT59L40tbs2zZqnT3ve66KwkNDeW773/m+PEYr/u8+dY7jBv/Lnv27MuukAOunqfMPpg+l0vOU2bg3PMaNazPuvUbadX6NoaPeD2HInUXXWvZKywsjBdHPAnA629M4s8/owIc0YVRH7YAM6YWr702jBIlivPzz8tZsmRZyraTJ+O5//5HmT1nodd+bcHA2q0sXbqSFi2aMnnya9x3X18OHjwMwMCBvbjyymYcO3acmTPnnXXcyZMn6d69Px9++ElQlt2y5atYtjz9m3/HjjcCsH//gZRm5gaeJtFdf/5Nr573cV2rqyhRvBhRUXtYsPALPv30f9kfuAusWPE7zZq3Zc2aP86778UXGwA2bXKakdu2bcVtt3agSpVKRB84yMKFXzJv3mfZGq8brFjxO5dnsswA4uJOcm/XvsyZ8zFJSUnZHJ176VrLXj173EOdi2py6NBhRo2eEOhwLpgStgAZ+tQAutxzGzWqVyU0NJRPP11Ej56PnbVPXFwcM9IkIsHozjt78u67b9C69dVs3ryULVu2U65cGcqXL8vGjVvo3fu/KTVxyeLiTjJr1oIARexu5cqVYdBjvQGYPXthyuPJHwjvTBlzzgCNe++9nS+/XMxddz9ETMyJnAs2AJb+mvmpS6pUcfoKHT16nI8+mkKnW9qdtb3znZ348svF3Nm551n9CPMaX8oMICbmhN6f6FrLTiEhITzq6aM7afJ0jh07HuCILpyaRAPk6quvoFbN6oSGOn+CWrWqc03Lf53nqOB08mQ8y5ev5sSJWAoWjOSSSy5OmW9oz559nDwZH+AIc4+CBSOZN3cqJUoUJzr6ICNfcfrCVKlSkRIligOwffsu2rW/i2LFa1O23MU88MAADh48TLt2rZkyJbials+nSGEnse3/aE86tG/Dk0+9SMVKjShWvDad7+pFdPRB2rVrzZtjM+7TJXI+utZ806F9G2rVqs7JkycZN/7dQIeTJZSwBUjPXo9RpGgtGjRsyfgJ06hb9yJmzXqb2//TMdChuUpmobehAAAgAElEQVSxYkVZtGgOQ4Y8ws8/L6d583YULVqbunWvYty4qbRqdRVff/0hzZs3CXSorleoUEE+Xvg+zZs3ISEhga7d+rF/vzOvWlLSaUaPnsC7787imms78c03P3LiRCyHDx/h/Q8+pGPHe0hMTOQ/t91E82Yq62QREeGA08fymWdf4dVXxxEdfZATJ2KZN+8z7rn3YcCpoaxX76JAhiq5nK413/R+qCsAH370aZ7p0+e6JlFjzAVVM1lrf8mqWLLTrl1/A7B583b69x9KYmIi/fo+wPARQ5g3//Og7teR2sCBvWjc+GLWrdvIrbd2JyHBGf20a9dfDBr0PCdPxjNw4EOMGfMC//pXhwBH616lS5fk44Xv0axZExITE3mwx0C+/vqHlO1RUXsYPGR4usevWPk7ixf/xA03XEuHm67PsH9cMEluejp27DhvvDH5nO3ffvsTK1as5vLLL6Vdu9aaMkX8pmst84oVK0qrVlcBMHt23ml6d2MN2xLgJz+/fgxAvFni1VfHAVCjelXNoZNKp05OP40xYyamJGupvfrqOBISErj00gbUrFktp8PLFWrUqMpPP35Cs2ZNOHXqFF279WPGDN/7Rq5Z63SMrqbrM8U///wDOINjTp065XWf5FG3NapXzbG4JO/RtZZ5bdteR/78+Tl06DCLv10S6HCyjOtq2IDuwFigMLAXyBOTQhUvXoxataqzceNmTpyIPWf73r37OX48hsKFC1G2bJmgm28tPcnJ6+bN27xuP3LkKNHRh6hQoSxVq1Zm+/ZdORme6zVsWI/PP5tBhQrliIk5Qee7evHVV9+mu3+BAgWIj/feJzAkJASA+HjvHxbByG7eft59kmvL0/uQFckMXWuZ16F9GwA++fR/Xv/Rz61cl7BZa6cZYyzwFVAE6GutzdxYcRdb8/u3VKhQjs6dezF/wefnbC9evBgFC0YCsGdP7lznLDscPXqciIiIdBc1Dg8Pp0wZZ5b0Y8eO5WRorle7dg2+/GIW5cqV4dChw9xyS1d+Xfab131HjBjCgP69+O67n+lwUxev+1zS6GIANm4K3qaWtFasWA0485BFREQQF3fu6LzatZ05FoNxfUfJOrrWMu+K5pcB8P0PuaKHVKa5sUkUa+1S4H6gEPBOgMPJEt9/71w43R+4y+v23g91JTQ0lPXrN50zCWww++mnXwHo2vVOr9vvuuvfhIWFceTIP6xduzEnQ3O1yMgIFiyYRrlyZYiOPkib629PN1kDWLPmD/Lnz0/Llld4bZJv1Kg+rVpdRWJiIgsWfJGdoecq3367hOjogxQqVJAeD56b6DZqVJ8rr2xGUlISn3y6KAARSl6hay1zihYtktI9JjnJzStcmbABWGvnA9OBy40x9wQ6ngs1evR4EhISuOH6a3lxxJMUKFAAcJqZevS4h6FDB5CUlHTeJV2CzejREzh16hQdO97AiBFDUmohAf797/a8/PJTZ+0njiFDHqWuqU1iYiKd7+rFunUZJ7MLF37F1q07iIiIYM7sSVSvXiVlW9PLLmH+vHfJly8fEye+H/T/vaeWmJjIc8+9Cji1lJ07d0rZVrVqJd6d+gahoaHMnDk/ZaCRiD90rWXOJY3qAxAbG4u13rvS5FauaxJNYwiQCFQ8345ut3bdRh7q/V8mjB/JoEF96NHjHrZu3UHlyhUpV64MCQkJDHzs2Qz7FwWj1avX07v3E4wf/zIDBz5Ejx73sGXLDipXrpCyoPsHH3zEqFG5fxbrrFKgQIGUIe0nTsQy7Pn/Zrj/nZ17sm9fNHd27smXX8yiadPGbPjjJzZv2U6+fPmoa2oD8NnnXzPo8eezPf7cZtLkD6hX7yL69n2AD94fx4sjnuLAgYM0aFCX/Pnzs2LFagYMfCbQYUoeoGvt/MpXcJYwTDuZel7g6oTNWhuF0zSaJ7z//oesW7eRxwf14eqrr6Bhw3ocOHCIOXMW8tqYiaxevS7QIbrSjBnzWLt2A/379+Saa1rQoIHh+PETLF78E1OnzmT+fDXRpdawQd2UBd2LFCnMlVc2y3D/5Pmd1q7dQJPL2jDosT506HA9tWtVJzY2jiVLljFt2mzee//DbI89txow8Bm+/uZHHu5zP02bXkLJkrWwdiszZy3gzTff8drfSMQfutYyVqpkCQB27857CVvI6dOnAx1DQBUIrxzcBeCHfKH5Ah1CrpSQmHdGK4m76abmu5BAB5BL6VrzT0J8lM+XnGv7sImIiIiIQwmbiIiIiMspYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwiYiIiLicEjYRERERl1PCJiIiIuJySthEREREXE4Jm4iIiIjLKWETERERcTklbCIiIiIup4RNRERExOWUsImIiIi4nBI2EREREZdTwiYiIiLickrYRERERFxOCZuIiIiIyylhExEREXE5JWwiIiIiLqeETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcTgmbiIiIiMspYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwiYiIiLicEjYRERERlwsLdACS+yQkJgQ6hFwpMn94oEPIdU6cOhnoECRInA50ALlUSKADCCKqYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwiYiIiLicEjYRERERl1PCJiIiIuJySthEREREXE4Jm4iIiIjLKWETERERcTklbCIiIiIup4RNRERExOWUsImIiIi4nBI2EREREZdTwiYiIiLickrYRERERFxOCZuIiIiIyylhExEREXE5JWwiIiIiLqeETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcTgmbiIiIiMspYRMRERFxOSVsIiIiIi6nhE1ERETE5ZSwBdgVV1xG7IldbLZLvW4PDQ2lX78HWPXbNxz9Zyu7o9aycOF7XHllsxyONPCMqcXkSaPZsvlXjh/bTvT+DSz+Zi5dutyWqePDwsJY9dvXnIqPomXLFtkcbWCEhITw7ffz2bFrZaaPebhvd47GbKfN9S3P2VazZjWOxmzP1NehfzZn5UtxrZCQEB58oAs//fAxB6M3cvTIVpYv+4pePe8LdGiuERISwi9LPmXv7nWZPib5/ZkQH8U1efT96avke97Wzb8Sc2w7B/Zv4Fsf7nnBIiQkhJ+XfMoeL9fb008P5FR8VKa+3pkyJgDRZ15YoAMIZgUKFGDSxFHky5cv3X2mvTuWzp07kZCQwPr1myhZsgTt27XmxhuupWevQXzwwUc5GHHgdOhwPbNmTiAyMpLY2Fis3UbZsqVp2bIFLVu24MYbruW+rv0yPMeQIY/QsGH9HIo4MJ5+9jGaXt6YgwcOZWr/Jk0a8dTTA9LdHhsbx9JfMk7+GjaqR+HChdix/U+fYs2NwsPDmffRFNq2bUViYiKb7FYKFypEk0sb0uStl2jZ8gq63NMn0GEG3AvDnqBZsyYcyOR1CPDkkEdolMffn764Kc09b5PdRjkf73nBYlgG19tff0bx88/L0z02MjKCJk0aAbBt+65sizErKGELoGefeYy6dS9Kd3vv3t3o3LkT27bvpGPHe9m6dQcAPXrcw5tjX2TcWy/x00+/snPnXzkVckCULVua9997k8jISKZMmc7Ax54lNjYOgJtvvpF3p77BXXfdyvLlq3lr3FSv52jQoC6Dn8jbN7fBQx5h0OOZTxYuv7wxH86dQuHChdLdZ8+efdx4/R3pbr/q6uZ8+vl0YmPj6HJ3b5/izY1eevFJ2rZtxZ9/RnHLv7uybt1GADq0b8OM6eO5845b+PyLb5g5c36AIw2cp4cO8Pm9FgzvT1+kvudN9nLPmzb1De4+zz0vWAw9z/U27b05THtvTrrbJ4wfSZMmjViyZBkjR76ZHSFmGTWJBkjjxg3o378nJ07Eet2eL18+Bg54CIC+fYekJGsAkydP552pM4mIiKB//145Em8gde9+N0WLFmHVqrX0eXhwyo0L4JNPFjF06EsAPPJID6/Hh4aGMnnSaEJCQoiPj8+RmHNS2XKlmTn7bZ4c2j9T+4eGhtK7Tze+WDSLUqVL+v28xYsXZdKU0eTLl49hz41i08Ytfp8rN6hRoyp9enfj1KlT3HTzPSnJGsDnX3zDmNcnAnB/186BCjGgypUrw7y57/DsM4N8Oi6vvz/98YDnnvdbOve8pzz3vEfTuecFg3LlyjDXj+sttZtvvpEHH7yH48djuL/7oyQmJmZhhFlPCVsAhIWFMWXya5w+fZqXXnrD6z7XXNOCatUqs3v3XhYv/umc7VOnzgLg1n+3JyQkJFvjDbTk/iwLFn7J6dOnz9n++RffAM4HavHixc7ZPnDgQzRt2pgxr0/k6NHj2RtsDmvV+ipW/b6YmzrewN69+3n2mVcy3D8yMoIlSz9j5KvPEBYWxogXxhAVtcev537m2UFUrlyR339fz4Tx0/w6R27S+c5OhIWFMWPmfDZsOLe/3rT35jD06Zd5973ZAYgusK5v05KNf/zELTe3Zc+efTz51IuZPvaxgQ9xeR59f/or+Z630M97Xl7Xpk1LNvh5vSUrWDCSN8c6x70w/LVc0VLlqoTNGBNhjBlhjNlmjIk1xmwxxrxkjCmVwTEfGGMScjLOCzX4iX40alSfUaPGs279Rq/7NLv8UgB+/fU3r9tXr17HyZMnKV++LHXq1My2WN3guedepfsD/fnkk6+8bi9UqGDKz2FhZ/cHrFOnFs88PZDNW7YzbNhr2RpnINStexGFCxdi1sz5XHF5W1YsX53h/pEFI2nQoC5//GFpd+NdjHzZvyaAi+rUpOv9dwIw5InhJCUl+XWe3KTVdVcB8Mmni7xu37Xrb14e+WZQNofWq1eHwoUL8cH0uVxyaWuWLVuVqeNSvz+fz4PvT389+9yr3P9Afz72454XDOp7rrfp0+fS2IfrLbXHHutNxYrl2bZtJ2PHTsmGKLOea/qwGWPCgW+B5kBylVEt4L/AfcaYO6y1P6dzeK6pYrq4vuGJJ/qyadMWXnxpLG3aXO11v1q1qgOwI52sPykpiajde6lZoxq1alXH2m3ZFXLALVu+imXL039Ddux4IwD79x84p9PppImjCA8Pp3fv/3Ly5MlsjTMQVq5cw9VXdmTdWu+Jf1on407yYPcBzP3o0wtKsp4f9l/y58/PN1//wM9L0u/Qm5dcfLEBYNOmrRQtWoRuXe/k6qubU7hQITZs3MKUd6azMY83C6dnxYrfubx5W9as+cOn4ybn8fenv853z7s5g3teMFix4nea+XG9JStbtnRKl6NhL4wmISF31Pm4JmEDHgeuAJYCvYHNQDNgGNAS+NoY08la+7/AhXhhQkNDmTRpNPnz56fXQ49n2F+jdBmnUvHQwcPp7nP40BGoUY1Spfzvh5TblStXhkGPOZ3dZ89eeNa2vg9358ormzF58nR+/NH7tCm53XIf/7OMiTnBh3M+vqDnrFWrOu07tAHg9TGTLuhcuUV4eDhly5YGoErlivzvqzlUrlwhZfv1119Dn95d6dvvSd6ZOjNQYQbM0l8zP41MsuT356TJ0/khj74/s0Pqe96sNPe8YOHP9ZZar173UbhwIf78M4o5F3g/zEluahLtDBwGOlpr11pr46y1P1prrwVGAhHAAmPMlYEM8kIMGNCLyy9vzNsT32fp0owvuMjICABi4+LS3Se5I2ryvsGmYMFI5s2dSokSxYmOPsjIV84071WvXoUXXhhMVNQeBg8ZHsAo856eD91LaGgoa9b8wY8/BMcHbZEiZ0bSTv9gHLGxcXS4qQuFitSkWo2mvP76JPLnz8/4cS9z3bW59haVY6pXr8JwvT99VrBgJPPTuedJ5oSFhdHjwXsAePOtd1w/0CA1NyVsNYFfrbXn1O9aa4cAw4FI4GNjTL2cDu5C1a5dg2eefow//4xKGdWYkcw0V4WGOn8+b51S87pChQry8cL3ad68CQkJCXTt1o/9+w+kbH97wqsULlyIRx59iqNHjwUw0rwlMjKCu7v8B4DxbwXPdAIREWf+KSpUqCDtOtzFov99z8mTJ4mK2sOg/z7PjJnzyJcvH8NfGBzASHOHiZ73Zz+9PzOtUKGCfJLBPU8y59Zb21OhQjmOH4/hnXdmBDocn7gpYUsE8qe30Vr7DDAZKAl8YYypkN6+bjTx7VeJjIyg3yNDOH485rz7xxw/AUBEeHi6+4SHFwAgLjb9Wri8qHTpkvxv0RyuvfZfJCYm8mCPgXz99Q8p2x/ofjetW1/NR3M/5ZNPvHcQF/+0an01xYoVITY2jk8+Dp6yjY09M/3O9BnzvI4oe9kzh1Pz5k0oUybdcVJBT+9P35UuXZKvU93zHugxkP+luudJ5t16602AM9L22LHcNSrZTQnbRqC5MaZ8Bvv0ARYB1YBFGY0edZPevbtx9dVXMHv2Qr788ttMHXPQ03etZMni6e5TslQJAKKDqNNpjRpV+enHT2jWrAmnTp2ia7d+zJgxL2V7xYrlefnloRw6dJj+/YcGMNK8qV371gB88/UPxMScCHA0Oefo0eMptd7r1m3wus/mzdtT+qVWr1Ylx2LLTSpWLM9Iz/vzUb0/M6VGjaosSXXPuy/NPU8yL3/+/FzfxlmCb968zwIcje/clLC9DxTBqT1raYyJTLuDtTYR+A+wCmgA/Aa4vnn01n93AKBz507En/z7rK+FC94DnD4dyY9Vq1YZu3krANWqVfZ6znz58lGpopPbbtu2w+s+eU3DhvX44fuF1K5dg5iYE9x6W/dzOoy2ad2S4sWLUbJkCaL+XnPOWnGlPRPFLv5mLqfio3j66YGBeCm51o1trwPg44XepxvIq06dOsWOHRkvvXX69OmU7gmnEk7lRFi5Tur35+6/15AQH3XWV+r3Z0J8FM8E+fuzYcN6/Hiee55kXsuWV1C0aBFiYk7w1VeZqzxxk3RHiRpjPsyC85+21t6ZyX3HA22B9sB3ODVuDdLuZK2NMca0Ab7EmQLE9f/Krv9jU7pz5ZQoUYz69Q1xcXH89ttaAOLiTqb8fLlnPra0Lr20IQUKFODAgUNs3bozW+J2k9q1a/DlF7MoV64Mhw4d5pZbuvLrsnPnqNu3PzrDdeOaNbuU/Pnzs379Rv755xh//RmVnWHnKdWrV6FcuTIAQTPYILUVK3+nVq3qXHbZJV63V6tWmfDwcBITE9m58+8cji532J/J9+e69Rs5+s8x/gzi92ft2jX4KtU97+Z07nmSeVdccRkAy5evPmv1iNwio2k9/pMF5890b3hrbZIx5magB9AVSLc3pbX2iDGmJfAC0A9nBKlrDRjwdLrb2rdvzcIF77F3bzTXtbo15fHo6INERx+kevUqtGp1Fd9+u+Ss47p3vwuAOR9+nOcHHURGRrBgwTTKlStDdPRBbmx751nLAqW2aNF3LFr0Xbrn2rN7HaVLl+TR/k/n2ak+skujSy4GICpqD3v37g9wNDnvw48+ofOdnbjt1g488+wr7N6996ztfR7qBsCPP/7KkSP/BCBC9/tq0Xd8lcH7c6/n/dm//9NBPdVHZGQEC1Pd827I4J4nmde4sVMHtGJlxhOMu1VGCdvzORaFh7U2CZjo+TrfvqeAwcaYkTjzteUpSUlJjH5tAi+/NJTJk16jU6euKasiPPhgF7rffxdxcXGMHTs5wJFmvyFDHqWuqU1iYiKd7+qlG1eANGxYF4D16zYFOJLA+PTT/7F06UpatGjKxwvf487OPdm+fRcAt99+M336dAPgpZfHBjBKyQue1D0vWzRqWB+AtWu990N1u3QTNmttjids/rDWHsYZiJDnjB07heuuu4obb7iW5cu/Yv36TRQvXiylX1vPnoPO268mtytQoAC9H+oKwIkTsQx7/r8Z7n9n557s2xedE6EFnXLlywLw99/+rT2a250+fZo77+rF/xbN4dLGDdiw/kc2bNxM4UKFqFmzGgDPPPsK33635DxnEkmfr/e8O3TPy7Tyyfewv3YHOBL/uGmlA0kjISGBTp260rdvd+679w7q1KnFqVOnWPztT4waNd7rovB5TcMGdVMWNy5SpDBXXplxZWpERPrToMiFKVnSGZW8J01TYDDZvXsvlze7kYEDHuL22ztSu5bTGXzRou94Y+xkTbUgF0z3vOwRGRlBwYLOWMaoXHoPC/Gn/5MxphDQHWgHGKCotbaMMaYMMAoYY639PUsjzSYFwivn7Q5g2SCv95nLLpH5dWP11YlTWl9SxM1yzULeLnMqPsrnovN5Wg9jTBPgD+B1nFGdNXAmswVntYJ7geXGmG6+nltEREREzuVTwuaZ1PYroCqwHBiAM/1Gsr04U3KEAe8YY/6VRXGKiIiIBC1fa9gGA6WBcdbaFtbaN4CUafattbusta2BN3BqSgdkWaQiIiIiQcrXhO0m4DiQ8bAVGAIcBa7yJygREREROcPXhK0SsMlaG5vRTtbaOGALZ/q2iYiIiIiffE3YYoCKmdy3NE4tm4iIiIhcAF8Ttt+ACsaYazPayRjTGqjm2V9ERERELoCvCdt4nMEEH3jW8jyHMaYVMANnHdF3Liw8EREREfF54lxjzCTgQZyEbB9QGCgEfAbUA2rhJHUfWms7Z2m02UAT5/pOE+f6RxPn+k4T54q4mybO9U+OTJxrre0JDMKZzqM8TsIWAnQEauP0c3sB6OLruUVERETkXH4tTQVgjAkHrgTqA0VxErUtwI/W2uNZFmE2Uw2b71TD5h/VsPlONWwi7qYaNv/4U8Pmd8KWVyhh812wXzP+UsLmOyVsIu6mhM0//iRsYf4+mTHmYpy1RA1QEDiCs8bol9banf6eV0RERETO5nPCZoypBEwGbvQ8lDpLPA0kGWPeBx6x1sZceIgiIiIiwc2nJlFjTHFgFc4ca4nA9zi1aseBIkBjnOWoQoCfgdbW2lNZG3LWUpOo79Qk6h81ifpOTaIi7qYmUf/kRJPoEKA6TtL2H29Nn8aYBsA8nAEJ/YFXfQ1KRERERM7wdVqPW4F44Jb0+qlZa9fjTPFxGuh6QdGJiIiIiM8JW2VgnbU2KqOdrLWbgbVATX8DExERERGHrwnbbqBcJvctChz08fwiIiIikoavCdt0oLIx5sGMdjLG3IxTuzbH38BERERExJHuoANjTEEvD78BXAeMN8bUBt5O3ZfNGFMGuA8YBiwBns7SaEVERESCULrTehhjEjN5jmM403oUwmkGTbYfiLfWVrugCLOZpvXwnab18I+m9fCdpvUQcTdN6+GfrJ7WI7MnK8rZiVqycjgjRUVERETkAmSUsNXIsShEREREJF1a/F1Noj4L9mvGX2oS9Z2aREXcTU2i/vGnSdTXUaI+McYUys7zi4iIiAQDfxZ/DwM6AfWBgpyb9IUBEUBFoCVQ8gJjFBEREQlqPiVsxpiiwA9Ao0zsHoIGHYiIiIhcMF+bRAcClwBJwLfAxziJ2RpgNs7ca8nTgfwA1MuaMEVERESCl68J2y04tWadrbXXA7cDR4G91tou1tprcBK6P4F/AZFZGayIiIhIMPK1D1tNYJ+1dh6AtTbRGLMKJznD89hGY8z9ODVwA4GuWRVsdkjSiEfJIRrxKCJ5jT5Bc46vNWwRwF9pHtsEFDHGpMzbZq39Hmeh+KsvKDoRERER8TlhOwiUSPPYDs/3tP3VdgMV/AlKRERERM7wNWFbDdQyxlyc6rFNOAMPWiQ/YIwJBaoCMRccoYiIiEiQ8zVhm4WTnH1tjHnQk5j9BJwAHjXGXGWMKQwMB8oCW7I0WhEREZEg5GvCNhNYBJQHxgMh1tojwCSgMM5UHv8AT+D0RRyXdaGKiIiIBCefEjZrbRLQEXgU+Mxamzzn2hCc2jc4M2Hum9ba6VkVqIiIiEiwytLF340xFYFqwFZrbXSWnTgbhRWopFHJIiIikmMS/Fj8PUsTttxICZuIiIjkJH8StnQnzjXG1L+wcBzW2g1ZcR4RERGRYJXRSgfrsuD8p8/zHCIiIiJyHhklUz5X12XTOURERESCmvqwqQ+biIiI5CB/+rD5Og+biIiIiOQwJWwiIiIiLqeETURERMTllLCJiIiIuJwSNhERERGXU8ImIiIi4nJK2ERERERcTgmbiIiIiMtltJZo1ax4Amvtn1lxHhEREZFgldHSVDuy4PxaS1RERETkAmXFWqL/AEeASKBsqscPAgl+xiUiIiIiHhn1YSvi5asU8BMQDwwDqllrS1hra1hry3u2DwJOABaonY2xi4iIiAQFnxZ/N8Y8CzwDdLHWzs5gv5uAT4DXrbUDLzjKbKTF30VERCQn5cTi7/cBf2aUrAFYaz8DtgF3+BqQiIiIiJzN14StAk7ftMw4DhT38fwiIiIikoavCdsuoIExplJGOxlj6gINga3+BhaMihcvxuhRz7NtyzJijm1n5/aVTJo4iqpVMyzuoKYy84/KzT8qN9+pzPyjcvNPXi43X/uwPYfTh+034HZr7U4v+zQC5gK1gMesta9nSaTZxC192IoXL8aPPyykfr06HD16jM1btlOzRlVKlizB4cNHaNXmP6xbtzHQYbqKysw/Kjf/qNx8pzLzj8rNP7mp3HKiD9toYD1wGbDZGPOjMeZtY8xoY8xEY8wyYDXO6NDvgXG+BhSsJr79KvXr1eGLLxZTtfplXNGiPVWqXca09+ZQokRxZkwfT2ioFqZITWXmH5Wbf1RuvlOZ+Ufl5p+8Xm4+1bABGGPKAmM5e0DBac7M25YIjAeetNbGZEWQ2ckNNWzG1GLdmu+JiTlBzdrNOXz4SMq20NBQfl+9mPr16nBH557Mn/95ACN1D5WZf1Ru/lG5+U5l5h+Vm39yW7nlRA0b1tr91trOQHWgFzAKmAK8AjwAVLTWPpobkjW36HL3bYSGhvLZ51+fdZEBJCUl8d57cwC44/abAxGeK6nM/KNy84/KzXcqM/+o3PwTDOXm97JRnjVCJ2dhLOdljBCDPaUAACAASURBVCkA1ATyOyHY+Jx8/uzS7PJLAVi6dKXX7cuWrQLgqiub5VhMbqcy84/KzT8qN9+pzPyjcvNPMJSb3wmbMSYfTl82AxSz1r5ljMkPVLXWbruA89YCbsBZ1mqhtTba8/jjwJNAUc+uMcaYt4BnrLW5egmsWrWqA7Bz519et+/6828AypcvS6FCBYmJOZFTobmWysw/Kjf/qNx8pzLzj8rNP8FQbn71vjPGPAL8DSwFpgFveDbVBKwxZq4xpmg6h2d03qeATcBbwNvAFmPMVcaYh4GROMnaNmADEAE8Acz35zW4SZkypQA4ePCw1+2HDp2p3i1dumSOxOR2KjP/qNz8o3LzncrMPyo3/wRDufmcsBljpgBjgHI4i76nTlPLe875b+B7Y0xBH87bHngBZ8LdCcAMoADwAc76pHuAf1lr61hrG+LU7K0EOhhjHvT1dbhJZGQEALFxcV63x8bGnbNvsFOZ+Ufl5h+Vm+9UZv5RufknGMrNp4TNGHMb0B0neWpnrS0F/J683Vr7A3CNZ/slwAAfTv8ocBInKetrrb0PZyRqNaAq8Ii1dlmq59oB3ArEeGLKtRITEzPcnnoYsq+jevMqlZl/VG7+Ubn5TmXmH5Wbf4Kh3HytYeuNM4XH7dbaRd52sNb+BHTCmebjdh/O3RT40VqbMqudZ03S5N+/8fJcUcAynFUVcq3ktvSI8HCv28PDC6T8nPq/hGCmMvOPys0/Kjffqcz8o3LzTzCUm68JWxNgm7V2aUY7WWtX4ixLdZEP5y4IeBv1uREn+Usv1oQMtuUKyW3uJUt6X3q1VKkSKT9HR2d2Kde8TWXmH5Wbf1RuvlOZ+Ufl5p9gKDdfE50InCbIzPjHx3Nv/j979x0eRdXFcfybTug91BASYOgCShMpCihVVEQEpFelqoBSRJGiiAqKgKBIka5SpYgg4ivSOwaGXkMghN4hyfvHJoGQTcwuKRPy+zxPHuLOncnZ42Zz9s4twDOGYeR86PE3gOJArJI4ck/TZ7jfC5cqRU2qLVSooN3jhXwLABAUFJxqPxkkNuXMOcqbc5Q3xylnzlHenJMW8uZowXYCMAzDyBBfo8gZoqUA+/Nr7ZsCZAHWGYbROHKJEEzTvGWa5gHTNG8+cH1XwzDqAWux9cxNdfB5WMq27bsAqFy5gt3jUY9v3rIj2WKyOuXMOcqbc5Q3xylnzlHenJMW8uZowfYrtl62L/6j3RjAC1juwLW/AWYCJYBFxH87dRawDNuepcuxbYWVai1ctAKAl5rUI1u2mN25rq6utGlj2wVs1uxUv4JJolHOnKO8OUd5c5xy5hzlzTlpIW+OFmyjgBCgs2EYawzD6AJkBzAMo5xhGC0Nw/gTaIdtyY/PE3ph0zTDI2eGvo6tMDwQT/OT2MbI9QNeNk0zdU75iLRnzz6WL19D5syZmD93Mtmz2+61e3l5MXnS55QsUYz95iEWRb4gRTlzlvLmHOXNccqZc5Q356SFvDmz+XsFbD1gBbDNGI11TeA80DRyxqilWWHzd4D8+fOybu1C/PwKcv36DfbtP4h/YV+yZ8/GpUuXqV6zCfv2HUzpMC1FOXOO8uYc5c1xyplzlDfnpKa8Jdfm79uB0th2GVgPXATCgCvANmAoUCo1FGtWcvr0GSpVqc/X474nJCSUsmVKcO9eGHPmLqTK0w0t8yKzEuXMOcqbc5Q3xylnzlHenPO4583hHrbHjVV62ERERCRtSPIeNsMwfjAM4/0Etv3aMIy1jgYkIiIiIjE5eku0HdAggW1rAZUdvL6IiIiIPMQ9rgOGYRQFOts55GcYxmfxXNMF2/6fpYGzjxaeiIiIiMRZsGFbNuM5oPwDj0UA+YF3/+O6UfdmZzkfmoiIiIhAPAWbaZoRhmF0BXo88HBbbL1mK+O5ZjhwDdgNTEuEGEVERETSNIdmiRqGEQ78bZpmjaQLKXlplqiIiIgkJ2dmicZ3S9SewtjZhD2KYRi5gPOpfecBEREREStxaJaoaZrHgfOGYQw0DONfwzC8HmoyAThrGMYgwzAcLQZFRERExA5H12HzAlYAw4DiQLGHmuQDcgIfA4sMw3C4y09EREREYnJ0Hba3gTpAMPAasO+h4zWA+tg2Z68PdH3UAEVERETSOkcnHezG1rNW3jTNf+NpVxbYDmw3TbPSI0eZhDTpQERERJJTcmz+XgTYH1+xBmCa5m7gIFDK0YBEREREJCZHC7abgFsC297BtiabiIiIiDwCRwu2A0BxwzBKxNfIMIwAbL1r+50NTERERERsHC3YfsS27dQvhmEUt9cgslhbENlu9qOFJyIiIiKOTjpwB/4EnsZ2u3MTsBfbVlQZgJJAVWy3TbcA1U3TvJO4IScuTToQERGR5OTMpAOHCjYAwzCyAmOB1tzf5D3ioe9/ArqZpnnJ0YCSmwo2ERERSU7JUrBFMQwjH9AACAByADewjXFbZZrmIacumgJUsImIiEhyStaC7XGhgk1ERESSU3KswyYiIiIiySzODdoNwziHbTxaVdM0jzzwmCMiTNP0eYT4RERERNK8OAs2bJu4RzzUJqeD19ftRhEREZFHFF/B9mzkvyfsPCYiIiIiyUSTDjTpQERERJKRJh2IiIiIPIbim3TQJjF+gGmaMxLjOiIiIiJpVXxj2KaROJMGVLCJiIiIPIL4Crbt2C/YcgB+kd8fBXYDlwBvoARQJvK8jcScsCAiIiIiTnB08/c82DZ8B2hrmuafdtpUAOYCWYEqUWu4WZUmHYiIiEhySo5JByOB/EBje8UagGma24HGQHbgM0cDEhEREZGYHC3YGgL/mqa5O75GpmmawB60bpuIiIjII4tvDJs93g6ckxFwuMsvuXm5e6R0CKmOp6ujLxsB8M2YO6VDSHX2XdQwWGdcP/1XSoeQ6mQsUDOlQ0iVymYvnNIhpBmO9rDtB4obhlEtvkaGYbwIBGCbkCAiIiIij8DRgu1bbL1miw3DaG0YhteDBw3DyGgYRk9gNraZomMSJ0wRERGRtMuhe1umaf5gGEZdoDm2ddq+MwzjGHAd2y3QwoAbtqJutGmaixMzWBEREZG0yJnBSC2BdUB/bOuxFXvo+F7gQ9M0Fz5aaCIiIiICThRspmlGYLs1+q1hGEWBokAW4KLtsHk0cUMUERERSdseabqfaZoHgYOJFIuIiIiI2OF0wWYYRhmgPmAAmU3TbGYYRkagGTDbNM3biRSjiIiISJrmcMFmGEY2YArQJPIhF+7vORoQeexjwzAamKa5J1GiFBEREUnDHFrWI3IZj1XAS8A1YAkQ9EATF2wbwecH1hmG4ZtIcYqIiIikWY6uw9YDeBL4CyhimubLQPQkA9M0d2KbOboO20SE9xInTBEREZG0y9GCrSVwD2hlmmaIvQamaV4BWgF3gXqPFp6IiIiIOFqwGdg2fz8dXyPTNIOwbWOV39nARERERMTG0YItHEifwLZugGaKioiIiDwiRws2E/A3DMMvvkaGYQQAJbH1somIiIjII3C0YJuFredshmEY2e01iHx8VuR/zn+E2EREREQEx9dhmwC0AJ4B9huGsRrbhu8YhvE2UAJoCmTDtqfo+MQLVURERCRtcqiHzTTNO9hmfv4K5AReB/JhW3/tc6ATtmLtL+AF0zRvJWq0IiIiImmQM5u/XwReNAzjSWy7HZQEMgPXse0rusw0zXWJGqWIiIhIGuZQwWYYxlvAPtM015qmuQ3YljRhiYiIiEgURycdDAKWGoaRNSmCEREREZHYHC3YsgP7TdO8lBTBiIiIiEhsjhZsO4GihmHkSIpgRERERCQ2RycddAB+A9YbhjEa2AicAeKcDWqa5g3nwxMRERERRwu2eUAEUBSYnID2EU78DBERERF5gKPFVGkH27s42F5EREREHuJowVY4SaIQERERkTg5VLCZpnk8qQIREREREfseaXyZYRjlgCJAFuA8EGia5sHECOxxVbJkMfr370GNmlXJlCkjx46dZPHiFYz/5gcuXrxs95zNm1dSqnTxOK/5zz9bqFunWVKFnGJcXFxY9cdPFPb3pUihSnbbzJk/mXoNnovzGqdPB1PaeCbW4y83bUDb9q9TtmxJMmRMT0jIBf7+ayNjv5zE/n2p+yX8xFOlmbp4IsFB52hQsel/ts+UJRML1s0kd55c1K/4CkEng6OPvdi8AcO+Gpygn7vln+10eqWH03FbRYUKZXmvfw+qVatE5swZOR0UzPLla/j88wmcOXPW7jlvtGrKm2+2p3Tp4ty+fZtduwL56uvJ/Prr78kc/aPbu+8A3/84n+279nLtxg1y58xBzWqV6diqGblzxV4goHv/D1m3fnOc1/PJlYM1i2bGevzvjVuZPncB/+4/yM1bt8iTOxfPVa9Kp9avkS1rFrvXCg8P55elK1m0fDWHjx7n3r0wChcqQNMX69H8pYa4uKSuUTjZs2flTNCeeNt88unXfPTR6DiPj/r0A/r06UL5CnUIDDQTO0RLKftUaSYvHMfZoHM0qdw81vEs2bPQvscb1Kz3DLny5OT82VC2b9zJ9G9mcfzwSbvX7Du8N807xP8+WaXgs4SFhSXKc3gUDhdshmG4Am8C72PbR/Th4/uAD0zTXPjo4T1eGjV+nunTx5EunRfXr99g//6DFMiflwEDetOqVVNebNyGgwePxDjH3d2dosX8uXv3Llu27LR73b179ydH+Mlu8JB3eKpiOUJDL8TZpmSpYgBs3rSDcDu/UCHnQ2M9NnHyaF5v+TIA586dx9x/CP8AP5q3eIkXX6pHx3Z9WLFsdSI9i+Tl4enBR18OxM3NLcHn9Pu4F7nz5LJ7LDTkAjs27YrzXBdXV8pVLAPAqWOnHQvWgho2rMNP87/H3d2d0NCL7Nt3EH//QvTs0ZFWLZvSoGFLtm/fHeOcEcMH0K9fd8LDwwkMPIBXOi9q1qxKzZpV+eij0Yz85KsUejaO+/PvjfQeOIywsHCyZM5EgJ8vJ0+fYdZPi1m6cg2Tx4ygdIliMc45ePgYAE+UKo6rW+yVorJnjb3O+pSZ8xkzcarteLas+PkW4NiJU0yfu4BVa/9mxoTR5M2TO8Y5t2/foffAYfy9cSuurq4U9i3AjZu32HfgMMM/H8/WHXsYPfT9VFW0lY78IH7+/AXMA4fstjlx4lSc57/wfC169OiQJLFZjYenB4O/eC/O9zZf/wKMnzeGPPl9CAsL4/D+I3in96Zx8wbUfbE2g7sPZd3Kv2OdV6S4PwD79xzg1k37C15EREQk3hN5BI5uTeUCzAFexTah4Aa2/UOvYttPtBi2vUV/NgxjtGma7yduuKlXoUIFmDJlDOnSebFkyW9069qPy5ev4OrqysBBvRkwoDcLF03jyQp1uX37dvR5xYsXwdPTk3/37n8se9Hi0n9AT97p92a8bTJlyohvoQJcuXKNF2onLDcdOrXk9ZYvc+XyVbq/+R6/LlkFgLd3OkZ8OpD2HVsyecoXVCxXl+Dgc4/8PJLbW/064V/ML8Htn65VmSbNG8Z5fP0fG1n/x8Y4j3fs1YZyFctw/PAJPvsg9RQm9uTPn5dpU7/G3d2dESPGMnzEGMLCwvD2TsfXX42gbdvmzJ49kVKlakR/2m7QoDb9+nUnNPQijRq/wbZttuK2cePnmTVzAkOGvMvaP9ezYcPWlHxqCRJ8LoT3Px5NWFg43dq1oFv7Vri7u3Hz1i1GfDGBRct/p++QT/h1zve4u9v+aF67fp2g4HNkSO/NzElfJqhY2n/wCGO/nQZA3x6daPv6K7i4uBB8LoTeA4bx7/6DfPDJWL7/amSM876c+AN/b9xKHp9cjP9sKEYR25DqP9dvot+Hn7JyzV/UrFaZxi/E3eNuNWVKlwBg/vzFvP3OEIfOrV/vOWbP/hZ397SxEEPXvh0oXLSQ3WOurq6M+m44efL7cPTgcfp1GBjdo1bjhWcYMWEIn076mJZ12nP0YMyRXQGRBVuPFu9y+YL9u1xW4ejCuR2BZtgKtA5ANtM0y5umWcM0zXJANqALcA3oZxhG/USNNhXr2asTGTNmIDDwAG1a9+Dy5SuArYt/+LAxrFu3gcKFfXnrrXYxzitVygAgMJXfpkuo3LlzMnPORAYM6v2fbaN618z99j+Z2vNm9/YAjBwxNrpYA7h58xbv9vmQrVt2kjFjBtq0j93dbnXFyxSjdbcW3LwR57KIMaTPkJ4PPn8vwe0fVqpcCd7s25GwsDAG9RzGjeupe8nFFq+/TJYsmfnzz38Y+vHn0UXZzZu36N5jAKGhF/EvXIhatZ6OPue9/j0BGDT4k+hiDWDp0lUMHz4GV1dX+vdPHbeJl61ay7XrN6hYviw9OreJLsq806VjSL8eZMmciVNBwWzefv95HojsXQvw801wz9ayVWuJiIigWuUnadeiafR5eXLnYsSgdwHYuHUHZ0POR59z8vQZ5i5YirubG99+Piy6WAOoVa0ybV9/BYCFv64iNYka6hIYeCDB53h6ejJkyLv88ssPpE/vnVShWYpRphitujaPswesZr3qFCnhz+1bt3m7zXsxbn/+9dvfTB8/G3cPd3oP6R7jvFx5cpI1exZCz4VavlgDxwu2rtjWVnvJNM1ppmneffCgaZq3TdP8HmiOrQeuT+KEmfrVrl0dgEmTZnD37t1YxydPmgFA8+YvxXi8VCnbL/S+fQn/hU6tnn3uGbbsXE3DxrberaFD4h63AVAysphN6JizvHl9KFLU9ka/ZOHKWMcjIiL4fdU6AJ54opQjoac4d3c3Ph47CCIi+G7stASd8/aQt8hXIA8TRn/n8M9zcXFhyOj38PD04KcZi9iz/V+Hr2E1Z86c5ZdffmXKlFmxjt25c4fDkcVJgQK2kSABAX5UrfoUd+7cYe7c2CNApk6bC0DdOjXIkiVz0gWeSHLlzMHzzz5DsyaxP2d7enriG/m8g8+FRD8edTs0wN9+z4c95yILsaL+frGOFfEvhJenp+3nnL3/c5av/pOwsHAavfAcRez8rJcbPk+vLm15udHzCY7DCkpHvr8HJvD9PW9eH3bv+oNBA/tw79493ur+XlKGZwlu7m4M+fJ9IiIimDJ2ht02VWpWBOCvVes5fTwo1vGfptl+P6vUqkiW7PfHR0bdDj1iHkvkqJOGowWbAZimaf4ZXyPTNFdiu1X6lJNx2f/hhpHdMAzfxLxmcilYMD8AO3futXs86o9ByVLF8PZOF/146TJpp2AzihchY8b0zJ29kKcrNYhzzF6UqE+nCS3Yrly5SotmXXi3z5A4B49niPzEGtW7kFp07N0Wo1RRpn4zk4P7/rvH8cmq5Xi19Uts27CTn2csdvjnNX6tPsXLFOPK5auMH5WQNbStb9bsX2jRshvz5sfOR/r03hSNLPajflcrVSwPwJ49+7hx42asc0JCQjl85Bienp5Urlwh6QJPJC/Wq82XwwfRoG6tWMdu3LzF8ZO2MYpRhRvAgcNHAShSOOEFm0/unIDt1ujDTpwK4vadOwDk8bk/rnLTVluv3rPVq9i9Zv68PnRp+3qquh0KtklokPAetly5clC4cCE2bNhK1acbMWXK7KQMzxLa92pNsVJFmDF+Nof2HbbbJk9+23jH/Xvs5/HyhctcuXQVNzc3SpS5PwazSMkAAA4fOJrIUScNR29+3wLCE9j2Bom/cO5XQAtS8e4J7nEMmHT3sD0lNzc38ufPy6FDthdQ1C3Rc2fP07t3Z56uVokM6b05cvQEP81fwv/+F/f4otRm+7Zd1KzWhL179iWofdQt0ZMnT9OhU0tq1HqarFkzE3Q6mKVLVsWaOHD9+g1Wrvgjzuu5uLhQt96zgGO3WVNakeL+dOrVhiMHjjF57DSqRn7ajItXOk8++nIgd27fZWjfTx0eUOvh6UGP97oAMGPiHK5cuup07KmBYQTw5Zcfky1bVtav38zff28CbD1sAMeO2Z99BnDi+GkC/P2i26ZGR46f5JMxE7ly9Rrly5bkqXJloo9F9bDl88nN3IW/smnrTq5cvYZPrpzUqVWN56pXjXW9JvXrMGPeIjZu3cGP8xfxRrMmuLi4EHrxEh+MHAPAczWq4pMrZ/Q5h47Yfo5/IV+uXrvOomWr2LpzLzdu3iTAz5dmTeoT4EDRaAX+/oXIlCkjZ86cJXeuHLz7Trfonv3duwOZOnUOhyLzG+X8+Qs0bdqBX5elvtnHzggwCtO+5xscPXicKV/NoHKN+PuA4pts5Rb5ITxvgTzRj0X1sJ08eooGr75A1WcrkSNXDi6cv8D61Rv4bdEawsMTWvIkPUcLn9+B1w3DqGaa5vq4GhmGURQoAyTFTNHUMwXoAceOnaREiaKUKl2cjRu3xTpeonjR6O+zZrN12WbJkjn69suixdPJlCljdJtngY4dWzJjxnx6dB9giSnHj2rzph0OtS8ROVtt/LejYuQGoEWrV/j9tz9p36YX1xM4tqpdh9cpUcL2/+Gn+UsdiiWluLq6MnTMQNw93Bn67ifcvRP7dvvDer7fDd/CBfhqxESOHz6Bt4PjYOq/XBeffLm5cf0G86b94mzoljd40Nu0eqMphf18cXV1ZenS3+jc5d3o4zkjl7gIvXAxzmtcvHjJ1jZH9qQNNglM+GEWS1as5vSZs0RERPDsM1UYNvDtGG0OHbUN4B404ktu3IzZy7hk5RqqV3mKL4YNjDHWKqBwIcaOHMzHn41j1FeT+P7H+eTMno1jJ05x5+5dGtatxYf9e0W3v337Dhcu2cYXBZ8LoVPv9zkbcn/294YtO5i74FcG9+3Oqy+mnmHTUbdDs2TJzPbtq2NMHnj++Vr06tWJt98Zwvff379FHxQUTFBQcKxrPY5cXV354Mv3cfdwZ3jfUfG+twWdOANAkRL+do/75M9NhozpAciUNVP041Ht33q/S/TxKC+8VIfmHV/lnbbvc+F83L/jycnRW6J9gdPAIsMw7E4tMwyjNLAEuAQk6Aa7YRhhCfkCWtppf8/B55Aifltp69np3bsznpFjNKK4uLjQu3fn6P/29PAA7k/5Bti+bTfPPfsKObIb+BeuyHv9h3Hz5i3atHmNjz/unwzPwFoKFMgbXdgeO3qCV15sR/7cZShc8Ene6tqfC6EXqftCLb75dlSCrlel6pOM+HQQAHNnL2TP7sAkiz0xtXmzBaXLl2T+tAXs3BL/ek4AZSqUomXnZuzfe4DpE5y7ndKiw6sALJ677LHuXatevQoB/n64utreJgMC/KhZ4/6EA+90tqELN+MYCP3gsQeHOaQWW3fs4VRQcHQP7IlTQWx5YEmTM8HnuHL1GgAF8+dl0pfD2bx6IetXzGf4wHfIkjkT/9u4lcEjv4x17ZzZs0VPHAi9cBHz0BFu37mDp4cHuXPljNHre/3G/Q9c/T/6FC8vL779Yhjb/ljM6oUzaNP8Ze6FhfHx6G/YtC3+YRRWEjXcJX16b374YQ5lytQkYyZ/SpWqznff/Yinpyfjvh5Jg/q1UzjSlNGqW3NKlS/Bz9MXsXuL/aFEUf5eswGAZ+vXwK9I7J7Wtt1bRX/v8cDdrKi2ly5cpn+nD6hVrB61itWjf8fBBJ08Q6nyJfh86sjo94CU5mgUHwDbgRzAEsMwjhiGMd8wjEmGYfxoGMY2YBe25T1uAXMNw9j80NcmO9c9i63nzAXbLde4vqI8+Jg1Fkj5D+PGfc/58xcICPBj0aJpPPFEKdsaa0X9mT3nW/wD/KLHwdy9a6tBL168xDfjpjBhwlQaNXqDTZu2c+vWbc6eDeGbb6bQsYNtTkf3Hh3Inz9vij23lBAeHsG4sd/x4/SfqF/3ddb+8Tc3btzk0sXLzJm1gGav2GYvvvRyfZ6qWC7ea1WuUoF5P3+Pt3c69u07SL93PkqeJ/GIfAsX4M2+nThzKpivRnz7n+09PD0YOnYgERERfPTOJ071ypapUIqSTxQnPDycmZPnOxN2qtGl67tkyhxA6TI1mDBxGsWLF2XOnG9p9mpjgATdKol6o7fKOk6OGDbwbbb9sZils7+jxSuNOXL8JO98MJIVq20Tc1xcXWjXoikvN3qeHyd+TrXKT5LeOx1ZMmfipYZ1+faLYbi6urJq7d/s2nt/mMP6Tdto81ZfNmzZQe+u7fhzySy2r13M1G9GEVDYl6mzf6Zb3w+4Fbm80e0HelZu3rzN5DEjeKbKU3h5eZIndy769+pCw+efJTw8nK8ilwtJDXbu2Mt33/1Inz6D6dlrIAcOHuHu3bscOnyMHj0HMmHCVFxdXfn004QtXP04KVi4AF3e7UDw6bOMHznpP9uvX7ORnZt34+HpwVezPqNa7Sp4enmSPWc2uvbrQNM2Tbh0wdbbfe+e7X3PK50nsyfPZ/nPv9HxxbdYu3wd16/d4Pq1G6xd8Rfdmvbm+rUblHmyFLUb10rKp5tgjt4S7cb9AskF8Iv8sicfdhbWxX6BVQqYCLwGbATamqYZa0SqYRgzgRamaXo4FLUFBAeH8FqzTvz08xRq1nqafzYsiz529eo12rXrxYQJo0if3purV229FoGBB3jvvWFxXnPx4pUcOHCYYsUCqPt8TaZNnZvkz8MqgoKCGTI47t6z7dt28+faf6hdpzr1GjzH1jgmMNR9viY/zPiajBkzcPTICV5t0p5r164nVdiJ6qMvB5LO24sR73+eoCU1ur7TgYBihZk6fib7dju3InrdxrYxfnt3BHLqeOpfKDc+x4/bFiw9cOAIffoMJiwsjJ49OjJ8xAB+WbCMa9dtr5N06bzivIaXl603Pb5eOKvKn9cHgMKFCjDo3bdwdXNl1k+LGfvtVJ5/9hny5M5F3x6d4jy/TEmDKk+V45/N2/lz/SaeKF2Cu/fuMfSzr7lz5y5vv9mejm+8Ft2+YvmyTB03ilfb92DH7kB+WryC1q+9RDqv+3ckGtd7jgL58sT6WV3aNGfZqrXsDjQJvXiJHNliL9ZrNctXrGH5ijVxCXurbQAAIABJREFUHh/12Te89VZ7DKMIRQL8Yo1ne5wN/uI90nl78en7X3DjeuwJPfa833kIX88eTbFSRRn742fRj4eHhzP165n4FfGldqNaXL9q+729cf0m4z+Je8LUmVPB/LZwNa+0fpEadavx++K4xz8nF0cLtvZJEYRpmhexjY1bDIwDdhmG0d80zYkPNU19H1MfsGnTdiqUr03nLq2pGNnrs3PnXn6YMoezZ0PImtU29d+RBVt3795HsWIB+PrmT5KYU7O9uwOpXad69Azdh73Rphljvh6Gu7s7Bw4c5uVGbVPN+JDXOzTlyarlWL5gFf9b/c9/tjdKFaVd91acOHqKiaO/d/rn1qxbDYDfl651+hqp1ejR4+nZoyOF/Xzx9c3PhVDbuJbs8RQH2bNnA+zvuJHadHrjNWb9tJjTZ85y5myI3cLpYcWL+vPP5u0ERb6n/bv/IEHB5/Dy9KRN5NppD8qQIT1vNGvCJ2O/ZdXa/9H6tZfImCE9Li4uREREUCygcKxzAAoVLIC7uzv37t0j6MzZVFGw/Zfg4HOcPRuCj08ufAsVSDMFW7P2r1ChyhOsXPg769ckfFJdaMgF2jboSuPX6lP12cqkz+jNySOnWDp/JYE79zFpwTgAzp9N+O/igX9tKxDkKeDj2JNIIo5u/j49qQKJvP4cwzDWAVOA8YZhvAx0ME0z7r05Upnz5y/wycjYK8KXK18ad3d3goKCuXTpSvTjLi4uuLu72127zXbc9u+dBAw2fxx5enpyJ3IZgIdFLchp73ivPp0ZOtw2xHL7tt281rQToefj3gLLauo0svV0NXjleRq8Yn/tqfwF87Ir2FbMLZ63DA8Pd3wLF2DzsT/jvO6KLQsA+KD3cJbMWx7jmG/hAtFjPn7/9fEr2LJmzUJAgB/79h2wu0xHcPA5rl27TsaMGcidOxemaVtioFChgnFe07eQ7cPC4VTwx/bylaucOB1EgF8h0tsZc5crZ3a8vdNx8+YtQi9cpEC+PERERHD37t1Y43KjRN0Jjho3FBRsW06nQL48eMSxQr+fb4HItuciz/Ugf14fTsXzYcrF5f57YWpaksfd3Z3w8PA4b6/ffw9LO+/vtRvWBKDey3Wp93Jdu23yFczLlqC/AHix0mucOWV7bdy7e4+Fs5aycFbMSWMuLi4UjZxgcNiMuYSHp5cnd27H/zfk7h1rDJW33PIYpmkGAfUNw3gT+AzYaxhGH9M0p6VsZI/m6acr8tRTT/DPhq12b8/VjxxY+r+/7n+imDr1K15p2pDp0+fTq+dAu9ctU8a2tUlqWoYiMXw4tB/de3Xgr3UbefUl+x2/pcuWBOCAGXPtnq5vtY0u1tb+8TetW7yV4JmkVnFo3+E4l4jJnDUTAYZt1e/AXbZ9Zo8fPhnnnqAP7ge6d+c+7t6+Q2hI7OK17FOlATh1/HT0G+TjZNfOP8ib14fXX+/KgoXLYh3PmjVL9GzHM2eCOXvWVlCULVsCLy+vGFvKgW3NLP/ChQgLC2Pr1rj3Y7WKJm905XzoRb4cPpDnn60e6/jlK1e5dcv2HHPnzMGYiT8wfc4CKj35BJPHjLB7zf0Hbb97/oVsy2dmTG+biRd68RLh4eF2B3NHFXVRbcF2e/VUUDD/7re/5mJQ8Dnu3r2Hq6sr+fJYozfkvxw6tImCBfLRuk0P5ttZ+y9vXh9yR65ZZ5pp5/390P4j0UtwPCxzlkz4G4W5fet29LCOO7fvUMAvP08/V5kLIRdZbaf3v3zlsmTKkomzQec4edTW//Nq25d4+6MenDkVzKvV37D784qVKgLAsUPH7R5PbpYr2KKYpjnRMIxVwAxgimEYTQH7H+NSgYoVyzHyk0H89NNS2rXtGeNYpkwZ6dTJNovlu+9mRj++d+9+XmvehEaN6jJ40CdcuRJzRl79BrUpViyAK1eusnr1X0n/JCxkz55APDw8qPZMJQoWzMfJkzFXty5dujg1a1UlLCyMJYt/i368Zq2nGRk5G3Tl8j9o+0aPOHvorOzTQWPiPFaj7tOM+/FzzodcoF2T+/uxTvna/irh3um92XjENpamX+dBBJ20X4wVL21bRmXvjoStk5fa/PnnP7Ro8TIdOrawW7C92a0trq6u7N27P/r1tmPHHsqXL0PLlq8wdeqcGO07tG8BwMqVf3DpkvW3valc4QmW/f4nPy9Zabdgm7vgVyIiIijq70fePLkxivpzLyyMrTv3EBR8NlahtP/gETZt24Wrqyt1a9lupZcrUxIPD3cuXb7C2r83UvuBWbdgm5zx62+2P7hPlb+/3lu92jVYsXodq9b+Tc8ubWKs0RYVG8BT5cqQJXMmUoN9gQcoWCAfb7Rqardg69Pbttbhur82EBKS+m+pJ9Tng+Pek/iZOlUZM2MUoSEX6PzS/S3fSuQ16De8D2eDzrF2+V+xJlS1fqslAAt+XBL92P49B/D08qRQgC+lK5Rk7/aYKwPk9MlB3Sa2jhR7RWBKsMZc1TiYtnsO1YHBQN3Ir1Rp6dJV3L59m6ZNG9Ks2YvRj/v45GLevMnkyZOblSv/iLFJ9PTp87hw4RI+PrmYNv1rckWu+wRQp04NJk/+AoBPP/maq5HT69OKX5f8zpHDx0mXzotpM7/Bt1CB6GPlK5Rh9vxJuLm58cP3szkeubCpu7s7X4+3TdEO/NekfZueqbJYSylGKdsadea/j+e+tl98MYF79+7xfN1ajBwxMPo2n4uLC507v8HgwW8THh7OwEH3NyX/7LNvbP+O+oAaNe4vEtuoUV0GDepDeHg4oz+fkLxPxEntWzXDzc2VfzZv58sJU6J/N8LDw5m3cBkTf5iFi4sLb79p69GuU+NpCubPa5tAMGhEjFuWe/aZ9HxvKOHh4TR/qSEFI2exZ86UkRav2GbZfjTqK/63YUv0OTdu3mLoZ1+zbddevNN5Re8PCvDsM1V4onQJbty8Sfd+H3Li1P0PaCtWr2P2L7Y/xF3app49gMeMtc1+fOGFZxk27D08IpdzcnV15e0+XenVqxP37t1j0AOvN7Fv326TE0dO4ZMvN30+6h7dQ+fp5UmfId15pk5Vzp8NZd6Un6PP2bs9MPquw8fjBkf3poFtlupXM0eTMVMG/vf7P2zfYI3lYlxSy3RzwzCeAEYAGUzTfDaxrpshvV+yJaBbt7Z88eVQwLaQ7uXLVyhevAheXl5s376bBvVbxiq8nnvuGebMnUTGjBm4des2Bw8cIWOmDBQubLvF8P33s+jda1ByPQUAPF2Tp2O2WvXK/LpiFqGhFyhSqFKs46VLF2fB0unkypXDNh3+0DHc3FwpVsy23cjK5X/QplX36PF/r7zakCnTbJ/ejhw+zrkH9ip82O7dgbzX9+NEfT6+GXMn6vXiEtXDdvrkGRpUbPqf7R/sYatf8ZU4e9gW/jUb/2J+DOw+lGW//Ga3TWLbd/FEsvycKG3avMbECaPw8PDg8uUrHDp0lAIF8uHjk4t79+7Rt99QJkyYGuOcSd9+Tvv2rwMQGGji4eFB0aK28TIffPApoyKLuuR0/bRzPe4Ll61i6KivuRcWRsYM6fEtkJ/gcyFcuHgJNzdX+vfsQqtmTaLb7z94hC59BnLh0mXc3dwoVDA/4eHhHD1hu+1Us1olxo4YHF2MANy9e5feA4fz1z+bAdsWVFkyZeLYiVPcvnMH73RejB76PrWeibkN1dmQ83TqNYCjJ07h5uaKv58vN2/eii4Ue3ZuQ9d2LZx63gAZC9R0+lxn9e/fg2Ef24ZnXLp0mcOHj+Prmz/6Pa1rt37MmhX/4tS3b9k+kJavUIfAQOdmfz+KstntTwRJClE9bEEnz9CkcszivOQTxZm8cBxe6by4GHqJM6eCKeiXn0xZMnHpwmW6vdqbw/tjLj7hky83E38aS8HCBQgLC+PUsSDu3L6Dv+GHm5sb/+7YR/fX34meWZqYtgT95fAmAJa9Jfow0zR3AY1SOo5H8e230zkdFEz37h0oV64UefPm5vChY8ybv5hvxk2JHh/yoD/++JuqVRrwzrvdqF27OkbxAK5evc6a1X8x+buZ/Lp0VQo8E2vYu3c/z1RuSK+3u1Cv/nP4+xfi1s1bbPhnCzNn/MzsmTHf6KpUvb+tiX9AIfwD4t7K5t5jsHNEYssauWnyueC4C93UbsaM+ezZs49+fd+ievUqlClTgvPnLzBv3iK+HDOJHTtiL07ctVtf1v+zmS6dW1OqlIGLiwsbNmxl/PgfmP/TEjs/xbpebvg8xQIK88Osn9iyYw8HDh8lW5bM1K9Tk3YtmlLqgR1ZwDYLdMGMCfww62f+XL+JE6eDSOflRYWypXi50fO81KBu9MDtKB4eHnwz6kOWrFjDouWrMA8d5XzoRXLnzE7VihVo37Jp9MSDB/nkysn8qeOYPmcBK9f8xclTZ/D29qJa5Sdp0/xlqlV+MklzkxQ+++wbNm3aRs8enahS5UnKlClOSMgF5sxdyBdfTGRPArfpEwjctZ/2jbrRsU9bKlQtR7GSRQg5e57fFq1h6tc/cu5M7Pets0HnaP1CJ1p1a85zDWqSv1B+wsLCMPceZOWC35k/dQFh96zztyDV9LAlleTsYXtcJFcP2+MmuXrYHifJ3cP2uHC2hy0tS4ketsdBcvawPU6c6WGz9Bg2EREREVHBJiIiImJ5KthERERELE4Fm4iIiIjFqWATERERsTgVbCIiIiIWp4JNRERExOJUsImIiIhYnAo2EREREYtTwSYiIiJicSrYRERERCxOBZuIiIiIxalgExEREbE4FWwiIiIiFqeCTURERMTiVLCJiIiIWJwKNhERERGLU8EmIiIiYnEq2EREREQsTgWbiIiIiMWpYBMRERGxOBVsIiIiIhangk1ERETE4lSwiYiIiFicCjYRERERi1PBJiIiImJxKthERERELE4Fm4iIiIjFqWATERERsTgVbCIiIiIW5xIREZHSMaQod8/8aTsBIiIikqzu3Tnt4ug56mETERERsTgVbCIiIiIWp4JNRERExOJUsImIiIhYnAo2EREREYtTwSYiIiJicSrYRERERCxOBZuIiIiIxalgExEREbE4FWwiIiIiFqeCTURERMTiVLCJiIiIWJwKNhERERGLU8EmIiIiYnEq2EREREQsTgWbiIiIiMWpYBMRERGxOBVsIiIiIhangk1ERETE4lSwiYiIiFicCjYRERERi1PBJiIiImJxKthERERELE4Fm4iIiIjFqWATERERsTgVbCIiIiIWp4JNRERExOJUsImIiIhYnAo2C8maNQtffD6Uwwc3cf3qEY4d2crkSZ/j65s/pUOzLOXMOcqbc5Q3xylnzlHenPM4580lIiIipWNIUe6e+S2RgKxZs/DXukWULFGMK1eucuDgEfwL+5I9ezYuXrzEc3VeZc+efSkdpqUoZ85R3pyjvDlOOXOO8uac1JS3e3dOuzh6jnrYLGLSt6MpWaIYy5evwdfvSapUbUDBQk8ybfo8smXLyqyZE3B11f+uBylnzlHenKO8OU45c47y5pzHPW/qYbNAD5thBLBn159cv34D/yKVuXjxUvQxV1dXdu5YQ8kSxXjt9S4sWLAsBSO1DuXMOcqbc5Q3xylnzlHenJPa8vZY97AZhuFmGEYJwzCeNAwjT0rHk5hatWyKq6srvy77PcaLDCA8PJzp0+cB8FqzF1MiPEtSzpyjvDlHeXOccuYc5c05aSFvlinYDMP42DCMV+w87mUYxmjgArAX2AycNgxjh2EYTZM7zqRQqWJ5ADZs2Gr3+KZN2wF4plqlZIvJ6pQz5yhvzlHeHKecOUd5c05ayJtlCjZgMPDSgw8YhuEFrAbeATICp4CtQCjwBDDfMIzPkjnORBcQ4AfAsWMn7R4/fuIUAHny5CZDhvTJFZalKWfOUd6co7w5TjlzjvLmnLSQNysVbPb0A6oBu4EKpmkWMk2zsmmauYEGwHHgXcMwmqRkkI8qV64cAISGXrR7/MKF+927OXNmT5aYrE45c47y5hzlzXHKmXOUN+ekhbxZvWB7A7gONDFNc9eDB0zTXAnUBe4AvVIgtkTj7Z0OgJu3btk9fvPmrVht0zrlzDnKm3OUN8cpZ85R3pyTFvJm9YKtELDVNM0T9g6apnkYWAtUSNaoEllYWFi8xx+chpzWZ/VGUc6co7w5R3lznHLmHOXNOWkhb1Yv2E4Bl/6zFXgldSBJ6fr1GwCk87L/NLy8PKO/f/BTQlqmnDlHeXOO8uY45cw5yptz0kLerFaw5X5oyY4VQHXDMLztNTYMIy/wDHAwOYJLKlH33LNnz2r3eI4c2aK/DwkJTZaYrE45c47y5hzlzXHKmXOUN+ekhbxZrWCri23JjiDDMJYC6YHswBTDMNyjGhmG4WoYxrPA70AGYGaKRJtIbHd2oVChgnaPF/ItAEBQUHCq/WSQ2JQz5yhvzlHeHKecOUd5c05ayJuVCrY2wFhgHZAOaAh0iDzWHCjyQNt52Jb7KAn8DYxJvjAT37bttvkUlSvbH4oX9fjmLTuSLSarU86co7w5R3lznHLmHOXNOWkhb5Yp2EzTnGma5rumaT5nmmZ2wB9oCgwHlgNHHmh+EdtabJ8AL5imeS/ZA05ECxetAOClJvXIli1md66rqytt2rwGwKzZC5I9NqtSzpyjvDlHeXOccuYc5c05aSFvlinYHmaa5jHTNBeapjnENM3GpmneeeDwO6Zp5jZNc5Bpmqmzb/MBe/bsY/nyNWTOnIn5cyeTPbvtXruXlxeTJ31OyRLF2G8eYlHkC1KUM2cpb85R3hynnDlHeXNOWsibNn+3wObvAPnz52Xd2oX4+RXk+vUb7Nt/EP/CvmTPno1Lly5TvWYT9u1L1XMrEp1y5hzlzTnKm+OUM+cob85JTXl7rDd/f9ydPn2GSlXq8/W47wkJCaVsmRLcuxfGnLkLqfJ0Q8u8yKxEOXOO8uYc5c1xyplzlDfnPO55Uw+bRXrYREREJG1QD5uIiIjIY0gFm4iIiIjFqWATERERsTgVbCIiIiIWp4JNRERExOJUsImIiIhYnAo2EREREYtTwSYiIiJicSrYRERERCxOBZuIiIiIxalgExEREbE4FWwiIiIiFqeCTURERMTiVLCJiIiIWJwKNhERERGLU8EmIiIiYnEq2EREREQsTgWbiIiIiMWpYBMRERGxOBVsIiIiIhangk1ERETE4lSwiYiIiFicCjYRERERi1PBJiIiImJxKthERERELE4Fm4iIiIjFqWATERERsTgVbCIiIiIWp4JNRERExOJUsImIiIhYnHtKByCSVrikdACpUERKByAi8fJy90jpENIM9bCJiIiIWJwKNhERERGLU8EmIiIiYnEq2EREREQsTgWbiIiIiMWpYBMRERGxOBVsIiIiIhangk1ERETE4lSwiYiIiFicCjYRERERi1PBJiIiImJxKthERERELE4Fm4iIiIjFqWATERERsTgVbCIiIiIWp4JNRERExOJUsImIiIhYnAo2EREREYtTwSYiIiJicSrYRERERCxOBZuIiIiIxalgExEREbE4FWwiIiIiFqeCTURERMTiVLCJiIiIWJwKNhERERGLU8EmIiIiYnEq2FKYi4sL//y9lOCgPfG2e+ONV9mw/leuXj7E+XOBrPn9Jxo1qptMUVpLQnP2IHd3d7Zv+517d05Ts0bVJIzOulxcXFj/91LOxJO3hQuncffO6Ti/jh7ZmowRW5NhBPDd5C84dGAj168e4fy5QP5Y/TOtWjVN6dAsK3v2bNy7czrer4+H9k/pMC3Nmfe9x1XJksWYNu1rjhzdQsj5fWzZuorBH7xNtmxZ4jwnW7YsfPhRX7Zs+Y2Q8/s4FxLIxo0r6P9eD9Kn907G6J3nntIBpHXDPn6PSpUqcP78hTjbjBwxgP79ehAeHs6/gSbpvNJRs+bT1Kz5NB9+NJoRI8cmY8QpLyE5e9jAAb0oW6ZkEkZlfR8nIG+lSxUHYOPGbYSFhcU6fi7kfJLFlxo0aliXObMn4u3tzc2bN9lvHsYnd05q1KhKjRpVeeH5WrRp2zOlw7ScMqVtr6vz5y9gmofstjl+/FRyhpTqOPO+9zhq1Ph5pk8fR7p0Xly/foP9+w9SIH9eBgzoTatWTXmxcRsOHjwS45xChQrw26p5FCyYn7CwMA4fPoa7uzslSxWjTNkSNH2lIfXrt+DChUsp9KwSRgVbCvpg8Nu8/178b+4NG9Shf78ehIZepGGjVmzdtguAxo2fZ86siXw45F3Wrv2bfzakjZ6PhOTsYaVLF3f4nMfN4ATkLVOmjPj5FeTKlatUr/FiMkWWeuTOnZMZ08fh7e3Nd9/P5J13P+TmzVsAvPjiC0z74StatniFzZt38M34H1I4WmspU6YEAHPnLaLP2x+kcDSpjzPve4+jQoUKMGXKGNKl82LJkt/o1rUfly9fwdXVlYGDejNgQG8WLprGkxXqcvv27ejzpk0fR8GC+dmwYSvt2/Xm5MnTgK2nbsaP4yldpgTfjP+Uli26pdRTSxDdEk0BPj65+OXnKXw4pO9/to36JR04aGR0sQawdOkqhg0fg6urK+/1f/x/kR3J2YNcXV35bvIXuLi4cOfOnSSKzrp8fHLxcwLzFtULsm/fwaQOK1Xq2KElmTNnYtv23bzV/f3oYg1gyZLfGDT4EwB69+qcUiFaVunI11Zg4IEUjiR1cfZ973HVs1cnMmbMQGDgAdq07sHly1cACA8PZ/iwMaxbt4HChX1566120edUqfIklSqV59q167Ru3T26WAMir9MdgCZN6lGwYP5kfT6OUsGWzOrWqcG+f/9HkxfrcebMWQYOGhln24AAP6pWfYo7d+4wZ+7CWMd/mDrHds26NciSJXOSxZzSHMnZw959pxsVnyrHmLGTuHLlWhJGaT116tQg0IG8lS5t6wUJDDSTI7xUJ2rs46JFK4iIiIh1fNny1QAULuxL1qxxj6VJi8roteWwR3nfe1zVrl0dgEmTZnD37t1YxydPmgFA8+YvRT9WvUYVADZv2s6ZoLOxzgkMPMCxYycBKFe+dKLHnJhSVcFmGEaAYRiVDcPwT+lYnFWiRDEyZszAjzN/5onytdm0aXucbStVKg/A7j37uHHjZqzjISGhHD58DE9PT6pUrpBkMac0R3L2oGLFAhjywTscOHiEoR9/mcRRWk/JyLzNnPkz5RKQt6jbVuoFse/Dj0bTvmMfFi9Zafd4hgzpo793d3dLrrBShZIliwHwr15bCebs+97jLKoHbOfOvXaPHz58DICSpYrh7Z0OgAW/LKNtm56MHTs5zuumj2zr7mbt31tLjWEzDCML8BFQzDTNhg883gkYAuR/4LEg4Bvgc9M0Y4+OtqgtW3ZSsXI9du369z/bFgnwA4iu/u05ceI0AQF+BES2fRw5krMHfTfpc7y8vHjzzf4xxjOkFVu27KSSA3mLum11/MQpunZpw7PPPUO2rFk4ffoMCxctZ+nSVUkZruVt2rydTZvj/qP5YuMXADh37nyaHxj+IH//QmTKlJEzZ86SO3cO+vV9kyfKlgJg955Apvwwh0OHjqZwlNbj7PteWhBXYeXuYStp3NzcyJ8/L4cOHeXw4WPRhZw9lSpVILdPLgD277f2cBDLFGyGYfgA/wOKAMEPPP4p0A9wAU4Dx4E8gB8wEqhtGEb91FK0bdiY8MkBOXPmACA09GKcbS5cvBTZNvujBWZhjuQsSo/uHahWrRKTv5vJur82JEFU1udo3kqVMgCY8v0YMmXKGONY69bNWLFiDS1aduP69RuJFuPjwscnF33ffROAOXMXpXA01hL1QSBLlszs2vEH7u73/+y88MKz9O7Vmd59PuC772emVIiW5Mz73uPu2LGTlChRlFKli7Nx47ZYx0sULxr9fdZ4lviI4urqyshPBgKwe3eg5cfvWumW6MfYirVfgEoAhmE8BfQHLgCNTNMsaJrmM6ZpFgFKAf8AtYG3UybkpBXVpXvrgcHND4sa+BzVVsDPryDDh73P6dNneH/A8JQOJ1UoWDAf2bJlBeDIkePUb9CCLFmLkNunFB07vk1o6EXq16/N99+PSeFIrSd9em8W/PwD2bJlJSQklFGfjUvpkCylbOSt9vTpvfl+ymxKlq6BdwY/ipd8hkmTf8TT05Px33xCwwZ1UjhSsbrfVv4BQO/enfH09IxxzMXFhd6970/48fTw+M/rfTZ6CFWrPkV4eDgDB4xI3GCTgJUKtobASaCVaZpRC/I0BSKAt0zTXP5gY9M0TeBFIBRom5yBJpfw8PD/bOPq6gJgdxB0WjVp4mgyZsxAz96DuHLlakqHkyqEh0fwxRcTmTp1DjVrvcTq1X9x48ZNLl68xIwf59O48RuEhYXxatNGVK70+I6XdFSGDOlZsmgGlStX4N69e7Rt15Nz59L2WnUP27FjL5Mm/0iv3oPo0XMABw4c5u7duxw6dJTuPd7nm/E/4OrqyqhRWu5D4jdu3PecP3+BgAA/Fi2axhNPlMLd3Z2iRf2ZPedb/AP8osd73717L95rjRgxgDffbAfAZ599w9q165M6/EdmpYItF7DVNM0H117IEfnvb/ZOME3zIrABSLWTEOJz/Zrt1pNXOq8423h52Y7djKcXLi3p2KEltWtX56efl7Jkid2XjdgR1RvZpWtfu7c8t2zdyZo1/wOgYRrdYeNhOXNm5/ff5lGr1tOEhYXRsfM7rPp9XUqHZTnLlq+me4/3mTBxmt3jn46y9UgWN4pQpEjhZIxMUpvg4BBea9aJ0NCL1Kz1NP9sWMblK4fYuesPnn22Gu3a9You2K5etf9h3c3NjW/Gf0Kft7sCMGXKbIalkklplhnDBpwDAh567HDkv7mAK3Gclx94LNdrCL1gG7uWPXvWONvkyJ4NgJAQDXLOly8Poz4dzIULF+ndZ3BKh/PY2bX7X55/vhaFfK29VlFyKFzYlxXLZlOo1b57AAAUxklEQVSkSGHu3r1Luw69mTdvcUqHlSoFB5/j7NkQfHxyUci3gCYgSLw2bdpOhfK16dylNRUrlgNss0Z/mDKHs2dDyJrVtsRVcPC5WOd6e6fjx5njqV+/NgDffjudd9/5MPmCf0RWKthWAe0Mw3jLNM0JkY/NBj7ANkM01m1PwzBaABWAn5MtymS0P3ILF79CBeJs4xv5x/PwYb3J1aldI3r9q6BTu+Jst2a17eXy8bAv+HhY6vhklVw8PT3jXGDYxcV2+/3OndjrH6UlZcqUYPmvs8ib14fr12/weouurIgcWyP2ubu7Ex4eHucwj/uvrbS3uLU47vz5C3wy8qtYj5crXxp3d3eCgoK5dClmH0+WLJn5ZcEPVK36FAAjRoxl5IjUta2jlQq2odjGrI0zDKMy8CWwG+gIzDAMIxcwETgG5ANeA9oAd4HHcmT5tsidDcqWLYmXl1espSly5cqBv38hwsLC2LI17gIlrTh3LoT16zfHebxSpfJ4eHiwZ+8+rly+yokTp+Nsm9aMGDGAt/t0Ze3a9TRs1Mpum6ilGPZZfOp7UipSpDArl8/BxycXFy5c5MUmbdm4KfZsNbnv6OEtFCyYj1at37LbC5k3rw+5c+cE7n9IFbHn6acr8tRTT/DPhq1s3bIz1vGonrP//bUxxuPe3umii7WwsDDeffdDvpuc+mYlW6ZgM03zhGEYdbD1qrUG3gDuYLtVegd4IfIrigtwHehgmubuZA43WRw/fortO/ZQoXwZWrV8JXpngygdO7QEYMXKP7h06XJKhGgpK39by8rf1sZ5PDhoDzlzZqdPnw/S7FIfcdm16188PDyoUaMKvr75YxWzZcuW5LnnniEsLIyFC5fHcZXHm7d3OhYtnIaPTy5CQkJ5vl5z9uzZl9JhWV5goEnBgvlo3epVuwXbO31sY4nWrfuHkJDQ5A5PUpGKFcsx8pNB/PTTUtq1jbklY6ZMGenUyfZh87vvYhZj48aNjC7Wunbpy5w5sXcOSg2sNOkA0zS3AqWx3f5ciq1YKwhkwFaguWDrUdsNfAqUMk3zp5SJNnmM+uwbAEZ/NiR6axyARo3qMnhQH8LDwxk9enxKhSePiUWLVnLo0FHSpUvHvLmT8fMrGH3sqSefYMEvU3Fzc2PSpBkcPXoiBSNNOQMH9Ka4UYSwsDBeb9FVxVoCfTlmEgD16j3HiOHv4xG53IKrqyvvvN2V3r07c+/ePQYM1NZLEr+lS1dx+/ZtmjZtSLNmL0Y/7uOTi3nzJpMnT25WrvyDDRvur2H33HPP0KLlKwAMHz4m1RZrAC5WXw7CMAxPIDOQDluP2mXTNP97vYsEcvfMn6IJqFmjKmtW/8z58xfIk6+M3TaTJ31Oh/YtAPg30MTDw4NiRW0TYwd/8Gn0LKu0IiE5syeqh612nVdTpIfNJdl/Ykw1HshbXjt5K1u2JCuWzyF37pzcvXuXAweP4ObmRnGjCAC/Lvud117rbHcPv6RilXcnT09Pgk7tJGvWLFy9eo3duwPjbf/a6104ezYkmaKzvvff68nwYe8DcOnSZQ4dPkYh3wLkypWDu3fv0rlrX2bOfCyHIicaZ9/3kpqX+3+vd5aYunVryxdfDgVsC+levnyF4sWL4OXlxfbtu2lQvyVXr96fh7ho8XTq1q0JwMaN2+JdLmv0Z+NZterPJI0/yvUbxxz+k2CZW6JxiVzmI00vbNSla1/Wr99M1y6tKVWqOC4uLmzYsJVx46cwf/6SlA5PHhO7dwdS4ck69H33LRo2rEuRAD9u3rzF339vYtq0uUyfMT+lQ0wxZUoXj57QkilTxv+3d+fBklX1Ace/I7IKImREh0VBkZ8jAYFBdgIuLNGMoCxugKJmSkOBGAtQSgmSQIGoFA4iFUUUQRGCghFcACGIQilQLAL+BiWjLGF3ZN9f/jinsefR780wb3j3NHw/Va9O97237/31q+6+v3u2y5ZbbjLu9suMMxXPC9GRR83mssuuYL/9Psrmm23M+utN56677uG73/sBX/zS1xaYAEs9J5zwbW697Xb22efDbLDBukybtgp//MNcvn/62Rw3+0QeeWT+vt69QQYAm202Y9x99/pStqr5GrbnWtc1bHrh6LqGbRj55ZTaNtk1bM8Xi1LD1lQfNkmSJD2TCZskSVLjTNgkSZIaZ8ImSZLUOBM2SZKkxpmwSZIkNc6ETZIkqXEmbJIkSY0zYZMkSWqcCZskSVLjTNgkSZIaZ8ImSZLUOBM2SZKkxpmwSZIkNc6ETZIkqXEmbJIkSY0zYZMkSWqcCZskSVLjTNgkSZIaZ8ImSZLUOBM2SZKkxpmwSZIkNc6ETZIkqXEmbJIkSY0zYZMkSWqcCZskSVLjTNgkSZIaZ8ImSZLUOBM2SZKkxpmwSZIkNc6ETZIkqXFTRkZGuo5BkiRJ47CGTZIkqXEmbJIkSY0zYZMkSWqcCZskSVLjTNgkSZIaZ8ImSZLUOBM2SZKkxpmwSZIkNc6ETZIkqXEv7joAzS8i3gYcDKwPLAVcARyZmT/rNLAhEREfAk4Cts7MSzoOp1kRsQTwceCDwHRgCeAm4DTg6Mx8pMPwmlX/b/sAHwECeAi4HDg2M8/pMrZhERErA78DpmXmlK7jaVlE7AmcPM4mh2fmZycrnmEREa8GDgF2AFYB7gLOAQ7JzNu7jG0irGFrSE02zgO2AH4DXApsCfw0ImZ1GNpQiIjNgdldx9G6mnScTflfvR64DLgIWBU4DLgoIpbrLMC2nQQcC6wJXEC5oNoG+HFEfK7DuIbJ8cC0roMYEhvW8jzg1AF/V3UUV7MiYmPgauDDwL2URO0p4J+BSyJipQ7DmxBr2BoREdOAE4C/Altl5u/q8jcB5wPHRsQ5mXlrh2E2KyLeDXwLWL7jUIbBR4F3ANcAb+99piJiKvAjYHPgc8BnOouwQRGxO7AnkMA2mXlHXb4u8Cvg0Ig4LTNv7DDMpkXE+4D3dB3HEOklbHv7279gEbE08F1gRWC/zJxdly8DnALsAhwKfKKrGCfCGrZ27AssDRzTS9YAMvO3wBeAZQBr2UaJiNUj4mTgTEqz3h0dhzQMPlTL/ftPApl5N6WZFOC9kx3UENijlp/uJWsAmXkdpbbjRcD2XQQ2DCJiVeA44NfAkx2HMyw2AO4wWVtouwOvA07tJWsAtYvHJynnh+gotgkzYWvHjrU8a8C6H9byHycplmHyH5Raj8uBzYDfdxvOULib8n/6zYB1c2q56uSFMzR2BdYDfjJg3Qq1fGLywhk6J1IuPD/YdSDDICLWAl5GaXbXwtmlll8evSIzb87MV2bmjqPXDQubRBsQEVOAN1Da2W8YsMmcum7diJiSmSOTGV/jfk85AZySmU9FDO3F06TJzJnjrH5TLW+ZjFiGSWY+RuksP5+I+CdgN+ABBl9wveBFxMcpF6X7ZuYf/J4ulF5z6B0RMZtywb468CdK856Dg55pI+Ax4OqIWAN4P7A2cA9wZm2xGlombG1YidIcelc9KcwnM5+IiLspo11WAO6b5PialZlHdh3D80W9cDisPj2zy1haFxHLAt+hXGhNB/4M7NnfVKoiIl4LHA38Avhqx+EMk6f7rwF/AX4J3ApsTPme7hgRb8vMhzuKrym1/9oalIvN3Sg1uv2Dpw6KiKMz88Au4lscbBJtw0tq+dA42/S+lHaq13PlCMqIxzsoJ1iN7VWU5pfpfcvW7yiWZtURySdTWgj2tnXgWeklbKcDa2TmTpm5DbAuZRTkFpQuISpeWsuVKZ+5H1L6q61E6ZN7L3DAMM+4YMLWhqdqOd6P2ZRRpbTYRMRhwKeBR4HdM/OujkNq3S3AVMrJYXdgSWB2RBzUaVTtOZCSWHwyM//cdTBDZldKcrZnZj7YW5iZcykDh0aAWRGxZCfRtWeZWi4HXJiZe2TmnMycl5nfB/aq6w+prQlDxybRNjxQy2XH2ab3YXxwnG2kZyUiXkxpppoFPAK8OzMv7jaq9tUTaO+7eEZE3EwZ/XhwRBxr3yKIiDdSplA4NzNP7DicoVM/Q9ePse6qiLiF0gS4DnDdZMbWqP5z4/GjV2bmORFxK7AapV/b0E2/Y8LWhvsoSdvUiHhxZs430qyeVKcCj2TmvC4C1PNPRCwPnEHpDD4P2MlkbdFk5mUR8UfKieA1jHGifYE5nHK3liUj4pRR614E0Ld8/zqtjBbe7ZSEzUmui79SBhwsBcwdY5s/URK2qZiwaVFk5khEXA9sQrlaGv1jH5QfuGsnOzY9P9XZvs8DZgA3UybQfcYISBW1CeUoSt+1PUZfVFWP1tImqqLX33a7cbb5QC0/S5luRkBErAB8idLk/t4xPm9r1dI52oDMfDIibgDeSJmW6OoBm72ylkPZ5cOErR0/pSRsO/PMhG3nWp47qRHpeSkilqJ8lmZQPms7ZKbTeIyjXlTtTJmU82RGfRfrnFlBaZbJyY+wPZm57VjrIuIJYAnvJTqmB4B3UWqCtqHcBu1pEbFjXXdtZt42+eE16yeUhG13Rs2XGGUumTWB2yj3TR46Djpox0mUPkQHRcSM3sJ6X7QDKaNEn9EuLy2CwyiTDN8MbGuyttD+s5ZfiYjVewsjYjXgNMoF8Fftv6aJqqNpv16fzq53iQCenialdy5wlOj8TqBcNO0VEe/vLawtCt+g5Dxfzcynxnh906aMjDjKuhUR8S+UDuCPU66opgBvoZwI9srM0f1ANEpEXES5It06My/pOJzmRMTKlBGOywJXMniiZgAyc4+x1r0Q1dF4ZwFvp5wULqF8NzelNP+dC7xr0FyKmp81bAtW5/r7ObAVpcat93v2Zsq8nV/OzE91FF6z6j1/T6V8N6+kNBlvTqmR/AWwY2Y+3l2Ei84atoZk5vHATOAyYGvKrPOXANuZrGkx2YS/jUbeiNKHaKw/9ak/8u8E9qPcfWQbyongOuBjwEyTNS0udULct1Km25lLSdS2oJwfdjFZGywzT6ecO8+k9DndDriT8n8c2mQNrGGTJElqnjVskiRJjTNhkyRJapwJmyRJUuNM2CRJkhpnwiZJktQ4EzZJkqTGmbBJkiQ1zoRNUqci4rX1LgJDJSIOjYiRiPivxbCvb9V9fXFxxLaAY43Uv79/ro8lafHx5u+SOlGTtEOAAyi3jRnaGcgl6blmwiapK6sBn+06CEkaBjaJSpIkNc6ETZIkqXE2iUqadBHxLeCDfYvujwiAtTJzbkTMBV4NrA0cDswEHgP+OzP36ls/MzN/PGD/dwN/B7w5My8atW4t4NPA9sCqwP3AZcAxmXnBYnp/awGfAN5a41wGuKce5yuZeeE4r90U+Hdgc+BJ4Dc1tp+Msf0qwIGU/9GrgEeAK4GvZeaEB0RIaoM1bJK6MAe4vO/5pcCvKMlGv1OAXev2TwB/mshBI2IH4FpgFrAKcB3wMPAO4PyI+LeJ7L8eY/u6308AawB/rH8rAzsDF0TE+8Z4+dbAxcC2lPf8ALAdcG5EfG7AsTaq7+dTlMRwDiUxfAtwRkR8MyKmTPQ9SeqeCZukSZeZRwC79S3aPjO3yszbR226IbB1Zm5IqQ07elGPGRFrAqcDL6HUYK2UmRtl5hrATsB9wKERsfMEjrE0cBKwLHAM8IrM3DAzp1Nqv84HpgDPSL6qTYCrgNdk5gxKwrcvMAJ8PiK26DvWisBZlMTzG8DLM/ONmbk2sBVwG7A3JXGUNORM2CS17AeZeSlAZj6emfdNYF8HAC8FTs7MQzLzsd6KzPwRpZkUYCK1bDOA5YFbgQMy89G+Y9wBfL4+jYgY9Pt7P7BTZt5SXzOSmccB36Qkep/q23YWJaH7H2BWZt7fd6xfAR+tTz8zjPPcSZqfCZukll26GPc1s5bfG2P9aZSarA0iYtqiHCAzf52ZKwKvy8wnB2zyUC1fROnXNtpZA2oZodTaAWwXEUvUx+/sxZ2ZIwNe81PgL5QauBkL9QYkNctBB5Ja9n+LYycRsQKlNgrgiIgYa/63Jym/i+tM5NiZ+XDtX7YR8Nr6tx4QfZsNumC+aoxdXlfLFYBpwC3AG+qy/SJijzFet1QtgzLgQdKQMmGT1LLRgxAW1Uv7Hm+4ENuvuKgHioh/AL7M/LVaI8CNwKnAWMkVlEEGC1q+XC1772n6QoS1yO9HUhtM2CQNs7FGQC436vmDfY+nZuY9z0Uw9f6cPweWBn4JfAe4BrghM++LiHUYP2F7yRjLV+h7PK+WD1ISsY0z84oJBS6peSZskobRE7VcevSKiHgZZZTm0zJzXkTcBbycUiN1yYDXLQG8GZgL/O8YfdAWZL8a0wXADgP2sfoCXr/OGMs3qOXdmXlnfXwjsDHl/QxM2CJiW+B24Kb+QRaSho+DDiR15am+x892rrC/1DIGrJs5YBnAubX82BjrPwCcR+lHtvyzjKdnzVpeM0bC95G+x4MumN9V+9uN9vFa9k8SfE4tZw2aay0itgYuBK6nzNEmaYiZsEnqSn+/rGebUPy6lvtGxOt7CyPibZT5zwb5AqVP3Aci4vCIWKbvddsDx9WnX8/Mvz7LeHrm1PI9EbF23/5XiohjgPf3bTtolOgrgO/XWkIiYok6Ye5uNfaj+rY9HribMtnuiXVett7xNqaMegU4OzNvXMT3I6kRJmySOpGZ91JGOwJcHBG/jYh1F/Llx1Bm9H8FcG1EXBURN1FqyOZQ+pGNPt71wF7Ao8DBwJ31mHOBn1H6iZ0PHLTIb6oMNphHmeT3hoi4NiKuoYw43R+4usZN3Wa0s4EdgFsi4nLKfG6HUZqA987M3/e9nzuBXerx9gZuj4jLI+JG4Ld1/9fUdZKGnAmbpC7tSkkuluVv018sUGbOBd4EfJtSyzQdeBw4lNIP7eExXncGpT/YicC9wPrA1BrD/sDbJ9LXKzNvqvv/NvBnSpPtqyiJ2r8Cm1KSShjcdPtjyj1Or6JM27EUJYnbLDNPG71xZl5MmS7kWOBmYF1KP7lrKRMAb5mZ80a/TtLwmTIyMmi+RUmSJLXCGjZJkqTGmbBJkiQ1zoRNkiSpcSZskiRJjTNhkyRJapwJmyRJUuNM2CRJkhpnwiZJktQ4EzZJkqTGmbBJkiQ1zoRNkiSpcf8PXqnt4W6QRSUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# computing the confusion matrix\n",
    "mat = confusion_matrix(converted_train_values, pred_train)\n",
    "\n",
    "# plotting confusion matrix\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False) \n",
    "\n",
    "plt.title('Train Confusion matrix')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "#fig1.show()\n",
    "#plt.savefig('confuseMat_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(63.7, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# computing the confusion matrix\n",
    "mat = confusion_matrix(converted_test_values, pred_test)\n",
    "\n",
    "# plotting confusion matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False) \n",
    "\n",
    "plt.title('Test Confusion matrix')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "#fig1.show()\n",
    "#plt.savefig('confuseMat_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
